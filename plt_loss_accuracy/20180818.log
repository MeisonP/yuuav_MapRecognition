Last login: Mon Aug 13 14:54:49 on ttys002
MasondeiMac:~ mason$ ssh mason@192.168.0.126
^C
MasondeiMac:~ mason$ ssh mason@192.168.0.126
^C
MasondeiMac:~ mason$ ssh mason@192.168.0.126
mason@192.168.0.126's password: 
Welcome to Ubuntu 16.04 LTS (GNU/Linux 4.4.0-21-generic x86_64)

 * Documentation:  https://help.ubuntu.com/

628 packages can be updated.
321 updates are security updates.

Last login: Mon Aug 13 14:54:57 2018 from 192.168.0.102
mason@mason_ubuntu:~$ df -h /
Filesystem      Size  Used Avail Use% Mounted on
/dev/sda1        86G   24G   58G  29% /
mason@mason_ubuntu:~$ sudo -s
[sudo] password for mason: 
root@mason_ubuntu:~# cd App/caffe/
root@mason_ubuntu:~/App/caffe# cd yuuav0810/
root@mason_ubuntu:~/App/caffe/yuuav0810# python ./src/ssd_pascal.py 
../build/tools/caffe: /home/mason/anaconda2/lib/libtiff.so.5: no version information available (required by /home/mason/App/opencv/build/lib/libopencv_imgcodecs.so.3.4)
I0813 16:40:57.563299  1670 caffe.cpp:217] Using GPUs 0
I0813 16:40:57.917001  1670 caffe.cpp:222] GPU 0: Quadro P2000
I0813 16:40:58.200986  1670 solver.cpp:63] Initializing solver from parameters: 
train_net: "./savedmodel/VGGNet/YUUAV/SSD_300x300/train.prototxt"
test_net: "./savedmodel/VGGNet/YUUAV/SSD_300x300/test.prototxt"
test_iter: 625
test_interval: 10000
base_lr: 0.0001
display: 100
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 50000
snapshot_prefix: "./snapshot/VGGNet/YUUAV/SSD_300x300/VGG_YUUAV_SSD_300x300"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 50000
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 8
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0813 16:40:58.201593  1670 solver.cpp:96] Creating training net from train_net file: ./savedmodel/VGGNet/YUUAV/SSD_300x300/train.prototxt
I0813 16:40:58.202591  1670 net.cpp:58] Initializing net from parameters: 
name: "VGG_YUUAV_SSD_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "data/yuuav/yuuav_trainval_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/labelmap_yuuav.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc6_mbox_loc"
  type: "Convolution"
  bottom: "fc6"
  top: "fc6_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_mbox_loc_perm"
  type: "Permute"
  bottom: "fc6_mbox_loc"
  top: "fc6_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc6_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc6_mbox_loc_perm"
  top: "fc6_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc6_mbox_conf"
  type: "Convolution"
  bottom: "fc6"
  top: "fc6_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_mbox_conf_perm"
  type: "Permute"
  bottom: "fc6_mbox_conf"
  top: "fc6_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc6_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc6_mbox_conf_perm"
  top: "fc6_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc6_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc6"
  bottom: "data"
  top: "fc6_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc6_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc6_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc6_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 23
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0813 16:40:58.202919  1670 layer_factory.hpp:77] Creating layer data
I0813 16:40:58.203642  1670 net.cpp:100] Creating Layer data
I0813 16:40:58.203652  1670 net.cpp:408] data -> data
I0813 16:40:58.203676  1670 net.cpp:408] data -> label
I0813 16:40:58.205123  1693 db_lmdb.cpp:35] Opened lmdb data/yuuav/yuuav_trainval_lmdb
I0813 16:40:58.233187  1670 annotated_data_layer.cpp:62] output data size: 8,3,300,300
I0813 16:40:58.240504  1670 net.cpp:150] Setting up data
I0813 16:40:58.240526  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240530  1670 net.cpp:157] Top shape: 1 1 4 8 (32)
I0813 16:40:58.240532  1670 net.cpp:165] Memory required for data: 8640128
I0813 16:40:58.240548  1670 layer_factory.hpp:77] Creating layer data_data_0_split
I0813 16:40:58.240558  1670 net.cpp:100] Creating Layer data_data_0_split
I0813 16:40:58.240563  1670 net.cpp:434] data_data_0_split <- data
I0813 16:40:58.240572  1670 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0813 16:40:58.240581  1670 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0813 16:40:58.240586  1670 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0813 16:40:58.240591  1670 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0813 16:40:58.240594  1670 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0813 16:40:58.240599  1670 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0813 16:40:58.240603  1670 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0813 16:40:58.240664  1670 net.cpp:150] Setting up data_data_0_split
I0813 16:40:58.240669  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240671  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240674  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240677  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240679  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240682  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240684  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:58.240687  1670 net.cpp:165] Memory required for data: 69120128
I0813 16:40:58.240689  1670 layer_factory.hpp:77] Creating layer conv1_1
I0813 16:40:58.240700  1670 net.cpp:100] Creating Layer conv1_1
I0813 16:40:58.240702  1670 net.cpp:434] conv1_1 <- data_data_0_split_0
I0813 16:40:58.240708  1670 net.cpp:408] conv1_1 -> conv1_1
I0813 16:40:58.916003  1670 net.cpp:150] Setting up conv1_1
I0813 16:40:58.916021  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:58.916024  1670 net.cpp:165] Memory required for data: 253440128
I0813 16:40:58.916040  1670 layer_factory.hpp:77] Creating layer relu1_1
I0813 16:40:58.916049  1670 net.cpp:100] Creating Layer relu1_1
I0813 16:40:58.916051  1670 net.cpp:434] relu1_1 <- conv1_1
I0813 16:40:58.916055  1670 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0813 16:40:58.916326  1670 net.cpp:150] Setting up relu1_1
I0813 16:40:58.916333  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:58.916349  1670 net.cpp:165] Memory required for data: 437760128
I0813 16:40:58.916352  1670 layer_factory.hpp:77] Creating layer conv1_2
I0813 16:40:58.916360  1670 net.cpp:100] Creating Layer conv1_2
I0813 16:40:58.916363  1670 net.cpp:434] conv1_2 <- conv1_1
I0813 16:40:58.916368  1670 net.cpp:408] conv1_2 -> conv1_2
I0813 16:40:58.918449  1670 net.cpp:150] Setting up conv1_2
I0813 16:40:58.918473  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:58.918475  1670 net.cpp:165] Memory required for data: 622080128
I0813 16:40:58.918481  1670 layer_factory.hpp:77] Creating layer relu1_2
I0813 16:40:58.918485  1670 net.cpp:100] Creating Layer relu1_2
I0813 16:40:58.918488  1670 net.cpp:434] relu1_2 <- conv1_2
I0813 16:40:58.918493  1670 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0813 16:40:58.918705  1670 net.cpp:150] Setting up relu1_2
I0813 16:40:58.918712  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:58.918715  1670 net.cpp:165] Memory required for data: 806400128
I0813 16:40:58.918717  1670 layer_factory.hpp:77] Creating layer pool1
I0813 16:40:58.918721  1670 net.cpp:100] Creating Layer pool1
I0813 16:40:58.918725  1670 net.cpp:434] pool1 <- conv1_2
I0813 16:40:58.918727  1670 net.cpp:408] pool1 -> pool1
I0813 16:40:58.918771  1670 net.cpp:150] Setting up pool1
I0813 16:40:58.918786  1670 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0813 16:40:58.918789  1670 net.cpp:165] Memory required for data: 852480128
I0813 16:40:58.918792  1670 layer_factory.hpp:77] Creating layer conv2_1
I0813 16:40:58.918797  1670 net.cpp:100] Creating Layer conv2_1
I0813 16:40:58.918799  1670 net.cpp:434] conv2_1 <- pool1
I0813 16:40:58.918802  1670 net.cpp:408] conv2_1 -> conv2_1
I0813 16:40:58.919958  1670 net.cpp:150] Setting up conv2_1
I0813 16:40:58.919967  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:58.919970  1670 net.cpp:165] Memory required for data: 944640128
I0813 16:40:58.919976  1670 layer_factory.hpp:77] Creating layer relu2_1
I0813 16:40:58.919981  1670 net.cpp:100] Creating Layer relu2_1
I0813 16:40:58.919984  1670 net.cpp:434] relu2_1 <- conv2_1
I0813 16:40:58.919987  1670 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0813 16:40:58.920354  1670 net.cpp:150] Setting up relu2_1
I0813 16:40:58.920362  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:58.920366  1670 net.cpp:165] Memory required for data: 1036800128
I0813 16:40:58.920368  1670 layer_factory.hpp:77] Creating layer conv2_2
I0813 16:40:58.920374  1670 net.cpp:100] Creating Layer conv2_2
I0813 16:40:58.920377  1670 net.cpp:434] conv2_2 <- conv2_1
I0813 16:40:58.920382  1670 net.cpp:408] conv2_2 -> conv2_2
I0813 16:40:58.921998  1670 net.cpp:150] Setting up conv2_2
I0813 16:40:58.922008  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:58.922009  1670 net.cpp:165] Memory required for data: 1128960128
I0813 16:40:58.922014  1670 layer_factory.hpp:77] Creating layer relu2_2
I0813 16:40:58.922019  1670 net.cpp:100] Creating Layer relu2_2
I0813 16:40:58.922021  1670 net.cpp:434] relu2_2 <- conv2_2
I0813 16:40:58.922024  1670 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0813 16:40:58.922282  1670 net.cpp:150] Setting up relu2_2
I0813 16:40:58.922289  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:58.922291  1670 net.cpp:165] Memory required for data: 1221120128
I0813 16:40:58.922293  1670 layer_factory.hpp:77] Creating layer pool2
I0813 16:40:58.922297  1670 net.cpp:100] Creating Layer pool2
I0813 16:40:58.922300  1670 net.cpp:434] pool2 <- conv2_2
I0813 16:40:58.922304  1670 net.cpp:408] pool2 -> pool2
I0813 16:40:58.922330  1670 net.cpp:150] Setting up pool2
I0813 16:40:58.922334  1670 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0813 16:40:58.922338  1670 net.cpp:165] Memory required for data: 1244160128
I0813 16:40:58.922339  1670 layer_factory.hpp:77] Creating layer conv3_1
I0813 16:40:58.922345  1670 net.cpp:100] Creating Layer conv3_1
I0813 16:40:58.922348  1670 net.cpp:434] conv3_1 <- pool2
I0813 16:40:58.922353  1670 net.cpp:408] conv3_1 -> conv3_1
I0813 16:40:58.925284  1670 net.cpp:150] Setting up conv3_1
I0813 16:40:58.925297  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.925300  1670 net.cpp:165] Memory required for data: 1290240128
I0813 16:40:58.925308  1670 layer_factory.hpp:77] Creating layer relu3_1
I0813 16:40:58.925315  1670 net.cpp:100] Creating Layer relu3_1
I0813 16:40:58.925318  1670 net.cpp:434] relu3_1 <- conv3_1
I0813 16:40:58.925323  1670 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0813 16:40:58.925699  1670 net.cpp:150] Setting up relu3_1
I0813 16:40:58.925706  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.925709  1670 net.cpp:165] Memory required for data: 1336320128
I0813 16:40:58.925711  1670 layer_factory.hpp:77] Creating layer conv3_2
I0813 16:40:58.925719  1670 net.cpp:100] Creating Layer conv3_2
I0813 16:40:58.925721  1670 net.cpp:434] conv3_2 <- conv3_1
I0813 16:40:58.925725  1670 net.cpp:408] conv3_2 -> conv3_2
I0813 16:40:58.929255  1670 net.cpp:150] Setting up conv3_2
I0813 16:40:58.929263  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.929267  1670 net.cpp:165] Memory required for data: 1382400128
I0813 16:40:58.929272  1670 layer_factory.hpp:77] Creating layer relu3_2
I0813 16:40:58.929277  1670 net.cpp:100] Creating Layer relu3_2
I0813 16:40:58.929280  1670 net.cpp:434] relu3_2 <- conv3_2
I0813 16:40:58.929283  1670 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0813 16:40:58.929555  1670 net.cpp:150] Setting up relu3_2
I0813 16:40:58.929563  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.929579  1670 net.cpp:165] Memory required for data: 1428480128
I0813 16:40:58.929581  1670 layer_factory.hpp:77] Creating layer conv3_3
I0813 16:40:58.929596  1670 net.cpp:100] Creating Layer conv3_3
I0813 16:40:58.929600  1670 net.cpp:434] conv3_3 <- conv3_2
I0813 16:40:58.929603  1670 net.cpp:408] conv3_3 -> conv3_3
I0813 16:40:58.933277  1670 net.cpp:150] Setting up conv3_3
I0813 16:40:58.933288  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.933290  1670 net.cpp:165] Memory required for data: 1474560128
I0813 16:40:58.933296  1670 layer_factory.hpp:77] Creating layer relu3_3
I0813 16:40:58.933302  1670 net.cpp:100] Creating Layer relu3_3
I0813 16:40:58.933305  1670 net.cpp:434] relu3_3 <- conv3_3
I0813 16:40:58.933308  1670 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0813 16:40:58.933581  1670 net.cpp:150] Setting up relu3_3
I0813 16:40:58.933588  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:58.933604  1670 net.cpp:165] Memory required for data: 1520640128
I0813 16:40:58.933606  1670 layer_factory.hpp:77] Creating layer pool3
I0813 16:40:58.933611  1670 net.cpp:100] Creating Layer pool3
I0813 16:40:58.933614  1670 net.cpp:434] pool3 <- conv3_3
I0813 16:40:58.933617  1670 net.cpp:408] pool3 -> pool3
I0813 16:40:58.933646  1670 net.cpp:150] Setting up pool3
I0813 16:40:58.933651  1670 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0813 16:40:58.933653  1670 net.cpp:165] Memory required for data: 1532469376
I0813 16:40:58.933655  1670 layer_factory.hpp:77] Creating layer conv4_1
I0813 16:40:58.933661  1670 net.cpp:100] Creating Layer conv4_1
I0813 16:40:58.933663  1670 net.cpp:434] conv4_1 <- pool3
I0813 16:40:58.933667  1670 net.cpp:408] conv4_1 -> conv4_1
I0813 16:40:58.939519  1670 net.cpp:150] Setting up conv4_1
I0813 16:40:58.939535  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.939538  1670 net.cpp:165] Memory required for data: 1556127872
I0813 16:40:58.939545  1670 layer_factory.hpp:77] Creating layer relu4_1
I0813 16:40:58.939550  1670 net.cpp:100] Creating Layer relu4_1
I0813 16:40:58.939553  1670 net.cpp:434] relu4_1 <- conv4_1
I0813 16:40:58.939556  1670 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0813 16:40:58.939939  1670 net.cpp:150] Setting up relu4_1
I0813 16:40:58.939949  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.939950  1670 net.cpp:165] Memory required for data: 1579786368
I0813 16:40:58.939952  1670 layer_factory.hpp:77] Creating layer conv4_2
I0813 16:40:58.939960  1670 net.cpp:100] Creating Layer conv4_2
I0813 16:40:58.939963  1670 net.cpp:434] conv4_2 <- conv4_1
I0813 16:40:58.939968  1670 net.cpp:408] conv4_2 -> conv4_2
I0813 16:40:58.950296  1670 net.cpp:150] Setting up conv4_2
I0813 16:40:58.950328  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.950330  1670 net.cpp:165] Memory required for data: 1603444864
I0813 16:40:58.950340  1670 layer_factory.hpp:77] Creating layer relu4_2
I0813 16:40:58.950346  1670 net.cpp:100] Creating Layer relu4_2
I0813 16:40:58.950350  1670 net.cpp:434] relu4_2 <- conv4_2
I0813 16:40:58.950354  1670 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0813 16:40:58.950634  1670 net.cpp:150] Setting up relu4_2
I0813 16:40:58.950639  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.950657  1670 net.cpp:165] Memory required for data: 1627103360
I0813 16:40:58.950659  1670 layer_factory.hpp:77] Creating layer conv4_3
I0813 16:40:58.950666  1670 net.cpp:100] Creating Layer conv4_3
I0813 16:40:58.950670  1670 net.cpp:434] conv4_3 <- conv4_2
I0813 16:40:58.950673  1670 net.cpp:408] conv4_3 -> conv4_3
I0813 16:40:58.960985  1670 net.cpp:150] Setting up conv4_3
I0813 16:40:58.961016  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.961019  1670 net.cpp:165] Memory required for data: 1650761856
I0813 16:40:58.961027  1670 layer_factory.hpp:77] Creating layer relu4_3
I0813 16:40:58.961033  1670 net.cpp:100] Creating Layer relu4_3
I0813 16:40:58.961037  1670 net.cpp:434] relu4_3 <- conv4_3
I0813 16:40:58.961041  1670 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0813 16:40:58.961441  1670 net.cpp:150] Setting up relu4_3
I0813 16:40:58.961448  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.961458  1670 net.cpp:165] Memory required for data: 1674420352
I0813 16:40:58.961462  1670 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0813 16:40:58.961467  1670 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0813 16:40:58.961468  1670 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0813 16:40:58.961472  1670 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0813 16:40:58.961477  1670 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0813 16:40:58.961506  1670 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0813 16:40:58.961510  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.961513  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:58.961514  1670 net.cpp:165] Memory required for data: 1721737344
I0813 16:40:58.961518  1670 layer_factory.hpp:77] Creating layer pool4
I0813 16:40:58.961522  1670 net.cpp:100] Creating Layer pool4
I0813 16:40:58.961525  1670 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0813 16:40:58.961529  1670 net.cpp:408] pool4 -> pool4
I0813 16:40:58.961553  1670 net.cpp:150] Setting up pool4
I0813 16:40:58.961558  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.961560  1670 net.cpp:165] Memory required for data: 1727651968
I0813 16:40:58.961561  1670 layer_factory.hpp:77] Creating layer conv5_1
I0813 16:40:58.961568  1670 net.cpp:100] Creating Layer conv5_1
I0813 16:40:58.961570  1670 net.cpp:434] conv5_1 <- pool4
I0813 16:40:58.961575  1670 net.cpp:408] conv5_1 -> conv5_1
I0813 16:40:58.972060  1670 net.cpp:150] Setting up conv5_1
I0813 16:40:58.972079  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.972080  1670 net.cpp:165] Memory required for data: 1733566592
I0813 16:40:58.972088  1670 layer_factory.hpp:77] Creating layer relu5_1
I0813 16:40:58.972095  1670 net.cpp:100] Creating Layer relu5_1
I0813 16:40:58.972098  1670 net.cpp:434] relu5_1 <- conv5_1
I0813 16:40:58.972102  1670 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0813 16:40:58.972373  1670 net.cpp:150] Setting up relu5_1
I0813 16:40:58.972380  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.972383  1670 net.cpp:165] Memory required for data: 1739481216
I0813 16:40:58.972384  1670 layer_factory.hpp:77] Creating layer conv5_2
I0813 16:40:58.972391  1670 net.cpp:100] Creating Layer conv5_2
I0813 16:40:58.972393  1670 net.cpp:434] conv5_2 <- conv5_1
I0813 16:40:58.972398  1670 net.cpp:408] conv5_2 -> conv5_2
I0813 16:40:58.982885  1670 net.cpp:150] Setting up conv5_2
I0813 16:40:58.982903  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.982906  1670 net.cpp:165] Memory required for data: 1745395840
I0813 16:40:58.982914  1670 layer_factory.hpp:77] Creating layer relu5_2
I0813 16:40:58.982920  1670 net.cpp:100] Creating Layer relu5_2
I0813 16:40:58.982923  1670 net.cpp:434] relu5_2 <- conv5_2
I0813 16:40:58.982926  1670 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0813 16:40:58.983196  1670 net.cpp:150] Setting up relu5_2
I0813 16:40:58.983202  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.983204  1670 net.cpp:165] Memory required for data: 1751310464
I0813 16:40:58.983206  1670 layer_factory.hpp:77] Creating layer conv5_3
I0813 16:40:58.983214  1670 net.cpp:100] Creating Layer conv5_3
I0813 16:40:58.983217  1670 net.cpp:434] conv5_3 <- conv5_2
I0813 16:40:58.983222  1670 net.cpp:408] conv5_3 -> conv5_3
I0813 16:40:58.993556  1670 net.cpp:150] Setting up conv5_3
I0813 16:40:58.993574  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.993577  1670 net.cpp:165] Memory required for data: 1757225088
I0813 16:40:58.993584  1670 layer_factory.hpp:77] Creating layer relu5_3
I0813 16:40:58.993594  1670 net.cpp:100] Creating Layer relu5_3
I0813 16:40:58.993597  1670 net.cpp:434] relu5_3 <- conv5_3
I0813 16:40:58.993602  1670 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0813 16:40:58.993999  1670 net.cpp:150] Setting up relu5_3
I0813 16:40:58.994021  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.994024  1670 net.cpp:165] Memory required for data: 1763139712
I0813 16:40:58.994035  1670 layer_factory.hpp:77] Creating layer pool5
I0813 16:40:58.994040  1670 net.cpp:100] Creating Layer pool5
I0813 16:40:58.994042  1670 net.cpp:434] pool5 <- conv5_3
I0813 16:40:58.994046  1670 net.cpp:408] pool5 -> pool5
I0813 16:40:58.994077  1670 net.cpp:150] Setting up pool5
I0813 16:40:58.994082  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:58.994084  1670 net.cpp:165] Memory required for data: 1769054336
I0813 16:40:58.994086  1670 layer_factory.hpp:77] Creating layer fc6
I0813 16:40:58.994092  1670 net.cpp:100] Creating Layer fc6
I0813 16:40:58.994094  1670 net.cpp:434] fc6 <- pool5
I0813 16:40:58.994098  1670 net.cpp:408] fc6 -> fc6
I0813 16:40:59.012306  1670 net.cpp:150] Setting up fc6
I0813 16:40:59.012323  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012326  1670 net.cpp:165] Memory required for data: 1780883584
I0813 16:40:59.012333  1670 layer_factory.hpp:77] Creating layer relu6
I0813 16:40:59.012339  1670 net.cpp:100] Creating Layer relu6
I0813 16:40:59.012342  1670 net.cpp:434] relu6 <- fc6
I0813 16:40:59.012347  1670 net.cpp:395] relu6 -> fc6 (in-place)
I0813 16:40:59.012676  1670 net.cpp:150] Setting up relu6
I0813 16:40:59.012682  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012698  1670 net.cpp:165] Memory required for data: 1792712832
I0813 16:40:59.012701  1670 layer_factory.hpp:77] Creating layer fc6_relu6_0_split
I0813 16:40:59.012706  1670 net.cpp:100] Creating Layer fc6_relu6_0_split
I0813 16:40:59.012707  1670 net.cpp:434] fc6_relu6_0_split <- fc6
I0813 16:40:59.012712  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_0
I0813 16:40:59.012717  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_1
I0813 16:40:59.012722  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_2
I0813 16:40:59.012728  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_3
I0813 16:40:59.012775  1670 net.cpp:150] Setting up fc6_relu6_0_split
I0813 16:40:59.012779  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012784  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012786  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012789  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.012791  1670 net.cpp:165] Memory required for data: 1840029824
I0813 16:40:59.012794  1670 layer_factory.hpp:77] Creating layer fc7
I0813 16:40:59.012801  1670 net.cpp:100] Creating Layer fc7
I0813 16:40:59.012804  1670 net.cpp:434] fc7 <- fc6_relu6_0_split_0
I0813 16:40:59.012809  1670 net.cpp:408] fc7 -> fc7
I0813 16:40:59.018115  1670 net.cpp:150] Setting up fc7
I0813 16:40:59.018127  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.018131  1670 net.cpp:165] Memory required for data: 1851859072
I0813 16:40:59.018137  1670 layer_factory.hpp:77] Creating layer relu7
I0813 16:40:59.018143  1670 net.cpp:100] Creating Layer relu7
I0813 16:40:59.018147  1670 net.cpp:434] relu7 <- fc7
I0813 16:40:59.018151  1670 net.cpp:395] relu7 -> fc7 (in-place)
I0813 16:40:59.018419  1670 net.cpp:150] Setting up relu7
I0813 16:40:59.018426  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.018429  1670 net.cpp:165] Memory required for data: 1863688320
I0813 16:40:59.018443  1670 layer_factory.hpp:77] Creating layer conv6_1
I0813 16:40:59.018450  1670 net.cpp:100] Creating Layer conv6_1
I0813 16:40:59.018453  1670 net.cpp:434] conv6_1 <- fc7
I0813 16:40:59.018457  1670 net.cpp:408] conv6_1 -> conv6_1
I0813 16:40:59.021075  1670 net.cpp:150] Setting up conv6_1
I0813 16:40:59.021097  1670 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0813 16:40:59.021100  1670 net.cpp:165] Memory required for data: 1866645632
I0813 16:40:59.021106  1670 layer_factory.hpp:77] Creating layer conv6_1_relu
I0813 16:40:59.021111  1670 net.cpp:100] Creating Layer conv6_1_relu
I0813 16:40:59.021113  1670 net.cpp:434] conv6_1_relu <- conv6_1
I0813 16:40:59.021116  1670 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0813 16:40:59.021392  1670 net.cpp:150] Setting up conv6_1_relu
I0813 16:40:59.021399  1670 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0813 16:40:59.021402  1670 net.cpp:165] Memory required for data: 1869602944
I0813 16:40:59.021404  1670 layer_factory.hpp:77] Creating layer conv6_2
I0813 16:40:59.021411  1670 net.cpp:100] Creating Layer conv6_2
I0813 16:40:59.021414  1670 net.cpp:434] conv6_2 <- conv6_1
I0813 16:40:59.021419  1670 net.cpp:408] conv6_2 -> conv6_2
I0813 16:40:59.027490  1670 net.cpp:150] Setting up conv6_2
I0813 16:40:59.027506  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.027508  1670 net.cpp:165] Memory required for data: 1871241344
I0813 16:40:59.027520  1670 layer_factory.hpp:77] Creating layer conv6_2_relu
I0813 16:40:59.027528  1670 net.cpp:100] Creating Layer conv6_2_relu
I0813 16:40:59.027532  1670 net.cpp:434] conv6_2_relu <- conv6_2
I0813 16:40:59.027536  1670 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0813 16:40:59.027930  1670 net.cpp:150] Setting up conv6_2_relu
I0813 16:40:59.027937  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.027940  1670 net.cpp:165] Memory required for data: 1872879744
I0813 16:40:59.027941  1670 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0813 16:40:59.027947  1670 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0813 16:40:59.027950  1670 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0813 16:40:59.027953  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0813 16:40:59.027958  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0813 16:40:59.027962  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0813 16:40:59.027966  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0813 16:40:59.028014  1670 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0813 16:40:59.028019  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.028035  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.028038  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.028039  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.028041  1670 net.cpp:165] Memory required for data: 1879433344
I0813 16:40:59.028059  1670 layer_factory.hpp:77] Creating layer conv7_1
I0813 16:40:59.028065  1670 net.cpp:100] Creating Layer conv7_1
I0813 16:40:59.028067  1670 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0813 16:40:59.028072  1670 net.cpp:408] conv7_1 -> conv7_1
I0813 16:40:59.029449  1670 net.cpp:150] Setting up conv7_1
I0813 16:40:59.029458  1670 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0813 16:40:59.029459  1670 net.cpp:165] Memory required for data: 1879842944
I0813 16:40:59.029464  1670 layer_factory.hpp:77] Creating layer conv7_1_relu
I0813 16:40:59.029467  1670 net.cpp:100] Creating Layer conv7_1_relu
I0813 16:40:59.029469  1670 net.cpp:434] conv7_1_relu <- conv7_1
I0813 16:40:59.029474  1670 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0813 16:40:59.029737  1670 net.cpp:150] Setting up conv7_1_relu
I0813 16:40:59.029744  1670 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0813 16:40:59.029747  1670 net.cpp:165] Memory required for data: 1880252544
I0813 16:40:59.029748  1670 layer_factory.hpp:77] Creating layer conv7_2
I0813 16:40:59.029754  1670 net.cpp:100] Creating Layer conv7_2
I0813 16:40:59.029757  1670 net.cpp:434] conv7_2 <- conv7_1
I0813 16:40:59.029762  1670 net.cpp:408] conv7_2 -> conv7_2
I0813 16:40:59.032330  1670 net.cpp:150] Setting up conv7_2
I0813 16:40:59.032353  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032356  1670 net.cpp:165] Memory required for data: 1880457344
I0813 16:40:59.032361  1670 layer_factory.hpp:77] Creating layer conv7_2_relu
I0813 16:40:59.032366  1670 net.cpp:100] Creating Layer conv7_2_relu
I0813 16:40:59.032368  1670 net.cpp:434] conv7_2_relu <- conv7_2
I0813 16:40:59.032374  1670 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0813 16:40:59.032795  1670 net.cpp:150] Setting up conv7_2_relu
I0813 16:40:59.032809  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032826  1670 net.cpp:165] Memory required for data: 1880662144
I0813 16:40:59.032829  1670 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0813 16:40:59.032833  1670 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0813 16:40:59.032835  1670 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0813 16:40:59.032841  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0813 16:40:59.032846  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0813 16:40:59.032851  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0813 16:40:59.032856  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0813 16:40:59.032903  1670 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0813 16:40:59.032907  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032910  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032912  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032915  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.032917  1670 net.cpp:165] Memory required for data: 1881481344
I0813 16:40:59.032919  1670 layer_factory.hpp:77] Creating layer conv8_1
I0813 16:40:59.032925  1670 net.cpp:100] Creating Layer conv8_1
I0813 16:40:59.032927  1670 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0813 16:40:59.032932  1670 net.cpp:408] conv8_1 -> conv8_1
I0813 16:40:59.034279  1670 net.cpp:150] Setting up conv8_1
I0813 16:40:59.034287  1670 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0813 16:40:59.034303  1670 net.cpp:165] Memory required for data: 1881583744
I0813 16:40:59.034309  1670 layer_factory.hpp:77] Creating layer conv8_1_relu
I0813 16:40:59.034312  1670 net.cpp:100] Creating Layer conv8_1_relu
I0813 16:40:59.034315  1670 net.cpp:434] conv8_1_relu <- conv8_1
I0813 16:40:59.034320  1670 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0813 16:40:59.034587  1670 net.cpp:150] Setting up conv8_1_relu
I0813 16:40:59.034593  1670 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0813 16:40:59.034595  1670 net.cpp:165] Memory required for data: 1881686144
I0813 16:40:59.034597  1670 layer_factory.hpp:77] Creating layer conv8_2
I0813 16:40:59.034603  1670 net.cpp:100] Creating Layer conv8_2
I0813 16:40:59.034605  1670 net.cpp:434] conv8_2 <- conv8_1
I0813 16:40:59.034610  1670 net.cpp:408] conv8_2 -> conv8_2
I0813 16:40:59.037346  1670 net.cpp:150] Setting up conv8_2
I0813 16:40:59.037370  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037374  1670 net.cpp:165] Memory required for data: 1881759872
I0813 16:40:59.037379  1670 layer_factory.hpp:77] Creating layer conv8_2_relu
I0813 16:40:59.037384  1670 net.cpp:100] Creating Layer conv8_2_relu
I0813 16:40:59.037386  1670 net.cpp:434] conv8_2_relu <- conv8_2
I0813 16:40:59.037389  1670 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0813 16:40:59.037667  1670 net.cpp:150] Setting up conv8_2_relu
I0813 16:40:59.037672  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037674  1670 net.cpp:165] Memory required for data: 1881833600
I0813 16:40:59.037678  1670 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0813 16:40:59.037681  1670 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0813 16:40:59.037683  1670 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0813 16:40:59.037688  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0813 16:40:59.037694  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0813 16:40:59.037698  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0813 16:40:59.037701  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0813 16:40:59.037750  1670 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0813 16:40:59.037755  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037758  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037768  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037770  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.037773  1670 net.cpp:165] Memory required for data: 1882128512
I0813 16:40:59.037775  1670 layer_factory.hpp:77] Creating layer conv9_1
I0813 16:40:59.037781  1670 net.cpp:100] Creating Layer conv9_1
I0813 16:40:59.037784  1670 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0813 16:40:59.037789  1670 net.cpp:408] conv9_1 -> conv9_1
I0813 16:40:59.039007  1670 net.cpp:150] Setting up conv9_1
I0813 16:40:59.039016  1670 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0813 16:40:59.039018  1670 net.cpp:165] Memory required for data: 1882165376
I0813 16:40:59.039023  1670 layer_factory.hpp:77] Creating layer conv9_1_relu
I0813 16:40:59.039027  1670 net.cpp:100] Creating Layer conv9_1_relu
I0813 16:40:59.039029  1670 net.cpp:434] conv9_1_relu <- conv9_1
I0813 16:40:59.039033  1670 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0813 16:40:59.039417  1670 net.cpp:150] Setting up conv9_1_relu
I0813 16:40:59.039427  1670 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0813 16:40:59.039428  1670 net.cpp:165] Memory required for data: 1882202240
I0813 16:40:59.039430  1670 layer_factory.hpp:77] Creating layer conv9_2
I0813 16:40:59.039436  1670 net.cpp:100] Creating Layer conv9_2
I0813 16:40:59.039439  1670 net.cpp:434] conv9_2 <- conv9_1
I0813 16:40:59.039443  1670 net.cpp:408] conv9_2 -> conv9_2
I0813 16:40:59.042037  1670 net.cpp:150] Setting up conv9_2
I0813 16:40:59.042045  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.042048  1670 net.cpp:165] Memory required for data: 1882210432
I0813 16:40:59.042052  1670 layer_factory.hpp:77] Creating layer conv9_2_relu
I0813 16:40:59.042057  1670 net.cpp:100] Creating Layer conv9_2_relu
I0813 16:40:59.042058  1670 net.cpp:434] conv9_2_relu <- conv9_2
I0813 16:40:59.042063  1670 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0813 16:40:59.042338  1670 net.cpp:150] Setting up conv9_2_relu
I0813 16:40:59.042345  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.042346  1670 net.cpp:165] Memory required for data: 1882218624
I0813 16:40:59.042348  1670 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0813 16:40:59.042352  1670 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0813 16:40:59.042354  1670 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0813 16:40:59.042358  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0813 16:40:59.042363  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0813 16:40:59.042367  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0813 16:40:59.042407  1670 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0813 16:40:59.042412  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.042414  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.042417  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.042418  1670 net.cpp:165] Memory required for data: 1882243200
I0813 16:40:59.042420  1670 layer_factory.hpp:77] Creating layer conv4_3_norm
I0813 16:40:59.042425  1670 net.cpp:100] Creating Layer conv4_3_norm
I0813 16:40:59.042428  1670 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0813 16:40:59.042431  1670 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0813 16:40:59.042554  1670 net.cpp:150] Setting up conv4_3_norm
I0813 16:40:59.042559  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.042562  1670 net.cpp:165] Memory required for data: 1905901696
I0813 16:40:59.042564  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.042567  1670 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.042570  1670 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0813 16:40:59.042573  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0813 16:40:59.042577  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0813 16:40:59.042588  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0813 16:40:59.042623  1670 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.042629  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.042630  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.042634  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.042635  1670 net.cpp:165] Memory required for data: 1976877184
I0813 16:40:59.042639  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0813 16:40:59.042644  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0813 16:40:59.042647  1670 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0813 16:40:59.042652  1670 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0813 16:40:59.044128  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0813 16:40:59.044137  1670 net.cpp:157] Top shape: 8 16 38 38 (184832)
I0813 16:40:59.044139  1670 net.cpp:165] Memory required for data: 1977616512
I0813 16:40:59.044144  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0813 16:40:59.044150  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0813 16:40:59.044153  1670 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0813 16:40:59.044157  1670 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0813 16:40:59.044239  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0813 16:40:59.044243  1670 net.cpp:157] Top shape: 8 38 38 16 (184832)
I0813 16:40:59.044246  1670 net.cpp:165] Memory required for data: 1978355840
I0813 16:40:59.044248  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0813 16:40:59.044253  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0813 16:40:59.044255  1670 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0813 16:40:59.044260  1670 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0813 16:40:59.044284  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0813 16:40:59.044289  1670 net.cpp:157] Top shape: 8 23104 (184832)
I0813 16:40:59.044292  1670 net.cpp:165] Memory required for data: 1979095168
I0813 16:40:59.044294  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0813 16:40:59.044304  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0813 16:40:59.044308  1670 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0813 16:40:59.044312  1670 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0813 16:40:59.047459  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0813 16:40:59.047471  1670 net.cpp:157] Top shape: 8 92 38 38 (1062784)
I0813 16:40:59.047473  1670 net.cpp:165] Memory required for data: 1983346304
I0813 16:40:59.047478  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0813 16:40:59.047485  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0813 16:40:59.047488  1670 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0813 16:40:59.047493  1670 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0813 16:40:59.047571  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0813 16:40:59.047576  1670 net.cpp:157] Top shape: 8 38 38 92 (1062784)
I0813 16:40:59.047578  1670 net.cpp:165] Memory required for data: 1987597440
I0813 16:40:59.047581  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0813 16:40:59.047585  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0813 16:40:59.047586  1670 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0813 16:40:59.047590  1670 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0813 16:40:59.047608  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0813 16:40:59.047613  1670 net.cpp:157] Top shape: 8 132848 (1062784)
I0813 16:40:59.047616  1670 net.cpp:165] Memory required for data: 1991848576
I0813 16:40:59.047626  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0813 16:40:59.047631  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0813 16:40:59.047632  1670 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0813 16:40:59.047636  1670 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0813 16:40:59.047639  1670 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0813 16:40:59.047662  1670 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0813 16:40:59.047667  1670 net.cpp:157] Top shape: 1 2 23104 (46208)
I0813 16:40:59.047667  1670 net.cpp:165] Memory required for data: 1992033408
I0813 16:40:59.047669  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc
I0813 16:40:59.047677  1670 net.cpp:100] Creating Layer fc6_mbox_loc
I0813 16:40:59.047678  1670 net.cpp:434] fc6_mbox_loc <- fc6_relu6_0_split_1
I0813 16:40:59.047683  1670 net.cpp:408] fc6_mbox_loc -> fc6_mbox_loc
I0813 16:40:59.049650  1670 net.cpp:150] Setting up fc6_mbox_loc
I0813 16:40:59.049659  1670 net.cpp:157] Top shape: 8 24 19 19 (69312)
I0813 16:40:59.049661  1670 net.cpp:165] Memory required for data: 1992310656
I0813 16:40:59.049666  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc_perm
I0813 16:40:59.049670  1670 net.cpp:100] Creating Layer fc6_mbox_loc_perm
I0813 16:40:59.049674  1670 net.cpp:434] fc6_mbox_loc_perm <- fc6_mbox_loc
I0813 16:40:59.049677  1670 net.cpp:408] fc6_mbox_loc_perm -> fc6_mbox_loc_perm
I0813 16:40:59.049755  1670 net.cpp:150] Setting up fc6_mbox_loc_perm
I0813 16:40:59.049760  1670 net.cpp:157] Top shape: 8 19 19 24 (69312)
I0813 16:40:59.049763  1670 net.cpp:165] Memory required for data: 1992587904
I0813 16:40:59.049765  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc_flat
I0813 16:40:59.049768  1670 net.cpp:100] Creating Layer fc6_mbox_loc_flat
I0813 16:40:59.049770  1670 net.cpp:434] fc6_mbox_loc_flat <- fc6_mbox_loc_perm
I0813 16:40:59.049774  1670 net.cpp:408] fc6_mbox_loc_flat -> fc6_mbox_loc_flat
I0813 16:40:59.049790  1670 net.cpp:150] Setting up fc6_mbox_loc_flat
I0813 16:40:59.049794  1670 net.cpp:157] Top shape: 8 8664 (69312)
I0813 16:40:59.049795  1670 net.cpp:165] Memory required for data: 1992865152
I0813 16:40:59.049798  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf
I0813 16:40:59.049806  1670 net.cpp:100] Creating Layer fc6_mbox_conf
I0813 16:40:59.049808  1670 net.cpp:434] fc6_mbox_conf <- fc6_relu6_0_split_2
I0813 16:40:59.049813  1670 net.cpp:408] fc6_mbox_conf -> fc6_mbox_conf
I0813 16:40:59.055963  1670 net.cpp:150] Setting up fc6_mbox_conf
I0813 16:40:59.055979  1670 net.cpp:157] Top shape: 8 138 19 19 (398544)
I0813 16:40:59.055981  1670 net.cpp:165] Memory required for data: 1994459328
I0813 16:40:59.055989  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf_perm
I0813 16:40:59.055996  1670 net.cpp:100] Creating Layer fc6_mbox_conf_perm
I0813 16:40:59.055999  1670 net.cpp:434] fc6_mbox_conf_perm <- fc6_mbox_conf
I0813 16:40:59.056005  1670 net.cpp:408] fc6_mbox_conf_perm -> fc6_mbox_conf_perm
I0813 16:40:59.056083  1670 net.cpp:150] Setting up fc6_mbox_conf_perm
I0813 16:40:59.056088  1670 net.cpp:157] Top shape: 8 19 19 138 (398544)
I0813 16:40:59.056090  1670 net.cpp:165] Memory required for data: 1996053504
I0813 16:40:59.056092  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf_flat
I0813 16:40:59.056097  1670 net.cpp:100] Creating Layer fc6_mbox_conf_flat
I0813 16:40:59.056099  1670 net.cpp:434] fc6_mbox_conf_flat <- fc6_mbox_conf_perm
I0813 16:40:59.056103  1670 net.cpp:408] fc6_mbox_conf_flat -> fc6_mbox_conf_flat
I0813 16:40:59.056121  1670 net.cpp:150] Setting up fc6_mbox_conf_flat
I0813 16:40:59.056125  1670 net.cpp:157] Top shape: 8 49818 (398544)
I0813 16:40:59.056128  1670 net.cpp:165] Memory required for data: 1997647680
I0813 16:40:59.056129  1670 layer_factory.hpp:77] Creating layer fc6_mbox_priorbox
I0813 16:40:59.056134  1670 net.cpp:100] Creating Layer fc6_mbox_priorbox
I0813 16:40:59.056136  1670 net.cpp:434] fc6_mbox_priorbox <- fc6_relu6_0_split_3
I0813 16:40:59.056147  1670 net.cpp:434] fc6_mbox_priorbox <- data_data_0_split_2
I0813 16:40:59.056152  1670 net.cpp:408] fc6_mbox_priorbox -> fc6_mbox_priorbox
I0813 16:40:59.056174  1670 net.cpp:150] Setting up fc6_mbox_priorbox
I0813 16:40:59.056177  1670 net.cpp:157] Top shape: 1 2 8664 (17328)
I0813 16:40:59.056180  1670 net.cpp:165] Memory required for data: 1997716992
I0813 16:40:59.056182  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0813 16:40:59.056188  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0813 16:40:59.056191  1670 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0813 16:40:59.056196  1670 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0813 16:40:59.057824  1670 net.cpp:150] Setting up conv6_2_mbox_loc
I0813 16:40:59.057833  1670 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0813 16:40:59.057837  1670 net.cpp:165] Memory required for data: 1997793792
I0813 16:40:59.057842  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0813 16:40:59.057847  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0813 16:40:59.057850  1670 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0813 16:40:59.057855  1670 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0813 16:40:59.057935  1670 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0813 16:40:59.057940  1670 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0813 16:40:59.057943  1670 net.cpp:165] Memory required for data: 1997870592
I0813 16:40:59.057945  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0813 16:40:59.057950  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0813 16:40:59.057952  1670 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0813 16:40:59.057955  1670 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0813 16:40:59.057972  1670 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0813 16:40:59.057977  1670 net.cpp:157] Top shape: 8 2400 (19200)
I0813 16:40:59.057979  1670 net.cpp:165] Memory required for data: 1997947392
I0813 16:40:59.057981  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0813 16:40:59.057987  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0813 16:40:59.057991  1670 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0813 16:40:59.057994  1670 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0813 16:40:59.061909  1670 net.cpp:150] Setting up conv6_2_mbox_conf
I0813 16:40:59.061921  1670 net.cpp:157] Top shape: 8 138 10 10 (110400)
I0813 16:40:59.061924  1670 net.cpp:165] Memory required for data: 1998388992
I0813 16:40:59.061930  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0813 16:40:59.061936  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0813 16:40:59.061939  1670 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0813 16:40:59.061945  1670 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0813 16:40:59.062028  1670 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0813 16:40:59.062033  1670 net.cpp:157] Top shape: 8 10 10 138 (110400)
I0813 16:40:59.062036  1670 net.cpp:165] Memory required for data: 1998830592
I0813 16:40:59.062038  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0813 16:40:59.062043  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0813 16:40:59.062047  1670 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0813 16:40:59.062049  1670 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0813 16:40:59.062068  1670 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0813 16:40:59.062072  1670 net.cpp:157] Top shape: 8 13800 (110400)
I0813 16:40:59.062074  1670 net.cpp:165] Memory required for data: 1999272192
I0813 16:40:59.062077  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0813 16:40:59.062083  1670 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0813 16:40:59.062085  1670 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0813 16:40:59.062088  1670 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0813 16:40:59.062099  1670 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0813 16:40:59.062121  1670 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0813 16:40:59.062125  1670 net.cpp:157] Top shape: 1 2 2400 (4800)
I0813 16:40:59.062129  1670 net.cpp:165] Memory required for data: 1999291392
I0813 16:40:59.062130  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0813 16:40:59.062137  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0813 16:40:59.062140  1670 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0813 16:40:59.062145  1670 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0813 16:40:59.063613  1670 net.cpp:150] Setting up conv7_2_mbox_loc
I0813 16:40:59.063622  1670 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0813 16:40:59.063624  1670 net.cpp:165] Memory required for data: 1999310592
I0813 16:40:59.063629  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0813 16:40:59.063637  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0813 16:40:59.063639  1670 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0813 16:40:59.063643  1670 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0813 16:40:59.063724  1670 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0813 16:40:59.063729  1670 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0813 16:40:59.063730  1670 net.cpp:165] Memory required for data: 1999329792
I0813 16:40:59.063732  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0813 16:40:59.063736  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0813 16:40:59.063738  1670 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0813 16:40:59.063742  1670 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0813 16:40:59.063761  1670 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0813 16:40:59.063766  1670 net.cpp:157] Top shape: 8 600 (4800)
I0813 16:40:59.063767  1670 net.cpp:165] Memory required for data: 1999348992
I0813 16:40:59.063769  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0813 16:40:59.063776  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0813 16:40:59.063778  1670 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0813 16:40:59.063782  1670 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0813 16:40:59.066493  1670 net.cpp:150] Setting up conv7_2_mbox_conf
I0813 16:40:59.066503  1670 net.cpp:157] Top shape: 8 138 5 5 (27600)
I0813 16:40:59.066505  1670 net.cpp:165] Memory required for data: 1999459392
I0813 16:40:59.066510  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0813 16:40:59.066515  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0813 16:40:59.066519  1670 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0813 16:40:59.066522  1670 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0813 16:40:59.066602  1670 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0813 16:40:59.066609  1670 net.cpp:157] Top shape: 8 5 5 138 (27600)
I0813 16:40:59.066612  1670 net.cpp:165] Memory required for data: 1999569792
I0813 16:40:59.066613  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0813 16:40:59.066617  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0813 16:40:59.066619  1670 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0813 16:40:59.066622  1670 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0813 16:40:59.066639  1670 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0813 16:40:59.066643  1670 net.cpp:157] Top shape: 8 3450 (27600)
I0813 16:40:59.066645  1670 net.cpp:165] Memory required for data: 1999680192
I0813 16:40:59.066648  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0813 16:40:59.066653  1670 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0813 16:40:59.066656  1670 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0813 16:40:59.066659  1670 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0813 16:40:59.066663  1670 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0813 16:40:59.066690  1670 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0813 16:40:59.066694  1670 net.cpp:157] Top shape: 1 2 600 (1200)
I0813 16:40:59.066697  1670 net.cpp:165] Memory required for data: 1999684992
I0813 16:40:59.066699  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0813 16:40:59.066705  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0813 16:40:59.066709  1670 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0813 16:40:59.066715  1670 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0813 16:40:59.067989  1670 net.cpp:150] Setting up conv8_2_mbox_loc
I0813 16:40:59.067997  1670 net.cpp:157] Top shape: 8 16 3 3 (1152)
I0813 16:40:59.067999  1670 net.cpp:165] Memory required for data: 1999689600
I0813 16:40:59.068011  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0813 16:40:59.068015  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0813 16:40:59.068018  1670 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0813 16:40:59.068023  1670 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0813 16:40:59.068102  1670 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0813 16:40:59.068107  1670 net.cpp:157] Top shape: 8 3 3 16 (1152)
I0813 16:40:59.068109  1670 net.cpp:165] Memory required for data: 1999694208
I0813 16:40:59.068111  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0813 16:40:59.068116  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0813 16:40:59.068119  1670 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0813 16:40:59.068122  1670 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0813 16:40:59.068140  1670 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0813 16:40:59.068145  1670 net.cpp:157] Top shape: 8 144 (1152)
I0813 16:40:59.068146  1670 net.cpp:165] Memory required for data: 1999698816
I0813 16:40:59.068148  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0813 16:40:59.068154  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0813 16:40:59.068157  1670 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0813 16:40:59.068161  1670 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0813 16:40:59.070118  1670 net.cpp:150] Setting up conv8_2_mbox_conf
I0813 16:40:59.070127  1670 net.cpp:157] Top shape: 8 92 3 3 (6624)
I0813 16:40:59.070129  1670 net.cpp:165] Memory required for data: 1999725312
I0813 16:40:59.070134  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0813 16:40:59.070138  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0813 16:40:59.070142  1670 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0813 16:40:59.070147  1670 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0813 16:40:59.070228  1670 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0813 16:40:59.070233  1670 net.cpp:157] Top shape: 8 3 3 92 (6624)
I0813 16:40:59.070235  1670 net.cpp:165] Memory required for data: 1999751808
I0813 16:40:59.070238  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0813 16:40:59.070242  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0813 16:40:59.070245  1670 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0813 16:40:59.070248  1670 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0813 16:40:59.070266  1670 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0813 16:40:59.070271  1670 net.cpp:157] Top shape: 8 828 (6624)
I0813 16:40:59.070272  1670 net.cpp:165] Memory required for data: 1999778304
I0813 16:40:59.070274  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0813 16:40:59.070279  1670 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0813 16:40:59.070282  1670 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0813 16:40:59.070286  1670 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0813 16:40:59.070291  1670 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0813 16:40:59.070310  1670 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0813 16:40:59.070315  1670 net.cpp:157] Top shape: 1 2 144 (288)
I0813 16:40:59.070323  1670 net.cpp:165] Memory required for data: 1999779456
I0813 16:40:59.070325  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0813 16:40:59.070331  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0813 16:40:59.070334  1670 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0813 16:40:59.070339  1670 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0813 16:40:59.071727  1670 net.cpp:150] Setting up conv9_2_mbox_loc
I0813 16:40:59.071734  1670 net.cpp:157] Top shape: 8 16 1 1 (128)
I0813 16:40:59.071738  1670 net.cpp:165] Memory required for data: 1999779968
I0813 16:40:59.071741  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0813 16:40:59.071745  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0813 16:40:59.071748  1670 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0813 16:40:59.071753  1670 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0813 16:40:59.071831  1670 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0813 16:40:59.071836  1670 net.cpp:157] Top shape: 8 1 1 16 (128)
I0813 16:40:59.071838  1670 net.cpp:165] Memory required for data: 1999780480
I0813 16:40:59.071841  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0813 16:40:59.071843  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0813 16:40:59.071846  1670 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0813 16:40:59.071849  1670 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0813 16:40:59.071867  1670 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0813 16:40:59.071871  1670 net.cpp:157] Top shape: 8 16 (128)
I0813 16:40:59.071872  1670 net.cpp:165] Memory required for data: 1999780992
I0813 16:40:59.071874  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0813 16:40:59.071880  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0813 16:40:59.071883  1670 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0813 16:40:59.071887  1670 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0813 16:40:59.073967  1670 net.cpp:150] Setting up conv9_2_mbox_conf
I0813 16:40:59.073976  1670 net.cpp:157] Top shape: 8 92 1 1 (736)
I0813 16:40:59.073978  1670 net.cpp:165] Memory required for data: 1999783936
I0813 16:40:59.073982  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0813 16:40:59.073987  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0813 16:40:59.073990  1670 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0813 16:40:59.073994  1670 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0813 16:40:59.074075  1670 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0813 16:40:59.074080  1670 net.cpp:157] Top shape: 8 1 1 92 (736)
I0813 16:40:59.074082  1670 net.cpp:165] Memory required for data: 1999786880
I0813 16:40:59.074084  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0813 16:40:59.074088  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0813 16:40:59.074090  1670 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0813 16:40:59.074095  1670 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0813 16:40:59.074111  1670 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0813 16:40:59.074115  1670 net.cpp:157] Top shape: 8 92 (736)
I0813 16:40:59.074116  1670 net.cpp:165] Memory required for data: 1999789824
I0813 16:40:59.074120  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0813 16:40:59.074123  1670 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0813 16:40:59.074126  1670 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0813 16:40:59.074129  1670 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0813 16:40:59.074134  1670 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0813 16:40:59.074152  1670 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0813 16:40:59.074156  1670 net.cpp:157] Top shape: 1 2 16 (32)
I0813 16:40:59.074158  1670 net.cpp:165] Memory required for data: 1999789952
I0813 16:40:59.074167  1670 layer_factory.hpp:77] Creating layer mbox_loc
I0813 16:40:59.074172  1670 net.cpp:100] Creating Layer mbox_loc
I0813 16:40:59.074175  1670 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0813 16:40:59.074178  1670 net.cpp:434] mbox_loc <- fc6_mbox_loc_flat
I0813 16:40:59.074182  1670 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0813 16:40:59.074184  1670 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0813 16:40:59.074187  1670 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0813 16:40:59.074189  1670 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0813 16:40:59.074193  1670 net.cpp:408] mbox_loc -> mbox_loc
I0813 16:40:59.074214  1670 net.cpp:150] Setting up mbox_loc
I0813 16:40:59.074218  1670 net.cpp:157] Top shape: 8 34928 (279424)
I0813 16:40:59.074220  1670 net.cpp:165] Memory required for data: 2000907648
I0813 16:40:59.074223  1670 layer_factory.hpp:77] Creating layer mbox_conf
I0813 16:40:59.074226  1670 net.cpp:100] Creating Layer mbox_conf
I0813 16:40:59.074229  1670 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0813 16:40:59.074231  1670 net.cpp:434] mbox_conf <- fc6_mbox_conf_flat
I0813 16:40:59.074234  1670 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0813 16:40:59.074237  1670 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0813 16:40:59.074239  1670 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0813 16:40:59.074241  1670 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0813 16:40:59.074245  1670 net.cpp:408] mbox_conf -> mbox_conf
I0813 16:40:59.074262  1670 net.cpp:150] Setting up mbox_conf
I0813 16:40:59.074266  1670 net.cpp:157] Top shape: 8 200836 (1606688)
I0813 16:40:59.074268  1670 net.cpp:165] Memory required for data: 2007334400
I0813 16:40:59.074270  1670 layer_factory.hpp:77] Creating layer mbox_priorbox
I0813 16:40:59.074273  1670 net.cpp:100] Creating Layer mbox_priorbox
I0813 16:40:59.074275  1670 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0813 16:40:59.074277  1670 net.cpp:434] mbox_priorbox <- fc6_mbox_priorbox
I0813 16:40:59.074280  1670 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0813 16:40:59.074282  1670 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0813 16:40:59.074285  1670 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0813 16:40:59.074288  1670 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0813 16:40:59.074292  1670 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0813 16:40:59.074309  1670 net.cpp:150] Setting up mbox_priorbox
I0813 16:40:59.074314  1670 net.cpp:157] Top shape: 1 2 34928 (69856)
I0813 16:40:59.074316  1670 net.cpp:165] Memory required for data: 2007613824
I0813 16:40:59.074318  1670 layer_factory.hpp:77] Creating layer mbox_loss
I0813 16:40:59.074323  1670 net.cpp:100] Creating Layer mbox_loss
I0813 16:40:59.074326  1670 net.cpp:434] mbox_loss <- mbox_loc
I0813 16:40:59.074328  1670 net.cpp:434] mbox_loss <- mbox_conf
I0813 16:40:59.074331  1670 net.cpp:434] mbox_loss <- mbox_priorbox
I0813 16:40:59.074333  1670 net.cpp:434] mbox_loss <- label
I0813 16:40:59.074337  1670 net.cpp:408] mbox_loss -> mbox_loss
I0813 16:40:59.074381  1670 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0813 16:40:59.074452  1670 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0813 16:40:59.074460  1670 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0813 16:40:59.074823  1670 net.cpp:150] Setting up mbox_loss
I0813 16:40:59.074831  1670 net.cpp:157] Top shape: (1)
I0813 16:40:59.074833  1670 net.cpp:160]     with loss weight 1
I0813 16:40:59.074846  1670 net.cpp:165] Memory required for data: 2007613828
I0813 16:40:59.074849  1670 net.cpp:226] mbox_loss needs backward computation.
I0813 16:40:59.074854  1670 net.cpp:228] mbox_priorbox does not need backward computation.
I0813 16:40:59.074858  1670 net.cpp:226] mbox_conf needs backward computation.
I0813 16:40:59.074863  1670 net.cpp:226] mbox_loc needs backward computation.
I0813 16:40:59.074867  1670 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.074870  1670 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0813 16:40:59.074878  1670 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0813 16:40:59.074880  1670 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0813 16:40:59.074883  1670 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0813 16:40:59.074885  1670 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0813 16:40:59.074887  1670 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0813 16:40:59.074889  1670 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.074893  1670 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0813 16:40:59.074896  1670 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0813 16:40:59.074898  1670 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0813 16:40:59.074901  1670 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0813 16:40:59.074903  1670 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0813 16:40:59.074905  1670 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0813 16:40:59.074908  1670 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.074910  1670 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0813 16:40:59.074913  1670 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0813 16:40:59.074915  1670 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0813 16:40:59.074918  1670 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0813 16:40:59.074920  1670 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0813 16:40:59.074923  1670 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0813 16:40:59.074924  1670 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.074928  1670 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0813 16:40:59.074930  1670 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0813 16:40:59.074934  1670 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0813 16:40:59.074935  1670 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0813 16:40:59.074937  1670 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0813 16:40:59.074940  1670 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0813 16:40:59.074942  1670 net.cpp:228] fc6_mbox_priorbox does not need backward computation.
I0813 16:40:59.074945  1670 net.cpp:226] fc6_mbox_conf_flat needs backward computation.
I0813 16:40:59.074947  1670 net.cpp:226] fc6_mbox_conf_perm needs backward computation.
I0813 16:40:59.074949  1670 net.cpp:226] fc6_mbox_conf needs backward computation.
I0813 16:40:59.074952  1670 net.cpp:226] fc6_mbox_loc_flat needs backward computation.
I0813 16:40:59.074954  1670 net.cpp:226] fc6_mbox_loc_perm needs backward computation.
I0813 16:40:59.074959  1670 net.cpp:226] fc6_mbox_loc needs backward computation.
I0813 16:40:59.074960  1670 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0813 16:40:59.074964  1670 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0813 16:40:59.074965  1670 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0813 16:40:59.074968  1670 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0813 16:40:59.074970  1670 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0813 16:40:59.074973  1670 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0813 16:40:59.074975  1670 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0813 16:40:59.074977  1670 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0813 16:40:59.074980  1670 net.cpp:226] conv4_3_norm needs backward computation.
I0813 16:40:59.074982  1670 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0813 16:40:59.074985  1670 net.cpp:226] conv9_2_relu needs backward computation.
I0813 16:40:59.074987  1670 net.cpp:226] conv9_2 needs backward computation.
I0813 16:40:59.074993  1670 net.cpp:226] conv9_1_relu needs backward computation.
I0813 16:40:59.074996  1670 net.cpp:226] conv9_1 needs backward computation.
I0813 16:40:59.074998  1670 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0813 16:40:59.075001  1670 net.cpp:226] conv8_2_relu needs backward computation.
I0813 16:40:59.075002  1670 net.cpp:226] conv8_2 needs backward computation.
I0813 16:40:59.075006  1670 net.cpp:226] conv8_1_relu needs backward computation.
I0813 16:40:59.075007  1670 net.cpp:226] conv8_1 needs backward computation.
I0813 16:40:59.075011  1670 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0813 16:40:59.075012  1670 net.cpp:226] conv7_2_relu needs backward computation.
I0813 16:40:59.075014  1670 net.cpp:226] conv7_2 needs backward computation.
I0813 16:40:59.075016  1670 net.cpp:226] conv7_1_relu needs backward computation.
I0813 16:40:59.075019  1670 net.cpp:226] conv7_1 needs backward computation.
I0813 16:40:59.075021  1670 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0813 16:40:59.075024  1670 net.cpp:226] conv6_2_relu needs backward computation.
I0813 16:40:59.075026  1670 net.cpp:226] conv6_2 needs backward computation.
I0813 16:40:59.075028  1670 net.cpp:226] conv6_1_relu needs backward computation.
I0813 16:40:59.075031  1670 net.cpp:226] conv6_1 needs backward computation.
I0813 16:40:59.075033  1670 net.cpp:226] relu7 needs backward computation.
I0813 16:40:59.075036  1670 net.cpp:226] fc7 needs backward computation.
I0813 16:40:59.075038  1670 net.cpp:226] fc6_relu6_0_split needs backward computation.
I0813 16:40:59.075040  1670 net.cpp:226] relu6 needs backward computation.
I0813 16:40:59.075042  1670 net.cpp:226] fc6 needs backward computation.
I0813 16:40:59.075044  1670 net.cpp:226] pool5 needs backward computation.
I0813 16:40:59.075047  1670 net.cpp:226] relu5_3 needs backward computation.
I0813 16:40:59.075049  1670 net.cpp:226] conv5_3 needs backward computation.
I0813 16:40:59.075052  1670 net.cpp:226] relu5_2 needs backward computation.
I0813 16:40:59.075053  1670 net.cpp:226] conv5_2 needs backward computation.
I0813 16:40:59.075057  1670 net.cpp:226] relu5_1 needs backward computation.
I0813 16:40:59.075058  1670 net.cpp:226] conv5_1 needs backward computation.
I0813 16:40:59.075060  1670 net.cpp:226] pool4 needs backward computation.
I0813 16:40:59.075062  1670 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0813 16:40:59.075065  1670 net.cpp:226] relu4_3 needs backward computation.
I0813 16:40:59.075067  1670 net.cpp:226] conv4_3 needs backward computation.
I0813 16:40:59.075070  1670 net.cpp:226] relu4_2 needs backward computation.
I0813 16:40:59.075071  1670 net.cpp:226] conv4_2 needs backward computation.
I0813 16:40:59.075074  1670 net.cpp:226] relu4_1 needs backward computation.
I0813 16:40:59.075076  1670 net.cpp:226] conv4_1 needs backward computation.
I0813 16:40:59.075078  1670 net.cpp:226] pool3 needs backward computation.
I0813 16:40:59.075080  1670 net.cpp:226] relu3_3 needs backward computation.
I0813 16:40:59.075083  1670 net.cpp:226] conv3_3 needs backward computation.
I0813 16:40:59.075085  1670 net.cpp:226] relu3_2 needs backward computation.
I0813 16:40:59.075088  1670 net.cpp:226] conv3_2 needs backward computation.
I0813 16:40:59.075089  1670 net.cpp:226] relu3_1 needs backward computation.
I0813 16:40:59.075091  1670 net.cpp:226] conv3_1 needs backward computation.
I0813 16:40:59.075093  1670 net.cpp:226] pool2 needs backward computation.
I0813 16:40:59.075096  1670 net.cpp:226] relu2_2 needs backward computation.
I0813 16:40:59.075099  1670 net.cpp:226] conv2_2 needs backward computation.
I0813 16:40:59.075101  1670 net.cpp:226] relu2_1 needs backward computation.
I0813 16:40:59.075103  1670 net.cpp:226] conv2_1 needs backward computation.
I0813 16:40:59.075105  1670 net.cpp:226] pool1 needs backward computation.
I0813 16:40:59.075107  1670 net.cpp:226] relu1_2 needs backward computation.
I0813 16:40:59.075114  1670 net.cpp:226] conv1_2 needs backward computation.
I0813 16:40:59.075115  1670 net.cpp:226] relu1_1 needs backward computation.
I0813 16:40:59.075117  1670 net.cpp:226] conv1_1 needs backward computation.
I0813 16:40:59.075120  1670 net.cpp:228] data_data_0_split does not need backward computation.
I0813 16:40:59.075124  1670 net.cpp:228] data does not need backward computation.
I0813 16:40:59.075125  1670 net.cpp:270] This network produces output mbox_loss
I0813 16:40:59.075176  1670 net.cpp:283] Network initialization done.
I0813 16:40:59.075808  1670 solver.cpp:196] Creating test net (#0) specified by test_net file: ./savedmodel/VGGNet/YUUAV/SSD_300x300/test.prototxt
I0813 16:40:59.076239  1670 net.cpp:58] Initializing net from parameters: 
name: "VGG_YUUAV_SSD_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "data/yuuav/yuuav_test_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/labelmap_yuuav.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc6_mbox_loc"
  type: "Convolution"
  bottom: "fc6"
  top: "fc6_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_mbox_loc_perm"
  type: "Permute"
  bottom: "fc6_mbox_loc"
  top: "fc6_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc6_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc6_mbox_loc_perm"
  top: "fc6_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc6_mbox_conf"
  type: "Convolution"
  bottom: "fc6"
  top: "fc6_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc6_mbox_conf_perm"
  type: "Permute"
  bottom: "fc6_mbox_conf"
  top: "fc6_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc6_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc6_mbox_conf_perm"
  top: "fc6_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc6_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc6"
  bottom: "data"
  top: "fc6_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 138
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 92
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc6_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc6_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc6_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 23
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 23
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "./data/results/YUUAV/SSD_300x300/Main"
      output_name_prefix: "comp4_det_test_"
      label_map_file: "data/labelmap_yuuav.prototxt"
      name_size_file: "data/test_name_size.txt"
      num_test_image: 5000
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 23
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/test_name_size.txt"
  }
}
I0813 16:40:59.076483  1670 layer_factory.hpp:77] Creating layer data
I0813 16:40:59.076596  1670 net.cpp:100] Creating Layer data
I0813 16:40:59.076612  1670 net.cpp:408] data -> data
I0813 16:40:59.076619  1670 net.cpp:408] data -> label
I0813 16:40:59.078198  1702 db_lmdb.cpp:35] Opened lmdb data/yuuav/yuuav_test_lmdb
I0813 16:40:59.081374  1670 annotated_data_layer.cpp:62] output data size: 8,3,300,300
I0813 16:40:59.089434  1670 net.cpp:150] Setting up data
I0813 16:40:59.089452  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089457  1670 net.cpp:157] Top shape: 1 1 1 8 (8)
I0813 16:40:59.089458  1670 net.cpp:165] Memory required for data: 8640032
I0813 16:40:59.089462  1670 layer_factory.hpp:77] Creating layer data_data_0_split
I0813 16:40:59.089471  1670 net.cpp:100] Creating Layer data_data_0_split
I0813 16:40:59.089474  1670 net.cpp:434] data_data_0_split <- data
I0813 16:40:59.089479  1670 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0813 16:40:59.089489  1670 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0813 16:40:59.089498  1670 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0813 16:40:59.089504  1670 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0813 16:40:59.089509  1670 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0813 16:40:59.089516  1670 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0813 16:40:59.089524  1670 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0813 16:40:59.089628  1670 net.cpp:150] Setting up data_data_0_split
I0813 16:40:59.089634  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089637  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089640  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089643  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089645  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089648  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089651  1670 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0813 16:40:59.089653  1670 net.cpp:165] Memory required for data: 69120032
I0813 16:40:59.089655  1670 layer_factory.hpp:77] Creating layer conv1_1
I0813 16:40:59.089665  1670 net.cpp:100] Creating Layer conv1_1
I0813 16:40:59.089669  1670 net.cpp:434] conv1_1 <- data_data_0_split_0
I0813 16:40:59.089684  1670 net.cpp:408] conv1_1 -> conv1_1
I0813 16:40:59.091136  1670 net.cpp:150] Setting up conv1_1
I0813 16:40:59.091145  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:59.091148  1670 net.cpp:165] Memory required for data: 253440032
I0813 16:40:59.091157  1670 layer_factory.hpp:77] Creating layer relu1_1
I0813 16:40:59.091163  1670 net.cpp:100] Creating Layer relu1_1
I0813 16:40:59.091168  1670 net.cpp:434] relu1_1 <- conv1_1
I0813 16:40:59.091173  1670 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0813 16:40:59.091589  1670 net.cpp:150] Setting up relu1_1
I0813 16:40:59.091598  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:59.091599  1670 net.cpp:165] Memory required for data: 437760032
I0813 16:40:59.091603  1670 layer_factory.hpp:77] Creating layer conv1_2
I0813 16:40:59.091614  1670 net.cpp:100] Creating Layer conv1_2
I0813 16:40:59.091616  1670 net.cpp:434] conv1_2 <- conv1_1
I0813 16:40:59.091621  1670 net.cpp:408] conv1_2 -> conv1_2
I0813 16:40:59.093628  1670 net.cpp:150] Setting up conv1_2
I0813 16:40:59.093637  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:59.093639  1670 net.cpp:165] Memory required for data: 622080032
I0813 16:40:59.093646  1670 layer_factory.hpp:77] Creating layer relu1_2
I0813 16:40:59.093649  1670 net.cpp:100] Creating Layer relu1_2
I0813 16:40:59.093652  1670 net.cpp:434] relu1_2 <- conv1_2
I0813 16:40:59.093655  1670 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0813 16:40:59.093932  1670 net.cpp:150] Setting up relu1_2
I0813 16:40:59.093940  1670 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0813 16:40:59.093941  1670 net.cpp:165] Memory required for data: 806400032
I0813 16:40:59.093943  1670 layer_factory.hpp:77] Creating layer pool1
I0813 16:40:59.093947  1670 net.cpp:100] Creating Layer pool1
I0813 16:40:59.093950  1670 net.cpp:434] pool1 <- conv1_2
I0813 16:40:59.093953  1670 net.cpp:408] pool1 -> pool1
I0813 16:40:59.093989  1670 net.cpp:150] Setting up pool1
I0813 16:40:59.093994  1670 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0813 16:40:59.093997  1670 net.cpp:165] Memory required for data: 852480032
I0813 16:40:59.093999  1670 layer_factory.hpp:77] Creating layer conv2_1
I0813 16:40:59.094005  1670 net.cpp:100] Creating Layer conv2_1
I0813 16:40:59.094007  1670 net.cpp:434] conv2_1 <- pool1
I0813 16:40:59.094012  1670 net.cpp:408] conv2_1 -> conv2_1
I0813 16:40:59.095542  1670 net.cpp:150] Setting up conv2_1
I0813 16:40:59.095551  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:59.095553  1670 net.cpp:165] Memory required for data: 944640032
I0813 16:40:59.095559  1670 layer_factory.hpp:77] Creating layer relu2_1
I0813 16:40:59.095567  1670 net.cpp:100] Creating Layer relu2_1
I0813 16:40:59.095571  1670 net.cpp:434] relu2_1 <- conv2_1
I0813 16:40:59.095577  1670 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0813 16:40:59.095855  1670 net.cpp:150] Setting up relu2_1
I0813 16:40:59.095862  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:59.095865  1670 net.cpp:165] Memory required for data: 1036800032
I0813 16:40:59.095867  1670 layer_factory.hpp:77] Creating layer conv2_2
I0813 16:40:59.095877  1670 net.cpp:100] Creating Layer conv2_2
I0813 16:40:59.095881  1670 net.cpp:434] conv2_2 <- conv2_1
I0813 16:40:59.095885  1670 net.cpp:408] conv2_2 -> conv2_2
I0813 16:40:59.097663  1670 net.cpp:150] Setting up conv2_2
I0813 16:40:59.097673  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:59.097676  1670 net.cpp:165] Memory required for data: 1128960032
I0813 16:40:59.097679  1670 layer_factory.hpp:77] Creating layer relu2_2
I0813 16:40:59.097683  1670 net.cpp:100] Creating Layer relu2_2
I0813 16:40:59.097687  1670 net.cpp:434] relu2_2 <- conv2_2
I0813 16:40:59.097689  1670 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0813 16:40:59.098093  1670 net.cpp:150] Setting up relu2_2
I0813 16:40:59.098101  1670 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0813 16:40:59.098104  1670 net.cpp:165] Memory required for data: 1221120032
I0813 16:40:59.098112  1670 layer_factory.hpp:77] Creating layer pool2
I0813 16:40:59.098119  1670 net.cpp:100] Creating Layer pool2
I0813 16:40:59.098120  1670 net.cpp:434] pool2 <- conv2_2
I0813 16:40:59.098124  1670 net.cpp:408] pool2 -> pool2
I0813 16:40:59.098162  1670 net.cpp:150] Setting up pool2
I0813 16:40:59.098168  1670 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0813 16:40:59.098170  1670 net.cpp:165] Memory required for data: 1244160032
I0813 16:40:59.098172  1670 layer_factory.hpp:77] Creating layer conv3_1
I0813 16:40:59.098177  1670 net.cpp:100] Creating Layer conv3_1
I0813 16:40:59.098179  1670 net.cpp:434] conv3_1 <- pool2
I0813 16:40:59.098184  1670 net.cpp:408] conv3_1 -> conv3_1
I0813 16:40:59.100894  1670 net.cpp:150] Setting up conv3_1
I0813 16:40:59.100906  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.100908  1670 net.cpp:165] Memory required for data: 1290240032
I0813 16:40:59.100916  1670 layer_factory.hpp:77] Creating layer relu3_1
I0813 16:40:59.100922  1670 net.cpp:100] Creating Layer relu3_1
I0813 16:40:59.100924  1670 net.cpp:434] relu3_1 <- conv3_1
I0813 16:40:59.100927  1670 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0813 16:40:59.101212  1670 net.cpp:150] Setting up relu3_1
I0813 16:40:59.101220  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.101222  1670 net.cpp:165] Memory required for data: 1336320032
I0813 16:40:59.101224  1670 layer_factory.hpp:77] Creating layer conv3_2
I0813 16:40:59.101231  1670 net.cpp:100] Creating Layer conv3_2
I0813 16:40:59.101234  1670 net.cpp:434] conv3_2 <- conv3_1
I0813 16:40:59.101238  1670 net.cpp:408] conv3_2 -> conv3_2
I0813 16:40:59.104972  1670 net.cpp:150] Setting up conv3_2
I0813 16:40:59.104985  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.104987  1670 net.cpp:165] Memory required for data: 1382400032
I0813 16:40:59.104993  1670 layer_factory.hpp:77] Creating layer relu3_2
I0813 16:40:59.104998  1670 net.cpp:100] Creating Layer relu3_2
I0813 16:40:59.105000  1670 net.cpp:434] relu3_2 <- conv3_2
I0813 16:40:59.105005  1670 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0813 16:40:59.105413  1670 net.cpp:150] Setting up relu3_2
I0813 16:40:59.105422  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.105423  1670 net.cpp:165] Memory required for data: 1428480032
I0813 16:40:59.105427  1670 layer_factory.hpp:77] Creating layer conv3_3
I0813 16:40:59.105435  1670 net.cpp:100] Creating Layer conv3_3
I0813 16:40:59.105437  1670 net.cpp:434] conv3_3 <- conv3_2
I0813 16:40:59.105442  1670 net.cpp:408] conv3_3 -> conv3_3
I0813 16:40:59.109174  1670 net.cpp:150] Setting up conv3_3
I0813 16:40:59.109186  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.109189  1670 net.cpp:165] Memory required for data: 1474560032
I0813 16:40:59.109195  1670 layer_factory.hpp:77] Creating layer relu3_3
I0813 16:40:59.109200  1670 net.cpp:100] Creating Layer relu3_3
I0813 16:40:59.109203  1670 net.cpp:434] relu3_3 <- conv3_3
I0813 16:40:59.109206  1670 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0813 16:40:59.109500  1670 net.cpp:150] Setting up relu3_3
I0813 16:40:59.109508  1670 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0813 16:40:59.109510  1670 net.cpp:165] Memory required for data: 1520640032
I0813 16:40:59.109513  1670 layer_factory.hpp:77] Creating layer pool3
I0813 16:40:59.109516  1670 net.cpp:100] Creating Layer pool3
I0813 16:40:59.109519  1670 net.cpp:434] pool3 <- conv3_3
I0813 16:40:59.109522  1670 net.cpp:408] pool3 -> pool3
I0813 16:40:59.109562  1670 net.cpp:150] Setting up pool3
I0813 16:40:59.109567  1670 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0813 16:40:59.109570  1670 net.cpp:165] Memory required for data: 1532469280
I0813 16:40:59.109571  1670 layer_factory.hpp:77] Creating layer conv4_1
I0813 16:40:59.109577  1670 net.cpp:100] Creating Layer conv4_1
I0813 16:40:59.109580  1670 net.cpp:434] conv4_1 <- pool3
I0813 16:40:59.109585  1670 net.cpp:408] conv4_1 -> conv4_1
I0813 16:40:59.115821  1670 net.cpp:150] Setting up conv4_1
I0813 16:40:59.115844  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.115847  1670 net.cpp:165] Memory required for data: 1556127776
I0813 16:40:59.115854  1670 layer_factory.hpp:77] Creating layer relu4_1
I0813 16:40:59.115860  1670 net.cpp:100] Creating Layer relu4_1
I0813 16:40:59.115864  1670 net.cpp:434] relu4_1 <- conv4_1
I0813 16:40:59.115869  1670 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0813 16:40:59.116160  1670 net.cpp:150] Setting up relu4_1
I0813 16:40:59.116168  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.116169  1670 net.cpp:165] Memory required for data: 1579786272
I0813 16:40:59.116173  1670 layer_factory.hpp:77] Creating layer conv4_2
I0813 16:40:59.116183  1670 net.cpp:100] Creating Layer conv4_2
I0813 16:40:59.116185  1670 net.cpp:434] conv4_2 <- conv4_1
I0813 16:40:59.116190  1670 net.cpp:408] conv4_2 -> conv4_2
I0813 16:40:59.126735  1670 net.cpp:150] Setting up conv4_2
I0813 16:40:59.126752  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.126754  1670 net.cpp:165] Memory required for data: 1603444768
I0813 16:40:59.126770  1670 layer_factory.hpp:77] Creating layer relu4_2
I0813 16:40:59.126776  1670 net.cpp:100] Creating Layer relu4_2
I0813 16:40:59.126780  1670 net.cpp:434] relu4_2 <- conv4_2
I0813 16:40:59.126783  1670 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0813 16:40:59.127213  1670 net.cpp:150] Setting up relu4_2
I0813 16:40:59.127220  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.127223  1670 net.cpp:165] Memory required for data: 1627103264
I0813 16:40:59.127225  1670 layer_factory.hpp:77] Creating layer conv4_3
I0813 16:40:59.127233  1670 net.cpp:100] Creating Layer conv4_3
I0813 16:40:59.127235  1670 net.cpp:434] conv4_3 <- conv4_2
I0813 16:40:59.127239  1670 net.cpp:408] conv4_3 -> conv4_3
I0813 16:40:59.137796  1670 net.cpp:150] Setting up conv4_3
I0813 16:40:59.137811  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.137814  1670 net.cpp:165] Memory required for data: 1650761760
I0813 16:40:59.137821  1670 layer_factory.hpp:77] Creating layer relu4_3
I0813 16:40:59.137826  1670 net.cpp:100] Creating Layer relu4_3
I0813 16:40:59.137828  1670 net.cpp:434] relu4_3 <- conv4_3
I0813 16:40:59.137832  1670 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0813 16:40:59.138128  1670 net.cpp:150] Setting up relu4_3
I0813 16:40:59.138134  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.138136  1670 net.cpp:165] Memory required for data: 1674420256
I0813 16:40:59.138139  1670 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0813 16:40:59.138142  1670 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0813 16:40:59.138144  1670 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0813 16:40:59.138149  1670 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0813 16:40:59.138152  1670 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0813 16:40:59.138190  1670 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0813 16:40:59.138193  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.138196  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.138197  1670 net.cpp:165] Memory required for data: 1721737248
I0813 16:40:59.138200  1670 layer_factory.hpp:77] Creating layer pool4
I0813 16:40:59.138203  1670 net.cpp:100] Creating Layer pool4
I0813 16:40:59.138206  1670 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0813 16:40:59.138209  1670 net.cpp:408] pool4 -> pool4
I0813 16:40:59.138240  1670 net.cpp:150] Setting up pool4
I0813 16:40:59.138245  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.138247  1670 net.cpp:165] Memory required for data: 1727651872
I0813 16:40:59.138249  1670 layer_factory.hpp:77] Creating layer conv5_1
I0813 16:40:59.138257  1670 net.cpp:100] Creating Layer conv5_1
I0813 16:40:59.138258  1670 net.cpp:434] conv5_1 <- pool4
I0813 16:40:59.138262  1670 net.cpp:408] conv5_1 -> conv5_1
I0813 16:40:59.149111  1670 net.cpp:150] Setting up conv5_1
I0813 16:40:59.149127  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.149137  1670 net.cpp:165] Memory required for data: 1733566496
I0813 16:40:59.149143  1670 layer_factory.hpp:77] Creating layer relu5_1
I0813 16:40:59.149149  1670 net.cpp:100] Creating Layer relu5_1
I0813 16:40:59.149152  1670 net.cpp:434] relu5_1 <- conv5_1
I0813 16:40:59.149157  1670 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0813 16:40:59.149580  1670 net.cpp:150] Setting up relu5_1
I0813 16:40:59.149590  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.149591  1670 net.cpp:165] Memory required for data: 1739481120
I0813 16:40:59.149593  1670 layer_factory.hpp:77] Creating layer conv5_2
I0813 16:40:59.149601  1670 net.cpp:100] Creating Layer conv5_2
I0813 16:40:59.149603  1670 net.cpp:434] conv5_2 <- conv5_1
I0813 16:40:59.149607  1670 net.cpp:408] conv5_2 -> conv5_2
I0813 16:40:59.160221  1670 net.cpp:150] Setting up conv5_2
I0813 16:40:59.160238  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.160239  1670 net.cpp:165] Memory required for data: 1745395744
I0813 16:40:59.160246  1670 layer_factory.hpp:77] Creating layer relu5_2
I0813 16:40:59.160251  1670 net.cpp:100] Creating Layer relu5_2
I0813 16:40:59.160254  1670 net.cpp:434] relu5_2 <- conv5_2
I0813 16:40:59.160259  1670 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0813 16:40:59.160545  1670 net.cpp:150] Setting up relu5_2
I0813 16:40:59.160552  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.160554  1670 net.cpp:165] Memory required for data: 1751310368
I0813 16:40:59.160557  1670 layer_factory.hpp:77] Creating layer conv5_3
I0813 16:40:59.160563  1670 net.cpp:100] Creating Layer conv5_3
I0813 16:40:59.160565  1670 net.cpp:434] conv5_3 <- conv5_2
I0813 16:40:59.160569  1670 net.cpp:408] conv5_3 -> conv5_3
I0813 16:40:59.171305  1670 net.cpp:150] Setting up conv5_3
I0813 16:40:59.171322  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.171324  1670 net.cpp:165] Memory required for data: 1757224992
I0813 16:40:59.171331  1670 layer_factory.hpp:77] Creating layer relu5_3
I0813 16:40:59.171340  1670 net.cpp:100] Creating Layer relu5_3
I0813 16:40:59.171344  1670 net.cpp:434] relu5_3 <- conv5_3
I0813 16:40:59.171347  1670 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0813 16:40:59.171633  1670 net.cpp:150] Setting up relu5_3
I0813 16:40:59.171643  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.171644  1670 net.cpp:165] Memory required for data: 1763139616
I0813 16:40:59.171646  1670 layer_factory.hpp:77] Creating layer pool5
I0813 16:40:59.171651  1670 net.cpp:100] Creating Layer pool5
I0813 16:40:59.171653  1670 net.cpp:434] pool5 <- conv5_3
I0813 16:40:59.171658  1670 net.cpp:408] pool5 -> pool5
I0813 16:40:59.171695  1670 net.cpp:150] Setting up pool5
I0813 16:40:59.171700  1670 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0813 16:40:59.171701  1670 net.cpp:165] Memory required for data: 1769054240
I0813 16:40:59.171703  1670 layer_factory.hpp:77] Creating layer fc6
I0813 16:40:59.171710  1670 net.cpp:100] Creating Layer fc6
I0813 16:40:59.171715  1670 net.cpp:434] fc6 <- pool5
I0813 16:40:59.171718  1670 net.cpp:408] fc6 -> fc6
I0813 16:40:59.190345  1670 net.cpp:150] Setting up fc6
I0813 16:40:59.190361  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190363  1670 net.cpp:165] Memory required for data: 1780883488
I0813 16:40:59.190371  1670 layer_factory.hpp:77] Creating layer relu6
I0813 16:40:59.190376  1670 net.cpp:100] Creating Layer relu6
I0813 16:40:59.190380  1670 net.cpp:434] relu6 <- fc6
I0813 16:40:59.190384  1670 net.cpp:395] relu6 -> fc6 (in-place)
I0813 16:40:59.190734  1670 net.cpp:150] Setting up relu6
I0813 16:40:59.190742  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190743  1670 net.cpp:165] Memory required for data: 1792712736
I0813 16:40:59.190745  1670 layer_factory.hpp:77] Creating layer fc6_relu6_0_split
I0813 16:40:59.190749  1670 net.cpp:100] Creating Layer fc6_relu6_0_split
I0813 16:40:59.190752  1670 net.cpp:434] fc6_relu6_0_split <- fc6
I0813 16:40:59.190755  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_0
I0813 16:40:59.190771  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_1
I0813 16:40:59.190775  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_2
I0813 16:40:59.190784  1670 net.cpp:408] fc6_relu6_0_split -> fc6_relu6_0_split_3
I0813 16:40:59.190845  1670 net.cpp:150] Setting up fc6_relu6_0_split
I0813 16:40:59.190850  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190853  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190856  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190858  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.190860  1670 net.cpp:165] Memory required for data: 1840029728
I0813 16:40:59.190862  1670 layer_factory.hpp:77] Creating layer fc7
I0813 16:40:59.190870  1670 net.cpp:100] Creating Layer fc7
I0813 16:40:59.190872  1670 net.cpp:434] fc7 <- fc6_relu6_0_split_0
I0813 16:40:59.190877  1670 net.cpp:408] fc7 -> fc7
I0813 16:40:59.196444  1670 net.cpp:150] Setting up fc7
I0813 16:40:59.196460  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.196461  1670 net.cpp:165] Memory required for data: 1851858976
I0813 16:40:59.196467  1670 layer_factory.hpp:77] Creating layer relu7
I0813 16:40:59.196472  1670 net.cpp:100] Creating Layer relu7
I0813 16:40:59.196475  1670 net.cpp:434] relu7 <- fc7
I0813 16:40:59.196480  1670 net.cpp:395] relu7 -> fc7 (in-place)
I0813 16:40:59.196774  1670 net.cpp:150] Setting up relu7
I0813 16:40:59.196780  1670 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0813 16:40:59.196784  1670 net.cpp:165] Memory required for data: 1863688224
I0813 16:40:59.196785  1670 layer_factory.hpp:77] Creating layer conv6_1
I0813 16:40:59.196794  1670 net.cpp:100] Creating Layer conv6_1
I0813 16:40:59.196795  1670 net.cpp:434] conv6_1 <- fc7
I0813 16:40:59.196800  1670 net.cpp:408] conv6_1 -> conv6_1
I0813 16:40:59.199473  1670 net.cpp:150] Setting up conv6_1
I0813 16:40:59.199482  1670 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0813 16:40:59.199484  1670 net.cpp:165] Memory required for data: 1866645536
I0813 16:40:59.199491  1670 layer_factory.hpp:77] Creating layer conv6_1_relu
I0813 16:40:59.199496  1670 net.cpp:100] Creating Layer conv6_1_relu
I0813 16:40:59.199501  1670 net.cpp:434] conv6_1_relu <- conv6_1
I0813 16:40:59.199506  1670 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0813 16:40:59.199924  1670 net.cpp:150] Setting up conv6_1_relu
I0813 16:40:59.199932  1670 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0813 16:40:59.199935  1670 net.cpp:165] Memory required for data: 1869602848
I0813 16:40:59.199939  1670 layer_factory.hpp:77] Creating layer conv6_2
I0813 16:40:59.199949  1670 net.cpp:100] Creating Layer conv6_2
I0813 16:40:59.199951  1670 net.cpp:434] conv6_2 <- conv6_1
I0813 16:40:59.199957  1670 net.cpp:408] conv6_2 -> conv6_2
I0813 16:40:59.206034  1670 net.cpp:150] Setting up conv6_2
I0813 16:40:59.206051  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206053  1670 net.cpp:165] Memory required for data: 1871241248
I0813 16:40:59.206066  1670 layer_factory.hpp:77] Creating layer conv6_2_relu
I0813 16:40:59.206076  1670 net.cpp:100] Creating Layer conv6_2_relu
I0813 16:40:59.206081  1670 net.cpp:434] conv6_2_relu <- conv6_2
I0813 16:40:59.206086  1670 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0813 16:40:59.206387  1670 net.cpp:150] Setting up conv6_2_relu
I0813 16:40:59.206394  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206398  1670 net.cpp:165] Memory required for data: 1872879648
I0813 16:40:59.206399  1670 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0813 16:40:59.206406  1670 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0813 16:40:59.206409  1670 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0813 16:40:59.206414  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0813 16:40:59.206421  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0813 16:40:59.206436  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0813 16:40:59.206442  1670 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0813 16:40:59.206509  1670 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0813 16:40:59.206514  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206518  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206521  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206526  1670 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0813 16:40:59.206528  1670 net.cpp:165] Memory required for data: 1879433248
I0813 16:40:59.206532  1670 layer_factory.hpp:77] Creating layer conv7_1
I0813 16:40:59.206539  1670 net.cpp:100] Creating Layer conv7_1
I0813 16:40:59.206542  1670 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0813 16:40:59.206547  1670 net.cpp:408] conv7_1 -> conv7_1
I0813 16:40:59.208016  1670 net.cpp:150] Setting up conv7_1
I0813 16:40:59.208025  1670 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0813 16:40:59.208027  1670 net.cpp:165] Memory required for data: 1879842848
I0813 16:40:59.208032  1670 layer_factory.hpp:77] Creating layer conv7_1_relu
I0813 16:40:59.208035  1670 net.cpp:100] Creating Layer conv7_1_relu
I0813 16:40:59.208039  1670 net.cpp:434] conv7_1_relu <- conv7_1
I0813 16:40:59.208042  1670 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0813 16:40:59.208459  1670 net.cpp:150] Setting up conv7_1_relu
I0813 16:40:59.208467  1670 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0813 16:40:59.208468  1670 net.cpp:165] Memory required for data: 1880252448
I0813 16:40:59.208472  1670 layer_factory.hpp:77] Creating layer conv7_2
I0813 16:40:59.208477  1670 net.cpp:100] Creating Layer conv7_2
I0813 16:40:59.208479  1670 net.cpp:434] conv7_2 <- conv7_1
I0813 16:40:59.208483  1670 net.cpp:408] conv7_2 -> conv7_2
I0813 16:40:59.211113  1670 net.cpp:150] Setting up conv7_2
I0813 16:40:59.211123  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211127  1670 net.cpp:165] Memory required for data: 1880457248
I0813 16:40:59.211132  1670 layer_factory.hpp:77] Creating layer conv7_2_relu
I0813 16:40:59.211138  1670 net.cpp:100] Creating Layer conv7_2_relu
I0813 16:40:59.211140  1670 net.cpp:434] conv7_2_relu <- conv7_2
I0813 16:40:59.211145  1670 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0813 16:40:59.211441  1670 net.cpp:150] Setting up conv7_2_relu
I0813 16:40:59.211447  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211450  1670 net.cpp:165] Memory required for data: 1880662048
I0813 16:40:59.211453  1670 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0813 16:40:59.211459  1670 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0813 16:40:59.211465  1670 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0813 16:40:59.211473  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0813 16:40:59.211478  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0813 16:40:59.211485  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0813 16:40:59.211490  1670 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0813 16:40:59.211555  1670 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0813 16:40:59.211560  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211562  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211566  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211570  1670 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0813 16:40:59.211572  1670 net.cpp:165] Memory required for data: 1881481248
I0813 16:40:59.211575  1670 layer_factory.hpp:77] Creating layer conv8_1
I0813 16:40:59.211583  1670 net.cpp:100] Creating Layer conv8_1
I0813 16:40:59.211587  1670 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0813 16:40:59.211592  1670 net.cpp:408] conv8_1 -> conv8_1
I0813 16:40:59.213059  1670 net.cpp:150] Setting up conv8_1
I0813 16:40:59.213070  1670 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0813 16:40:59.213081  1670 net.cpp:165] Memory required for data: 1881583648
I0813 16:40:59.213089  1670 layer_factory.hpp:77] Creating layer conv8_1_relu
I0813 16:40:59.213093  1670 net.cpp:100] Creating Layer conv8_1_relu
I0813 16:40:59.213099  1670 net.cpp:434] conv8_1_relu <- conv8_1
I0813 16:40:59.213104  1670 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0813 16:40:59.213399  1670 net.cpp:150] Setting up conv8_1_relu
I0813 16:40:59.213407  1670 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0813 16:40:59.213412  1670 net.cpp:165] Memory required for data: 1881686048
I0813 16:40:59.213414  1670 layer_factory.hpp:77] Creating layer conv8_2
I0813 16:40:59.213423  1670 net.cpp:100] Creating Layer conv8_2
I0813 16:40:59.213426  1670 net.cpp:434] conv8_2 <- conv8_1
I0813 16:40:59.213433  1670 net.cpp:408] conv8_2 -> conv8_2
I0813 16:40:59.216190  1670 net.cpp:150] Setting up conv8_2
I0813 16:40:59.216200  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216202  1670 net.cpp:165] Memory required for data: 1881759776
I0813 16:40:59.216208  1670 layer_factory.hpp:77] Creating layer conv8_2_relu
I0813 16:40:59.216212  1670 net.cpp:100] Creating Layer conv8_2_relu
I0813 16:40:59.216215  1670 net.cpp:434] conv8_2_relu <- conv8_2
I0813 16:40:59.216218  1670 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0813 16:40:59.216634  1670 net.cpp:150] Setting up conv8_2_relu
I0813 16:40:59.216642  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216645  1670 net.cpp:165] Memory required for data: 1881833504
I0813 16:40:59.216646  1670 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0813 16:40:59.216650  1670 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0813 16:40:59.216652  1670 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0813 16:40:59.216656  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0813 16:40:59.216661  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0813 16:40:59.216665  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0813 16:40:59.216670  1670 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0813 16:40:59.216732  1670 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0813 16:40:59.216737  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216739  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216742  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216744  1670 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0813 16:40:59.216745  1670 net.cpp:165] Memory required for data: 1882128416
I0813 16:40:59.216748  1670 layer_factory.hpp:77] Creating layer conv9_1
I0813 16:40:59.216753  1670 net.cpp:100] Creating Layer conv9_1
I0813 16:40:59.216756  1670 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0813 16:40:59.216760  1670 net.cpp:408] conv9_1 -> conv9_1
I0813 16:40:59.218528  1670 net.cpp:150] Setting up conv9_1
I0813 16:40:59.218536  1670 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0813 16:40:59.218538  1670 net.cpp:165] Memory required for data: 1882165280
I0813 16:40:59.218544  1670 layer_factory.hpp:77] Creating layer conv9_1_relu
I0813 16:40:59.218547  1670 net.cpp:100] Creating Layer conv9_1_relu
I0813 16:40:59.218549  1670 net.cpp:434] conv9_1_relu <- conv9_1
I0813 16:40:59.218554  1670 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0813 16:40:59.218853  1670 net.cpp:150] Setting up conv9_1_relu
I0813 16:40:59.218860  1670 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0813 16:40:59.218863  1670 net.cpp:165] Memory required for data: 1882202144
I0813 16:40:59.218864  1670 layer_factory.hpp:77] Creating layer conv9_2
I0813 16:40:59.218870  1670 net.cpp:100] Creating Layer conv9_2
I0813 16:40:59.218873  1670 net.cpp:434] conv9_2 <- conv9_1
I0813 16:40:59.218878  1670 net.cpp:408] conv9_2 -> conv9_2
I0813 16:40:59.221599  1670 net.cpp:150] Setting up conv9_2
I0813 16:40:59.221609  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.221612  1670 net.cpp:165] Memory required for data: 1882210336
I0813 16:40:59.221624  1670 layer_factory.hpp:77] Creating layer conv9_2_relu
I0813 16:40:59.221628  1670 net.cpp:100] Creating Layer conv9_2_relu
I0813 16:40:59.221630  1670 net.cpp:434] conv9_2_relu <- conv9_2
I0813 16:40:59.221634  1670 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0813 16:40:59.222048  1670 net.cpp:150] Setting up conv9_2_relu
I0813 16:40:59.222056  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.222059  1670 net.cpp:165] Memory required for data: 1882218528
I0813 16:40:59.222060  1670 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0813 16:40:59.222065  1670 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0813 16:40:59.222067  1670 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0813 16:40:59.222070  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0813 16:40:59.222076  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0813 16:40:59.222080  1670 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0813 16:40:59.222131  1670 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0813 16:40:59.222136  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.222138  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.222141  1670 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0813 16:40:59.222142  1670 net.cpp:165] Memory required for data: 1882243104
I0813 16:40:59.222144  1670 layer_factory.hpp:77] Creating layer conv4_3_norm
I0813 16:40:59.222148  1670 net.cpp:100] Creating Layer conv4_3_norm
I0813 16:40:59.222151  1670 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0813 16:40:59.222156  1670 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0813 16:40:59.222312  1670 net.cpp:150] Setting up conv4_3_norm
I0813 16:40:59.222318  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.222321  1670 net.cpp:165] Memory required for data: 1905901600
I0813 16:40:59.222324  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.222327  1670 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.222331  1670 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0813 16:40:59.222333  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0813 16:40:59.222337  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0813 16:40:59.222342  1670 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0813 16:40:59.222388  1670 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0813 16:40:59.222393  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.222394  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.222398  1670 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0813 16:40:59.222399  1670 net.cpp:165] Memory required for data: 1976877088
I0813 16:40:59.222401  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0813 16:40:59.222407  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0813 16:40:59.222409  1670 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0813 16:40:59.222414  1670 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0813 16:40:59.224020  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0813 16:40:59.224030  1670 net.cpp:157] Top shape: 8 16 38 38 (184832)
I0813 16:40:59.224031  1670 net.cpp:165] Memory required for data: 1977616416
I0813 16:40:59.224038  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0813 16:40:59.224046  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0813 16:40:59.224051  1670 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0813 16:40:59.224056  1670 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0813 16:40:59.224158  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0813 16:40:59.224162  1670 net.cpp:157] Top shape: 8 38 38 16 (184832)
I0813 16:40:59.224170  1670 net.cpp:165] Memory required for data: 1978355744
I0813 16:40:59.224174  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0813 16:40:59.224177  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0813 16:40:59.224179  1670 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0813 16:40:59.224182  1670 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0813 16:40:59.224210  1670 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0813 16:40:59.224216  1670 net.cpp:157] Top shape: 8 23104 (184832)
I0813 16:40:59.224218  1670 net.cpp:165] Memory required for data: 1979095072
I0813 16:40:59.224220  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0813 16:40:59.224229  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0813 16:40:59.224233  1670 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0813 16:40:59.224236  1670 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0813 16:40:59.227407  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0813 16:40:59.227416  1670 net.cpp:157] Top shape: 8 92 38 38 (1062784)
I0813 16:40:59.227419  1670 net.cpp:165] Memory required for data: 1983346208
I0813 16:40:59.227425  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0813 16:40:59.227430  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0813 16:40:59.227432  1670 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0813 16:40:59.227437  1670 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0813 16:40:59.227535  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0813 16:40:59.227541  1670 net.cpp:157] Top shape: 8 38 38 92 (1062784)
I0813 16:40:59.227542  1670 net.cpp:165] Memory required for data: 1987597344
I0813 16:40:59.227545  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0813 16:40:59.227550  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0813 16:40:59.227551  1670 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0813 16:40:59.227555  1670 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0813 16:40:59.227576  1670 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0813 16:40:59.227581  1670 net.cpp:157] Top shape: 8 132848 (1062784)
I0813 16:40:59.227581  1670 net.cpp:165] Memory required for data: 1991848480
I0813 16:40:59.227583  1670 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0813 16:40:59.227589  1670 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0813 16:40:59.227592  1670 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0813 16:40:59.227596  1670 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0813 16:40:59.227598  1670 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0813 16:40:59.227622  1670 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0813 16:40:59.227627  1670 net.cpp:157] Top shape: 1 2 23104 (46208)
I0813 16:40:59.227628  1670 net.cpp:165] Memory required for data: 1992033312
I0813 16:40:59.227630  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc
I0813 16:40:59.227636  1670 net.cpp:100] Creating Layer fc6_mbox_loc
I0813 16:40:59.227640  1670 net.cpp:434] fc6_mbox_loc <- fc6_relu6_0_split_1
I0813 16:40:59.227644  1670 net.cpp:408] fc6_mbox_loc -> fc6_mbox_loc
I0813 16:40:59.229750  1670 net.cpp:150] Setting up fc6_mbox_loc
I0813 16:40:59.229759  1670 net.cpp:157] Top shape: 8 24 19 19 (69312)
I0813 16:40:59.229761  1670 net.cpp:165] Memory required for data: 1992310560
I0813 16:40:59.229765  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc_perm
I0813 16:40:59.229770  1670 net.cpp:100] Creating Layer fc6_mbox_loc_perm
I0813 16:40:59.229774  1670 net.cpp:434] fc6_mbox_loc_perm <- fc6_mbox_loc
I0813 16:40:59.229777  1670 net.cpp:408] fc6_mbox_loc_perm -> fc6_mbox_loc_perm
I0813 16:40:59.229877  1670 net.cpp:150] Setting up fc6_mbox_loc_perm
I0813 16:40:59.229882  1670 net.cpp:157] Top shape: 8 19 19 24 (69312)
I0813 16:40:59.229892  1670 net.cpp:165] Memory required for data: 1992587808
I0813 16:40:59.229893  1670 layer_factory.hpp:77] Creating layer fc6_mbox_loc_flat
I0813 16:40:59.229897  1670 net.cpp:100] Creating Layer fc6_mbox_loc_flat
I0813 16:40:59.229899  1670 net.cpp:434] fc6_mbox_loc_flat <- fc6_mbox_loc_perm
I0813 16:40:59.229903  1670 net.cpp:408] fc6_mbox_loc_flat -> fc6_mbox_loc_flat
I0813 16:40:59.229924  1670 net.cpp:150] Setting up fc6_mbox_loc_flat
I0813 16:40:59.229928  1670 net.cpp:157] Top shape: 8 8664 (69312)
I0813 16:40:59.229930  1670 net.cpp:165] Memory required for data: 1992865056
I0813 16:40:59.229933  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf
I0813 16:40:59.229940  1670 net.cpp:100] Creating Layer fc6_mbox_conf
I0813 16:40:59.229944  1670 net.cpp:434] fc6_mbox_conf <- fc6_relu6_0_split_2
I0813 16:40:59.229949  1670 net.cpp:408] fc6_mbox_conf -> fc6_mbox_conf
I0813 16:40:59.236399  1670 net.cpp:150] Setting up fc6_mbox_conf
I0813 16:40:59.236416  1670 net.cpp:157] Top shape: 8 138 19 19 (398544)
I0813 16:40:59.236419  1670 net.cpp:165] Memory required for data: 1994459232
I0813 16:40:59.236428  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf_perm
I0813 16:40:59.236436  1670 net.cpp:100] Creating Layer fc6_mbox_conf_perm
I0813 16:40:59.236439  1670 net.cpp:434] fc6_mbox_conf_perm <- fc6_mbox_conf
I0813 16:40:59.236444  1670 net.cpp:408] fc6_mbox_conf_perm -> fc6_mbox_conf_perm
I0813 16:40:59.236548  1670 net.cpp:150] Setting up fc6_mbox_conf_perm
I0813 16:40:59.236554  1670 net.cpp:157] Top shape: 8 19 19 138 (398544)
I0813 16:40:59.236557  1670 net.cpp:165] Memory required for data: 1996053408
I0813 16:40:59.236558  1670 layer_factory.hpp:77] Creating layer fc6_mbox_conf_flat
I0813 16:40:59.236562  1670 net.cpp:100] Creating Layer fc6_mbox_conf_flat
I0813 16:40:59.236565  1670 net.cpp:434] fc6_mbox_conf_flat <- fc6_mbox_conf_perm
I0813 16:40:59.236569  1670 net.cpp:408] fc6_mbox_conf_flat -> fc6_mbox_conf_flat
I0813 16:40:59.236591  1670 net.cpp:150] Setting up fc6_mbox_conf_flat
I0813 16:40:59.236595  1670 net.cpp:157] Top shape: 8 49818 (398544)
I0813 16:40:59.236598  1670 net.cpp:165] Memory required for data: 1997647584
I0813 16:40:59.236600  1670 layer_factory.hpp:77] Creating layer fc6_mbox_priorbox
I0813 16:40:59.236605  1670 net.cpp:100] Creating Layer fc6_mbox_priorbox
I0813 16:40:59.236608  1670 net.cpp:434] fc6_mbox_priorbox <- fc6_relu6_0_split_3
I0813 16:40:59.236611  1670 net.cpp:434] fc6_mbox_priorbox <- data_data_0_split_2
I0813 16:40:59.236615  1670 net.cpp:408] fc6_mbox_priorbox -> fc6_mbox_priorbox
I0813 16:40:59.236641  1670 net.cpp:150] Setting up fc6_mbox_priorbox
I0813 16:40:59.236646  1670 net.cpp:157] Top shape: 1 2 8664 (17328)
I0813 16:40:59.236650  1670 net.cpp:165] Memory required for data: 1997716896
I0813 16:40:59.236654  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0813 16:40:59.236665  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0813 16:40:59.236668  1670 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0813 16:40:59.236675  1670 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0813 16:40:59.238425  1670 net.cpp:150] Setting up conv6_2_mbox_loc
I0813 16:40:59.238435  1670 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0813 16:40:59.238440  1670 net.cpp:165] Memory required for data: 1997793696
I0813 16:40:59.238447  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0813 16:40:59.238452  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0813 16:40:59.238456  1670 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0813 16:40:59.238463  1670 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0813 16:40:59.238572  1670 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0813 16:40:59.238577  1670 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0813 16:40:59.238581  1670 net.cpp:165] Memory required for data: 1997870496
I0813 16:40:59.238584  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0813 16:40:59.238589  1670 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0813 16:40:59.238600  1670 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0813 16:40:59.238606  1670 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0813 16:40:59.238631  1670 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0813 16:40:59.238636  1670 net.cpp:157] Top shape: 8 2400 (19200)
I0813 16:40:59.238641  1670 net.cpp:165] Memory required for data: 1997947296
I0813 16:40:59.238643  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0813 16:40:59.238652  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0813 16:40:59.238656  1670 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0813 16:40:59.238662  1670 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0813 16:40:59.242635  1670 net.cpp:150] Setting up conv6_2_mbox_conf
I0813 16:40:59.242647  1670 net.cpp:157] Top shape: 8 138 10 10 (110400)
I0813 16:40:59.242650  1670 net.cpp:165] Memory required for data: 1998388896
I0813 16:40:59.242656  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0813 16:40:59.242661  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0813 16:40:59.242664  1670 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0813 16:40:59.242669  1670 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0813 16:40:59.242789  1670 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0813 16:40:59.242796  1670 net.cpp:157] Top shape: 8 10 10 138 (110400)
I0813 16:40:59.242799  1670 net.cpp:165] Memory required for data: 1998830496
I0813 16:40:59.242802  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0813 16:40:59.242808  1670 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0813 16:40:59.242811  1670 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0813 16:40:59.242817  1670 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0813 16:40:59.242842  1670 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0813 16:40:59.242847  1670 net.cpp:157] Top shape: 8 13800 (110400)
I0813 16:40:59.242849  1670 net.cpp:165] Memory required for data: 1999272096
I0813 16:40:59.242851  1670 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0813 16:40:59.242859  1670 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0813 16:40:59.242862  1670 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0813 16:40:59.242866  1670 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0813 16:40:59.242872  1670 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0813 16:40:59.242898  1670 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0813 16:40:59.242903  1670 net.cpp:157] Top shape: 1 2 2400 (4800)
I0813 16:40:59.242904  1670 net.cpp:165] Memory required for data: 1999291296
I0813 16:40:59.242908  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0813 16:40:59.242916  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0813 16:40:59.242919  1670 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0813 16:40:59.242924  1670 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0813 16:40:59.244397  1670 net.cpp:150] Setting up conv7_2_mbox_loc
I0813 16:40:59.244406  1670 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0813 16:40:59.244407  1670 net.cpp:165] Memory required for data: 1999310496
I0813 16:40:59.244412  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0813 16:40:59.244417  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0813 16:40:59.244421  1670 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0813 16:40:59.244423  1670 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0813 16:40:59.244529  1670 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0813 16:40:59.244534  1670 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0813 16:40:59.244535  1670 net.cpp:165] Memory required for data: 1999329696
I0813 16:40:59.244537  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0813 16:40:59.244541  1670 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0813 16:40:59.244544  1670 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0813 16:40:59.244554  1670 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0813 16:40:59.244577  1670 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0813 16:40:59.244582  1670 net.cpp:157] Top shape: 8 600 (4800)
I0813 16:40:59.244583  1670 net.cpp:165] Memory required for data: 1999348896
I0813 16:40:59.244586  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0813 16:40:59.244592  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0813 16:40:59.244594  1670 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0813 16:40:59.244598  1670 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0813 16:40:59.247426  1670 net.cpp:150] Setting up conv7_2_mbox_conf
I0813 16:40:59.247436  1670 net.cpp:157] Top shape: 8 138 5 5 (27600)
I0813 16:40:59.247437  1670 net.cpp:165] Memory required for data: 1999459296
I0813 16:40:59.247443  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0813 16:40:59.247450  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0813 16:40:59.247457  1670 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0813 16:40:59.247462  1670 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0813 16:40:59.247570  1670 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0813 16:40:59.247577  1670 net.cpp:157] Top shape: 8 5 5 138 (27600)
I0813 16:40:59.247579  1670 net.cpp:165] Memory required for data: 1999569696
I0813 16:40:59.247582  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0813 16:40:59.247587  1670 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0813 16:40:59.247591  1670 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0813 16:40:59.247596  1670 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0813 16:40:59.247618  1670 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0813 16:40:59.247624  1670 net.cpp:157] Top shape: 8 3450 (27600)
I0813 16:40:59.247627  1670 net.cpp:165] Memory required for data: 1999680096
I0813 16:40:59.247629  1670 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0813 16:40:59.247635  1670 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0813 16:40:59.247638  1670 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0813 16:40:59.247643  1670 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0813 16:40:59.247650  1670 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0813 16:40:59.247676  1670 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0813 16:40:59.247683  1670 net.cpp:157] Top shape: 1 2 600 (1200)
I0813 16:40:59.247684  1670 net.cpp:165] Memory required for data: 1999684896
I0813 16:40:59.247686  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0813 16:40:59.247694  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0813 16:40:59.247699  1670 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0813 16:40:59.247704  1670 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0813 16:40:59.249233  1670 net.cpp:150] Setting up conv8_2_mbox_loc
I0813 16:40:59.249241  1670 net.cpp:157] Top shape: 8 16 3 3 (1152)
I0813 16:40:59.249243  1670 net.cpp:165] Memory required for data: 1999689504
I0813 16:40:59.249254  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0813 16:40:59.249259  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0813 16:40:59.249261  1670 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0813 16:40:59.249267  1670 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0813 16:40:59.249373  1670 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0813 16:40:59.249378  1670 net.cpp:157] Top shape: 8 3 3 16 (1152)
I0813 16:40:59.249380  1670 net.cpp:165] Memory required for data: 1999694112
I0813 16:40:59.249382  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0813 16:40:59.249387  1670 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0813 16:40:59.249389  1670 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0813 16:40:59.249392  1670 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0813 16:40:59.249421  1670 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0813 16:40:59.249428  1670 net.cpp:157] Top shape: 8 144 (1152)
I0813 16:40:59.249428  1670 net.cpp:165] Memory required for data: 1999698720
I0813 16:40:59.249430  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0813 16:40:59.249438  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0813 16:40:59.249439  1670 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0813 16:40:59.249444  1670 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0813 16:40:59.251566  1670 net.cpp:150] Setting up conv8_2_mbox_conf
I0813 16:40:59.251574  1670 net.cpp:157] Top shape: 8 92 3 3 (6624)
I0813 16:40:59.251577  1670 net.cpp:165] Memory required for data: 1999725216
I0813 16:40:59.251582  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0813 16:40:59.251590  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0813 16:40:59.251595  1670 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0813 16:40:59.251600  1670 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0813 16:40:59.251709  1670 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0813 16:40:59.251714  1670 net.cpp:157] Top shape: 8 3 3 92 (6624)
I0813 16:40:59.251716  1670 net.cpp:165] Memory required for data: 1999751712
I0813 16:40:59.251719  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0813 16:40:59.251725  1670 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0813 16:40:59.251730  1670 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0813 16:40:59.251734  1670 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0813 16:40:59.251760  1670 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0813 16:40:59.251765  1670 net.cpp:157] Top shape: 8 828 (6624)
I0813 16:40:59.251767  1670 net.cpp:165] Memory required for data: 1999778208
I0813 16:40:59.251768  1670 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0813 16:40:59.251775  1670 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0813 16:40:59.251778  1670 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0813 16:40:59.251782  1670 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0813 16:40:59.251787  1670 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0813 16:40:59.251816  1670 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0813 16:40:59.251821  1670 net.cpp:157] Top shape: 1 2 144 (288)
I0813 16:40:59.251821  1670 net.cpp:165] Memory required for data: 1999779360
I0813 16:40:59.251823  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0813 16:40:59.251832  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0813 16:40:59.251837  1670 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0813 16:40:59.251842  1670 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0813 16:40:59.253381  1670 net.cpp:150] Setting up conv9_2_mbox_loc
I0813 16:40:59.253388  1670 net.cpp:157] Top shape: 8 16 1 1 (128)
I0813 16:40:59.253391  1670 net.cpp:165] Memory required for data: 1999779872
I0813 16:40:59.253396  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0813 16:40:59.253399  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0813 16:40:59.253402  1670 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0813 16:40:59.253408  1670 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0813 16:40:59.253513  1670 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0813 16:40:59.253518  1670 net.cpp:157] Top shape: 8 1 1 16 (128)
I0813 16:40:59.253520  1670 net.cpp:165] Memory required for data: 1999780384
I0813 16:40:59.253522  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0813 16:40:59.253527  1670 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0813 16:40:59.253530  1670 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0813 16:40:59.253532  1670 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0813 16:40:59.253556  1670 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0813 16:40:59.253561  1670 net.cpp:157] Top shape: 8 16 (128)
I0813 16:40:59.253569  1670 net.cpp:165] Memory required for data: 1999780896
I0813 16:40:59.253572  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0813 16:40:59.253582  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0813 16:40:59.253584  1670 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0813 16:40:59.253592  1670 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0813 16:40:59.255693  1670 net.cpp:150] Setting up conv9_2_mbox_conf
I0813 16:40:59.255703  1670 net.cpp:157] Top shape: 8 92 1 1 (736)
I0813 16:40:59.255705  1670 net.cpp:165] Memory required for data: 1999783840
I0813 16:40:59.255712  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0813 16:40:59.255719  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0813 16:40:59.255722  1670 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0813 16:40:59.255729  1670 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0813 16:40:59.255841  1670 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0813 16:40:59.255846  1670 net.cpp:157] Top shape: 8 1 1 92 (736)
I0813 16:40:59.255848  1670 net.cpp:165] Memory required for data: 1999786784
I0813 16:40:59.255851  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0813 16:40:59.255856  1670 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0813 16:40:59.255859  1670 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0813 16:40:59.255864  1670 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0813 16:40:59.255888  1670 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0813 16:40:59.255892  1670 net.cpp:157] Top shape: 8 92 (736)
I0813 16:40:59.255894  1670 net.cpp:165] Memory required for data: 1999789728
I0813 16:40:59.255897  1670 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0813 16:40:59.255903  1670 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0813 16:40:59.255906  1670 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0813 16:40:59.255909  1670 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0813 16:40:59.255916  1670 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0813 16:40:59.255940  1670 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0813 16:40:59.255945  1670 net.cpp:157] Top shape: 1 2 16 (32)
I0813 16:40:59.255946  1670 net.cpp:165] Memory required for data: 1999789856
I0813 16:40:59.255949  1670 layer_factory.hpp:77] Creating layer mbox_loc
I0813 16:40:59.255955  1670 net.cpp:100] Creating Layer mbox_loc
I0813 16:40:59.255959  1670 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0813 16:40:59.255962  1670 net.cpp:434] mbox_loc <- fc6_mbox_loc_flat
I0813 16:40:59.255967  1670 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0813 16:40:59.255971  1670 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0813 16:40:59.255975  1670 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0813 16:40:59.255980  1670 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0813 16:40:59.255986  1670 net.cpp:408] mbox_loc -> mbox_loc
I0813 16:40:59.256011  1670 net.cpp:150] Setting up mbox_loc
I0813 16:40:59.256016  1670 net.cpp:157] Top shape: 8 34928 (279424)
I0813 16:40:59.256018  1670 net.cpp:165] Memory required for data: 2000907552
I0813 16:40:59.256022  1670 layer_factory.hpp:77] Creating layer mbox_conf
I0813 16:40:59.256028  1670 net.cpp:100] Creating Layer mbox_conf
I0813 16:40:59.256031  1670 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0813 16:40:59.256036  1670 net.cpp:434] mbox_conf <- fc6_mbox_conf_flat
I0813 16:40:59.256039  1670 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0813 16:40:59.256043  1670 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0813 16:40:59.256045  1670 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0813 16:40:59.256048  1670 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0813 16:40:59.256052  1670 net.cpp:408] mbox_conf -> mbox_conf
I0813 16:40:59.256073  1670 net.cpp:150] Setting up mbox_conf
I0813 16:40:59.256078  1670 net.cpp:157] Top shape: 8 200836 (1606688)
I0813 16:40:59.256085  1670 net.cpp:165] Memory required for data: 2007334304
I0813 16:40:59.256088  1670 layer_factory.hpp:77] Creating layer mbox_priorbox
I0813 16:40:59.256093  1670 net.cpp:100] Creating Layer mbox_priorbox
I0813 16:40:59.256095  1670 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0813 16:40:59.256098  1670 net.cpp:434] mbox_priorbox <- fc6_mbox_priorbox
I0813 16:40:59.256103  1670 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0813 16:40:59.256104  1670 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0813 16:40:59.256108  1670 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0813 16:40:59.256109  1670 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0813 16:40:59.256112  1670 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0813 16:40:59.256134  1670 net.cpp:150] Setting up mbox_priorbox
I0813 16:40:59.256139  1670 net.cpp:157] Top shape: 1 2 34928 (69856)
I0813 16:40:59.256140  1670 net.cpp:165] Memory required for data: 2007613728
I0813 16:40:59.256144  1670 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0813 16:40:59.256147  1670 net.cpp:100] Creating Layer mbox_conf_reshape
I0813 16:40:59.256150  1670 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0813 16:40:59.256155  1670 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0813 16:40:59.256184  1670 net.cpp:150] Setting up mbox_conf_reshape
I0813 16:40:59.256189  1670 net.cpp:157] Top shape: 8 8732 23 (1606688)
I0813 16:40:59.256193  1670 net.cpp:165] Memory required for data: 2014040480
I0813 16:40:59.256196  1670 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0813 16:40:59.256202  1670 net.cpp:100] Creating Layer mbox_conf_softmax
I0813 16:40:59.256206  1670 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0813 16:40:59.256211  1670 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0813 16:40:59.256712  1670 net.cpp:150] Setting up mbox_conf_softmax
I0813 16:40:59.256721  1670 net.cpp:157] Top shape: 8 8732 23 (1606688)
I0813 16:40:59.256724  1670 net.cpp:165] Memory required for data: 2020467232
I0813 16:40:59.256726  1670 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0813 16:40:59.256731  1670 net.cpp:100] Creating Layer mbox_conf_flatten
I0813 16:40:59.256732  1670 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0813 16:40:59.256737  1670 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0813 16:40:59.256763  1670 net.cpp:150] Setting up mbox_conf_flatten
I0813 16:40:59.256768  1670 net.cpp:157] Top shape: 8 200836 (1606688)
I0813 16:40:59.256772  1670 net.cpp:165] Memory required for data: 2026893984
I0813 16:40:59.256775  1670 layer_factory.hpp:77] Creating layer detection_out
I0813 16:40:59.256785  1670 net.cpp:100] Creating Layer detection_out
I0813 16:40:59.256788  1670 net.cpp:434] detection_out <- mbox_loc
I0813 16:40:59.256791  1670 net.cpp:434] detection_out <- mbox_conf_flatten
I0813 16:40:59.256794  1670 net.cpp:434] detection_out <- mbox_priorbox
I0813 16:40:59.256798  1670 net.cpp:408] detection_out -> detection_out
W0813 16:40:59.257266  1670 detection_output_layer.cpp:49] Failed to create directory: ./data/results/YUUAV/SSD_300x300/Main
I0813 16:40:59.259686  1670 net.cpp:150] Setting up detection_out
I0813 16:40:59.259694  1670 net.cpp:157] Top shape: 1 1 1 7 (7)
I0813 16:40:59.259696  1670 net.cpp:165] Memory required for data: 2026894012
I0813 16:40:59.259698  1670 layer_factory.hpp:77] Creating layer detection_eval
I0813 16:40:59.259703  1670 net.cpp:100] Creating Layer detection_eval
I0813 16:40:59.259707  1670 net.cpp:434] detection_eval <- detection_out
I0813 16:40:59.259711  1670 net.cpp:434] detection_eval <- label
I0813 16:40:59.259713  1670 net.cpp:408] detection_eval -> detection_eval
I0813 16:40:59.260967  1670 net.cpp:150] Setting up detection_eval
I0813 16:40:59.260973  1670 net.cpp:157] Top shape: 1 1 23 5 (115)
I0813 16:40:59.260975  1670 net.cpp:165] Memory required for data: 2026894472
I0813 16:40:59.260977  1670 net.cpp:228] detection_eval does not need backward computation.
I0813 16:40:59.260980  1670 net.cpp:228] detection_out does not need backward computation.
I0813 16:40:59.260988  1670 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0813 16:40:59.260991  1670 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0813 16:40:59.260993  1670 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0813 16:40:59.260995  1670 net.cpp:228] mbox_priorbox does not need backward computation.
I0813 16:40:59.260998  1670 net.cpp:228] mbox_conf does not need backward computation.
I0813 16:40:59.261001  1670 net.cpp:228] mbox_loc does not need backward computation.
I0813 16:40:59.261004  1670 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.261008  1670 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261009  1670 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261011  1670 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0813 16:40:59.261013  1670 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261015  1670 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261018  1670 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0813 16:40:59.261020  1670 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.261024  1670 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261027  1670 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261031  1670 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0813 16:40:59.261034  1670 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261035  1670 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261039  1670 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0813 16:40:59.261041  1670 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.261044  1670 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261046  1670 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261049  1670 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0813 16:40:59.261052  1670 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261054  1670 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261057  1670 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0813 16:40:59.261059  1670 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0813 16:40:59.261063  1670 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261065  1670 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261067  1670 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0813 16:40:59.261070  1670 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261072  1670 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261075  1670 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0813 16:40:59.261077  1670 net.cpp:228] fc6_mbox_priorbox does not need backward computation.
I0813 16:40:59.261080  1670 net.cpp:228] fc6_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261083  1670 net.cpp:228] fc6_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261085  1670 net.cpp:228] fc6_mbox_conf does not need backward computation.
I0813 16:40:59.261087  1670 net.cpp:228] fc6_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261090  1670 net.cpp:228] fc6_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261093  1670 net.cpp:228] fc6_mbox_loc does not need backward computation.
I0813 16:40:59.261096  1670 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0813 16:40:59.261101  1670 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0813 16:40:59.261106  1670 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0813 16:40:59.261108  1670 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0813 16:40:59.261111  1670 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0813 16:40:59.261112  1670 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0813 16:40:59.261114  1670 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0813 16:40:59.261117  1670 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0813 16:40:59.261121  1670 net.cpp:228] conv4_3_norm does not need backward computation.
I0813 16:40:59.261122  1670 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0813 16:40:59.261126  1670 net.cpp:228] conv9_2_relu does not need backward computation.
I0813 16:40:59.261128  1670 net.cpp:228] conv9_2 does not need backward computation.
I0813 16:40:59.261131  1670 net.cpp:228] conv9_1_relu does not need backward computation.
I0813 16:40:59.261132  1670 net.cpp:228] conv9_1 does not need backward computation.
I0813 16:40:59.261135  1670 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0813 16:40:59.261138  1670 net.cpp:228] conv8_2_relu does not need backward computation.
I0813 16:40:59.261140  1670 net.cpp:228] conv8_2 does not need backward computation.
I0813 16:40:59.261143  1670 net.cpp:228] conv8_1_relu does not need backward computation.
I0813 16:40:59.261145  1670 net.cpp:228] conv8_1 does not need backward computation.
I0813 16:40:59.261148  1670 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0813 16:40:59.261152  1670 net.cpp:228] conv7_2_relu does not need backward computation.
I0813 16:40:59.261153  1670 net.cpp:228] conv7_2 does not need backward computation.
I0813 16:40:59.261155  1670 net.cpp:228] conv7_1_relu does not need backward computation.
I0813 16:40:59.261157  1670 net.cpp:228] conv7_1 does not need backward computation.
I0813 16:40:59.261162  1670 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0813 16:40:59.261163  1670 net.cpp:228] conv6_2_relu does not need backward computation.
I0813 16:40:59.261167  1670 net.cpp:228] conv6_2 does not need backward computation.
I0813 16:40:59.261169  1670 net.cpp:228] conv6_1_relu does not need backward computation.
I0813 16:40:59.261171  1670 net.cpp:228] conv6_1 does not need backward computation.
I0813 16:40:59.261174  1670 net.cpp:228] relu7 does not need backward computation.
I0813 16:40:59.261176  1670 net.cpp:228] fc7 does not need backward computation.
I0813 16:40:59.261179  1670 net.cpp:228] fc6_relu6_0_split does not need backward computation.
I0813 16:40:59.261183  1670 net.cpp:228] relu6 does not need backward computation.
I0813 16:40:59.261184  1670 net.cpp:228] fc6 does not need backward computation.
I0813 16:40:59.261186  1670 net.cpp:228] pool5 does not need backward computation.
I0813 16:40:59.261190  1670 net.cpp:228] relu5_3 does not need backward computation.
I0813 16:40:59.261193  1670 net.cpp:228] conv5_3 does not need backward computation.
I0813 16:40:59.261194  1670 net.cpp:228] relu5_2 does not need backward computation.
I0813 16:40:59.261196  1670 net.cpp:228] conv5_2 does not need backward computation.
I0813 16:40:59.261199  1670 net.cpp:228] relu5_1 does not need backward computation.
I0813 16:40:59.261201  1670 net.cpp:228] conv5_1 does not need backward computation.
I0813 16:40:59.261204  1670 net.cpp:228] pool4 does not need backward computation.
I0813 16:40:59.261206  1670 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0813 16:40:59.261209  1670 net.cpp:228] relu4_3 does not need backward computation.
I0813 16:40:59.261211  1670 net.cpp:228] conv4_3 does not need backward computation.
I0813 16:40:59.261214  1670 net.cpp:228] relu4_2 does not need backward computation.
I0813 16:40:59.261219  1670 net.cpp:228] conv4_2 does not need backward computation.
I0813 16:40:59.261222  1670 net.cpp:228] relu4_1 does not need backward computation.
I0813 16:40:59.261224  1670 net.cpp:228] conv4_1 does not need backward computation.
I0813 16:40:59.261226  1670 net.cpp:228] pool3 does not need backward computation.
I0813 16:40:59.261229  1670 net.cpp:228] relu3_3 does not need backward computation.
I0813 16:40:59.261231  1670 net.cpp:228] conv3_3 does not need backward computation.
I0813 16:40:59.261234  1670 net.cpp:228] relu3_2 does not need backward computation.
I0813 16:40:59.261236  1670 net.cpp:228] conv3_2 does not need backward computation.
I0813 16:40:59.261238  1670 net.cpp:228] relu3_1 does not need backward computation.
I0813 16:40:59.261240  1670 net.cpp:228] conv3_1 does not need backward computation.
I0813 16:40:59.261242  1670 net.cpp:228] pool2 does not need backward computation.
I0813 16:40:59.261245  1670 net.cpp:228] relu2_2 does not need backward computation.
I0813 16:40:59.261247  1670 net.cpp:228] conv2_2 does not need backward computation.
I0813 16:40:59.261250  1670 net.cpp:228] relu2_1 does not need backward computation.
I0813 16:40:59.261252  1670 net.cpp:228] conv2_1 does not need backward computation.
I0813 16:40:59.261255  1670 net.cpp:228] pool1 does not need backward computation.
I0813 16:40:59.261256  1670 net.cpp:228] relu1_2 does not need backward computation.
I0813 16:40:59.261260  1670 net.cpp:228] conv1_2 does not need backward computation.
I0813 16:40:59.261261  1670 net.cpp:228] relu1_1 does not need backward computation.
I0813 16:40:59.261263  1670 net.cpp:228] conv1_1 does not need backward computation.
I0813 16:40:59.261265  1670 net.cpp:228] data_data_0_split does not need backward computation.
I0813 16:40:59.261270  1670 net.cpp:228] data does not need backward computation.
I0813 16:40:59.261270  1670 net.cpp:270] This network produces output detection_eval
I0813 16:40:59.261320  1670 net.cpp:283] Network initialization done.
I0813 16:40:59.261502  1670 solver.cpp:75] Solver scaffolding done.
I0813 16:40:59.264024  1670 caffe.cpp:155] Finetuning from ./premodel/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0813 16:40:59.438139  1670 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./premodel/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0813 16:40:59.438153  1670 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0813 16:40:59.438170  1670 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0813 16:40:59.447122  1670 net.cpp:761] Ignoring source layer drop6
I0813 16:40:59.447595  1670 net.cpp:761] Ignoring source layer drop7
I0813 16:40:59.447600  1670 net.cpp:761] Ignoring source layer fc8
I0813 16:40:59.447602  1670 net.cpp:761] Ignoring source layer prob
I0813 16:40:59.470065  1670 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./premodel/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0813 16:40:59.470082  1670 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0813 16:40:59.470098  1670 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0813 16:40:59.478971  1670 net.cpp:761] Ignoring source layer drop6
I0813 16:40:59.479441  1670 net.cpp:761] Ignoring source layer drop7
I0813 16:40:59.479446  1670 net.cpp:761] Ignoring source layer fc8
I0813 16:40:59.479449  1670 net.cpp:761] Ignoring source layer prob
I0813 16:40:59.480087  1670 caffe.cpp:251] Starting Optimization
I0813 16:40:59.480093  1670 solver.cpp:294] Solving VGG_YUUAV_SSD_300x300_train
I0813 16:40:59.480109  1670 solver.cpp:295] Learning Rate Policy: multistep
I0813 16:41:05.964718  1670 solver.cpp:243] Iteration 0, loss = 24.9904
I0813 16:41:05.964754  1670 solver.cpp:259]     Train net output #0: mbox_loss = 23.554 (* 1 = 23.554 loss)
I0813 16:41:05.964768  1670 sgd_solver.cpp:138] Iteration 0, lr = 0.0001
I0813 16:50:26.610155  1670 solver.cpp:243] Iteration 100, loss = 13.2174
I0813 16:50:26.610225  1670 solver.cpp:259]     Train net output #0: mbox_loss = 12.9418 (* 1 = 12.9418 loss)
I0813 16:50:26.610231  1670 sgd_solver.cpp:138] Iteration 100, lr = 0.0001
I0813 16:59:48.248430  1670 solver.cpp:243] Iteration 200, loss = 9.90093
I0813 16:59:48.249608  1670 solver.cpp:259]     Train net output #0: mbox_loss = 8.60646 (* 1 = 8.60646 loss)
I0813 16:59:48.249614  1670 sgd_solver.cpp:138] Iteration 200, lr = 0.0001
I0813 17:09:09.276800  1670 solver.cpp:243] Iteration 300, loss = 6.80143
I0813 17:09:09.278059  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.78952 (* 1 = 6.78952 loss)
I0813 17:09:09.278065  1670 sgd_solver.cpp:138] Iteration 300, lr = 0.0001
I0813 17:18:31.922662  1670 solver.cpp:243] Iteration 400, loss = 7.50721
I0813 17:18:31.923009  1670 solver.cpp:259]     Train net output #0: mbox_loss = 8.6044 (* 1 = 8.6044 loss)
I0813 17:18:31.923017  1670 sgd_solver.cpp:138] Iteration 400, lr = 0.0001
I0813 17:27:51.540524  1670 solver.cpp:243] Iteration 500, loss = 6.15214
I0813 17:27:51.542363  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.64977 (* 1 = 6.64977 loss)
I0813 17:27:51.542369  1670 sgd_solver.cpp:138] Iteration 500, lr = 0.0001
I0813 17:37:14.480141  1670 solver.cpp:243] Iteration 600, loss = 6.80073
I0813 17:37:14.481413  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.38404 (* 1 = 5.38404 loss)
I0813 17:37:14.481420  1670 sgd_solver.cpp:138] Iteration 600, lr = 0.0001
I0813 17:46:32.791539  1670 solver.cpp:243] Iteration 700, loss = 5.60695
I0813 17:46:32.791612  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.04732 (* 1 = 6.04732 loss)
I0813 17:46:32.791618  1670 sgd_solver.cpp:138] Iteration 700, lr = 0.0001
I0813 17:55:55.137475  1670 solver.cpp:243] Iteration 800, loss = 6.12376
I0813 17:55:55.138710  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.85464 (* 1 = 5.85464 loss)
I0813 17:55:55.138716  1670 sgd_solver.cpp:138] Iteration 800, lr = 0.0001
I0813 18:05:12.439291  1670 solver.cpp:243] Iteration 900, loss = 5.48812
I0813 18:05:12.442090  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.30899 (* 1 = 4.30899 loss)
I0813 18:05:12.442095  1670 sgd_solver.cpp:138] Iteration 900, lr = 0.0001
I0813 18:14:34.368908  1670 solver.cpp:243] Iteration 1000, loss = 5.79803
I0813 18:14:34.370277  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.24915 (* 1 = 5.24915 loss)
I0813 18:14:34.370285  1670 sgd_solver.cpp:138] Iteration 1000, lr = 0.0001
I0813 18:23:51.211108  1670 solver.cpp:243] Iteration 1100, loss = 5.31729
I0813 18:23:51.212019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.25972 (* 1 = 5.25972 loss)
I0813 18:23:51.212026  1670 sgd_solver.cpp:138] Iteration 1100, lr = 0.0001
I0813 18:33:12.836381  1670 solver.cpp:243] Iteration 1200, loss = 5.4988
I0813 18:33:12.837576  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.29912 (* 1 = 6.29912 loss)
I0813 18:33:12.837582  1670 sgd_solver.cpp:138] Iteration 1200, lr = 0.0001
I0813 18:42:28.191671  1670 solver.cpp:243] Iteration 1300, loss = 5.25925
I0813 18:42:28.191959  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.64696 (* 1 = 4.64696 loss)
I0813 18:42:28.191965  1670 sgd_solver.cpp:138] Iteration 1300, lr = 0.0001
I0813 18:51:49.864233  1670 solver.cpp:243] Iteration 1400, loss = 6.13833
I0813 18:51:49.865499  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.20883 (* 1 = 4.20883 loss)
I0813 18:51:49.865505  1670 sgd_solver.cpp:138] Iteration 1400, lr = 0.0001
I0813 19:01:04.655004  1670 solver.cpp:243] Iteration 1500, loss = 5.11
I0813 19:01:04.655983  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.02659 (* 1 = 6.02659 loss)
I0813 19:01:04.655989  1670 sgd_solver.cpp:138] Iteration 1500, lr = 0.0001
I0813 19:10:26.841413  1670 solver.cpp:243] Iteration 1600, loss = 6.19542
I0813 19:10:26.842660  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.188 (* 1 = 6.188 loss)
I0813 19:10:26.842666  1670 sgd_solver.cpp:138] Iteration 1600, lr = 0.0001
I0813 19:19:41.959779  1670 solver.cpp:243] Iteration 1700, loss = 4.94542
I0813 19:19:41.960053  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.22624 (* 1 = 4.22624 loss)
I0813 19:19:41.960060  1670 sgd_solver.cpp:138] Iteration 1700, lr = 0.0001
I0813 19:29:04.284745  1670 solver.cpp:243] Iteration 1800, loss = 5.83741
I0813 19:29:04.286082  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.84781 (* 1 = 5.84781 loss)
I0813 19:29:04.286088  1670 sgd_solver.cpp:138] Iteration 1800, lr = 0.0001
I0813 19:38:19.384395  1670 solver.cpp:243] Iteration 1900, loss = 4.85612
I0813 19:38:19.385620  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.75223 (* 1 = 4.75223 loss)
I0813 19:38:19.385627  1670 sgd_solver.cpp:138] Iteration 1900, lr = 0.0001
I0813 19:47:41.881119  1670 solver.cpp:243] Iteration 2000, loss = 5.17569
I0813 19:47:41.882342  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.02365 (* 1 = 6.02365 loss)
I0813 19:47:41.882349  1670 sgd_solver.cpp:138] Iteration 2000, lr = 0.0001
I0813 19:56:56.200059  1670 solver.cpp:243] Iteration 2100, loss = 4.76228
I0813 19:56:56.200137  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.82048 (* 1 = 4.82048 loss)
I0813 19:56:56.200143  1670 sgd_solver.cpp:138] Iteration 2100, lr = 0.0001
I0813 20:06:18.863778  1670 solver.cpp:243] Iteration 2200, loss = 5.45241
I0813 20:06:18.865046  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.1341 (* 1 = 6.1341 loss)
I0813 20:06:18.865051  1670 sgd_solver.cpp:138] Iteration 2200, lr = 0.0001
I0813 20:15:36.726054  1670 solver.cpp:243] Iteration 2300, loss = 6.06027
I0813 20:15:36.727329  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.87433 (* 1 = 6.87433 loss)
I0813 20:15:36.727336  1670 sgd_solver.cpp:138] Iteration 2300, lr = 0.0001
I0813 20:24:57.673550  1670 solver.cpp:243] Iteration 2400, loss = 5.12332
I0813 20:24:57.674826  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.84947 (* 1 = 4.84947 loss)
I0813 20:24:57.674834  1670 sgd_solver.cpp:138] Iteration 2400, lr = 0.0001
I0813 20:34:17.777087  1670 solver.cpp:243] Iteration 2500, loss = 6.38604
I0813 20:34:17.778486  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.25458 (* 1 = 6.25458 loss)
I0813 20:34:17.778491  1670 sgd_solver.cpp:138] Iteration 2500, lr = 0.0001
I0813 20:43:37.450094  1670 solver.cpp:243] Iteration 2600, loss = 5.11735
I0813 20:43:37.451361  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.26675 (* 1 = 5.26675 loss)
I0813 20:43:37.451367  1670 sgd_solver.cpp:138] Iteration 2600, lr = 0.0001
I0813 20:52:59.346223  1670 solver.cpp:243] Iteration 2700, loss = 6.13574
I0813 20:52:59.347600  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.55104 (* 1 = 5.55104 loss)
I0813 20:52:59.347609  1670 sgd_solver.cpp:138] Iteration 2700, lr = 0.0001
I0813 21:02:18.457415  1670 solver.cpp:243] Iteration 2800, loss = 5.00638
I0813 21:02:18.458669  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.96164 (* 1 = 4.96164 loss)
I0813 21:02:18.458675  1670 sgd_solver.cpp:138] Iteration 2800, lr = 0.0001
I0813 21:11:40.377499  1670 solver.cpp:243] Iteration 2900, loss = 5.38939
I0813 21:11:40.378943  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.12181 (* 1 = 5.12181 loss)
I0813 21:11:40.378952  1670 sgd_solver.cpp:138] Iteration 2900, lr = 0.0001
I0813 21:20:58.555212  1670 solver.cpp:243] Iteration 3000, loss = 4.61025
I0813 21:20:58.555951  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.50617 (* 1 = 4.50617 loss)
I0813 21:20:58.555959  1670 sgd_solver.cpp:138] Iteration 3000, lr = 0.0001
I0813 21:30:21.730190  1670 solver.cpp:243] Iteration 3100, loss = 5.06278
I0813 21:30:21.731490  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.40834 (* 1 = 4.40834 loss)
I0813 21:30:21.731497  1670 sgd_solver.cpp:138] Iteration 3100, lr = 0.0001
I0813 21:39:39.711236  1670 solver.cpp:243] Iteration 3200, loss = 4.62209
I0813 21:39:39.713227  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.14304 (* 1 = 5.14304 loss)
I0813 21:39:39.713237  1670 sgd_solver.cpp:138] Iteration 3200, lr = 0.0001
I0813 21:49:02.165908  1670 solver.cpp:243] Iteration 3300, loss = 4.81031
I0813 21:49:02.166038  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.93021 (* 1 = 4.93021 loss)
I0813 21:49:02.166045  1670 sgd_solver.cpp:138] Iteration 3300, lr = 0.0001
I0813 21:58:20.004798  1670 solver.cpp:243] Iteration 3400, loss = 4.41352
I0813 21:58:20.006043  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.71905 (* 1 = 3.71905 loss)
I0813 21:58:20.006049  1670 sgd_solver.cpp:138] Iteration 3400, lr = 0.0001
I0813 22:07:43.743643  1670 solver.cpp:243] Iteration 3500, loss = 4.99731
I0813 22:07:43.743891  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.94575 (* 1 = 5.94575 loss)
I0813 22:07:43.743897  1670 sgd_solver.cpp:138] Iteration 3500, lr = 0.0001
I0813 22:17:01.500552  1670 solver.cpp:243] Iteration 3600, loss = 4.32937
I0813 22:17:01.501852  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.23227 (* 1 = 4.23227 loss)
I0813 22:17:01.501859  1670 sgd_solver.cpp:138] Iteration 3600, lr = 0.0001
I0813 22:26:25.647732  1670 solver.cpp:243] Iteration 3700, loss = 5.66495
I0813 22:26:25.647914  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.57634 (* 1 = 5.57634 loss)
I0813 22:26:25.647920  1670 sgd_solver.cpp:138] Iteration 3700, lr = 0.0001
I0813 22:35:43.016832  1670 solver.cpp:243] Iteration 3800, loss = 4.32649
I0813 22:35:43.018054  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.39607 (* 1 = 5.39607 loss)
I0813 22:35:43.018060  1670 sgd_solver.cpp:138] Iteration 3800, lr = 0.0001
I0813 22:45:07.376602  1670 solver.cpp:243] Iteration 3900, loss = 5.66541
I0813 22:45:07.378154  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.45651 (* 1 = 5.45651 loss)
I0813 22:45:07.378160  1670 sgd_solver.cpp:138] Iteration 3900, lr = 0.0001
I0813 22:54:24.374660  1670 solver.cpp:243] Iteration 4000, loss = 4.3057
I0813 22:54:24.375509  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.28817 (* 1 = 4.28817 loss)
I0813 22:54:24.375516  1670 sgd_solver.cpp:138] Iteration 4000, lr = 0.0001
I0813 23:03:48.495431  1670 solver.cpp:243] Iteration 4100, loss = 4.85008
I0813 23:03:48.496990  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.06372 (* 1 = 5.06372 loss)
I0813 23:03:48.496996  1670 sgd_solver.cpp:138] Iteration 4100, lr = 0.0001
I0813 23:13:05.231416  1670 solver.cpp:243] Iteration 4200, loss = 4.37022
I0813 23:13:05.231962  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.22498 (* 1 = 4.22498 loss)
I0813 23:13:05.231969  1670 sgd_solver.cpp:138] Iteration 4200, lr = 0.0001
I0813 23:22:29.370453  1670 solver.cpp:243] Iteration 4300, loss = 4.58215
I0813 23:22:29.371732  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.33469 (* 1 = 4.33469 loss)
I0813 23:22:29.371742  1670 sgd_solver.cpp:138] Iteration 4300, lr = 0.0001
I0813 23:31:46.123735  1670 solver.cpp:243] Iteration 4400, loss = 3.45761
I0813 23:31:46.123955  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.24047 (* 1 = 2.24047 loss)
I0813 23:31:46.123963  1670 sgd_solver.cpp:138] Iteration 4400, lr = 0.0001
I0813 23:41:10.479686  1670 solver.cpp:243] Iteration 4500, loss = 4.71357
I0813 23:41:10.481613  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.95687 (* 1 = 4.95687 loss)
I0813 23:41:10.481621  1670 sgd_solver.cpp:138] Iteration 4500, lr = 0.0001
I0813 23:50:30.999136  1670 solver.cpp:243] Iteration 4600, loss = 6.34727
I0813 23:50:30.999985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.69967 (* 1 = 5.69967 loss)
I0813 23:50:30.999991  1670 sgd_solver.cpp:138] Iteration 4600, lr = 0.0001
I0813 23:59:51.429384  1670 solver.cpp:243] Iteration 4700, loss = 4.55215
I0813 23:59:51.430685  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.54619 (* 1 = 4.54619 loss)
I0813 23:59:51.430691  1670 sgd_solver.cpp:138] Iteration 4700, lr = 0.0001
I0814 00:09:12.510208  1670 solver.cpp:243] Iteration 4800, loss = 5.65364
I0814 00:09:12.511471  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.0342 (* 1 = 6.0342 loss)
I0814 00:09:12.511477  1670 sgd_solver.cpp:138] Iteration 4800, lr = 0.0001
I0814 00:18:32.196519  1670 solver.cpp:243] Iteration 4900, loss = 4.55184
I0814 00:18:32.197684  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.66047 (* 1 = 3.66047 loss)
I0814 00:18:32.197690  1670 sgd_solver.cpp:138] Iteration 4900, lr = 0.0001
I0814 00:27:54.744489  1670 solver.cpp:243] Iteration 5000, loss = 5.25869
I0814 00:27:54.745642  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.46612 (* 1 = 4.46612 loss)
I0814 00:27:54.745648  1670 sgd_solver.cpp:138] Iteration 5000, lr = 0.0001
I0814 00:37:13.852376  1670 solver.cpp:243] Iteration 5100, loss = 4.21933
I0814 00:37:13.854285  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.55165 (* 1 = 4.55165 loss)
I0814 00:37:13.854291  1670 sgd_solver.cpp:138] Iteration 5100, lr = 0.0001
I0814 00:46:36.833871  1670 solver.cpp:243] Iteration 5200, loss = 4.85611
I0814 00:46:36.835237  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.45938 (* 1 = 4.45938 loss)
I0814 00:46:36.835242  1670 sgd_solver.cpp:138] Iteration 5200, lr = 0.0001
I0814 00:55:55.161748  1670 solver.cpp:243] Iteration 5300, loss = 4.27231
I0814 00:55:55.162715  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.6299 (* 1 = 5.6299 loss)
I0814 00:55:55.162724  1670 sgd_solver.cpp:138] Iteration 5300, lr = 0.0001
I0814 01:05:18.087792  1670 solver.cpp:243] Iteration 5400, loss = 4.46088
I0814 01:05:18.087977  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.91853 (* 1 = 3.91853 loss)
I0814 01:05:18.087983  1670 sgd_solver.cpp:138] Iteration 5400, lr = 0.0001
I0814 01:14:36.001652  1670 solver.cpp:243] Iteration 5500, loss = 4.06352
I0814 01:14:36.001730  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.51245 (* 1 = 3.51245 loss)
I0814 01:14:36.001736  1670 sgd_solver.cpp:138] Iteration 5500, lr = 0.0001
I0814 01:23:59.801671  1670 solver.cpp:243] Iteration 5600, loss = 4.43412
I0814 01:23:59.802230  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.15702 (* 1 = 4.15702 loss)
I0814 01:23:59.802237  1670 sgd_solver.cpp:138] Iteration 5600, lr = 0.0001
I0814 01:33:18.022249  1670 solver.cpp:243] Iteration 5700, loss = 3.8476
I0814 01:33:18.023530  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.14107 (* 1 = 4.14107 loss)
I0814 01:33:18.023536  1670 sgd_solver.cpp:138] Iteration 5700, lr = 0.0001
I0814 01:42:42.482054  1670 solver.cpp:243] Iteration 5800, loss = 4.8305
I0814 01:42:42.483590  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.7071 (* 1 = 5.7071 loss)
I0814 01:42:42.483597  1670 sgd_solver.cpp:138] Iteration 5800, lr = 0.0001
I0814 01:51:59.801225  1670 solver.cpp:243] Iteration 5900, loss = 3.87131
I0814 01:51:59.802455  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.28461 (* 1 = 5.28461 loss)
I0814 01:51:59.802460  1670 sgd_solver.cpp:138] Iteration 5900, lr = 0.0001
I0814 02:01:24.260505  1670 solver.cpp:243] Iteration 6000, loss = 5.08772
I0814 02:01:24.260588  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.25164 (* 1 = 4.25164 loss)
I0814 02:01:24.260596  1670 sgd_solver.cpp:138] Iteration 6000, lr = 0.0001
I0814 02:10:41.651708  1670 solver.cpp:243] Iteration 6100, loss = 4.12814
I0814 02:10:41.653682  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.89336 (* 1 = 3.89336 loss)
I0814 02:10:41.653703  1670 sgd_solver.cpp:138] Iteration 6100, lr = 0.0001
I0814 02:20:06.152801  1670 solver.cpp:243] Iteration 6200, loss = 4.71931
I0814 02:20:06.154188  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.87393 (* 1 = 2.87393 loss)
I0814 02:20:06.154196  1670 sgd_solver.cpp:138] Iteration 6200, lr = 0.0001
I0814 02:29:23.576970  1670 solver.cpp:243] Iteration 6300, loss = 3.95143
I0814 02:29:23.577571  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.89457 (* 1 = 4.89457 loss)
I0814 02:29:23.577579  1670 sgd_solver.cpp:138] Iteration 6300, lr = 0.0001
I0814 02:38:48.056061  1670 solver.cpp:243] Iteration 6400, loss = 4.11542
I0814 02:38:48.057340  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.00579 (* 1 = 3.00579 loss)
I0814 02:38:48.057346  1670 sgd_solver.cpp:138] Iteration 6400, lr = 0.0001
I0814 02:48:05.270525  1670 solver.cpp:243] Iteration 6500, loss = 3.62483
I0814 02:48:05.271765  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.22004 (* 1 = 3.22004 loss)
I0814 02:48:05.271775  1670 sgd_solver.cpp:138] Iteration 6500, lr = 0.0001
I0814 02:57:30.746425  1670 solver.cpp:243] Iteration 6600, loss = 4.29961
I0814 02:57:30.747685  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.76341 (* 1 = 4.76341 loss)
I0814 02:57:30.747694  1670 sgd_solver.cpp:138] Iteration 6600, lr = 0.0001
I0814 03:06:50.167800  1670 solver.cpp:243] Iteration 6700, loss = 4.21767
I0814 03:06:50.167979  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.64241 (* 1 = 5.64241 loss)
I0814 03:06:50.167987  1670 sgd_solver.cpp:138] Iteration 6700, lr = 0.0001
I0814 03:16:12.576710  1670 solver.cpp:243] Iteration 6800, loss = 4.15261
I0814 03:16:12.577927  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.45012 (* 1 = 2.45012 loss)
I0814 03:16:12.577934  1670 sgd_solver.cpp:138] Iteration 6800, lr = 0.0001
I0814 03:25:33.748754  1670 solver.cpp:243] Iteration 6900, loss = 5.89179
I0814 03:25:33.750289  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.20352 (* 1 = 4.20352 loss)
I0814 03:25:33.750295  1670 sgd_solver.cpp:138] Iteration 6900, lr = 0.0001
I0814 03:34:54.325356  1670 solver.cpp:243] Iteration 7000, loss = 4.18221
I0814 03:34:54.327195  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.816 (* 1 = 4.816 loss)
I0814 03:34:54.327203  1670 sgd_solver.cpp:138] Iteration 7000, lr = 0.0001
I0814 03:44:15.934716  1670 solver.cpp:243] Iteration 7100, loss = 5.36776
I0814 03:44:15.936064  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.38965 (* 1 = 6.38965 loss)
I0814 03:44:15.936070  1670 sgd_solver.cpp:138] Iteration 7100, lr = 0.0001
I0814 03:53:35.879515  1670 solver.cpp:243] Iteration 7200, loss = 4.11451
I0814 03:53:35.879966  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.21495 (* 1 = 4.21495 loss)
I0814 03:53:35.879971  1670 sgd_solver.cpp:138] Iteration 7200, lr = 0.0001
I0814 04:02:58.571152  1670 solver.cpp:243] Iteration 7300, loss = 4.59972
I0814 04:02:58.572461  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.05623 (* 1 = 5.05623 loss)
I0814 04:02:58.572468  1670 sgd_solver.cpp:138] Iteration 7300, lr = 0.0001
I0814 04:12:17.605965  1670 solver.cpp:243] Iteration 7400, loss = 3.69611
I0814 04:12:17.607326  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.22431 (* 1 = 4.22431 loss)
I0814 04:12:17.607334  1670 sgd_solver.cpp:138] Iteration 7400, lr = 0.0001
I0814 04:21:41.453431  1670 solver.cpp:243] Iteration 7500, loss = 4.43877
I0814 04:21:41.454769  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.03328 (* 1 = 4.03328 loss)
I0814 04:21:41.454774  1670 sgd_solver.cpp:138] Iteration 7500, lr = 0.0001
I0814 04:30:59.769713  1670 solver.cpp:243] Iteration 7600, loss = 3.91007
I0814 04:30:59.770998  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.17556 (* 1 = 3.17556 loss)
I0814 04:30:59.771004  1670 sgd_solver.cpp:138] Iteration 7600, lr = 0.0001
I0814 04:40:24.172216  1670 solver.cpp:243] Iteration 7700, loss = 4.02633
I0814 04:40:24.173400  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.94922 (* 1 = 4.94922 loss)
I0814 04:40:24.173408  1670 sgd_solver.cpp:138] Iteration 7700, lr = 0.0001
I0814 04:49:42.842646  1670 solver.cpp:243] Iteration 7800, loss = 3.34687
I0814 04:49:42.843930  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.87354 (* 1 = 1.87354 loss)
I0814 04:49:42.843945  1670 sgd_solver.cpp:138] Iteration 7800, lr = 0.0001
I0814 04:59:04.829607  1670 solver.cpp:243] Iteration 7900, loss = 4.09481
I0814 04:59:04.830950  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.46531 (* 1 = 5.46531 loss)
I0814 04:59:04.830960  1670 sgd_solver.cpp:138] Iteration 7900, lr = 0.0001
I0814 05:08:22.497215  1670 solver.cpp:243] Iteration 8000, loss = 3.44162
I0814 05:08:22.498421  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.49283 (* 1 = 3.49283 loss)
I0814 05:08:22.498427  1670 sgd_solver.cpp:138] Iteration 8000, lr = 0.0001
I0814 05:17:46.820489  1670 solver.cpp:243] Iteration 8100, loss = 4.77983
I0814 05:17:46.821853  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.46104 (* 1 = 5.46104 loss)
I0814 05:17:46.821861  1670 sgd_solver.cpp:138] Iteration 8100, lr = 0.0001
I0814 05:27:04.476677  1670 solver.cpp:243] Iteration 8200, loss = 3.63423
I0814 05:27:04.477919  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.33188 (* 1 = 3.33188 loss)
I0814 05:27:04.477926  1670 sgd_solver.cpp:138] Iteration 8200, lr = 0.0001
I0814 05:36:29.481070  1670 solver.cpp:243] Iteration 8300, loss = 4.787
I0814 05:36:29.482275  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.56416 (* 1 = 4.56416 loss)
I0814 05:36:29.482281  1670 sgd_solver.cpp:138] Iteration 8300, lr = 0.0001
I0814 05:45:47.465216  1670 solver.cpp:243] Iteration 8400, loss = 3.8558
I0814 05:45:47.466526  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.18471 (* 1 = 3.18471 loss)
I0814 05:45:47.466531  1670 sgd_solver.cpp:138] Iteration 8400, lr = 0.0001
I0814 05:55:11.827211  1670 solver.cpp:243] Iteration 8500, loss = 4.20699
I0814 05:55:11.828246  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.64684 (* 1 = 4.64684 loss)
I0814 05:55:11.828253  1670 sgd_solver.cpp:138] Iteration 8500, lr = 0.0001
I0814 06:04:29.386845  1670 solver.cpp:243] Iteration 8600, loss = 3.67689
I0814 06:04:29.388023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.66918 (* 1 = 3.66918 loss)
I0814 06:04:29.388031  1670 sgd_solver.cpp:138] Iteration 8600, lr = 0.0001
I0814 06:13:53.043249  1670 solver.cpp:243] Iteration 8700, loss = 3.76097
I0814 06:13:53.043341  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.29303 (* 1 = 5.29303 loss)
I0814 06:13:53.043347  1670 sgd_solver.cpp:138] Iteration 8700, lr = 0.0001
I0814 06:23:09.918012  1670 solver.cpp:243] Iteration 8800, loss = 3.02161
I0814 06:23:09.919279  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.33783 (* 1 = 3.33783 loss)
I0814 06:23:09.919286  1670 sgd_solver.cpp:138] Iteration 8800, lr = 0.0001
I0814 06:32:34.823915  1670 solver.cpp:243] Iteration 8900, loss = 4.0181
I0814 06:32:34.825126  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.28086 (* 1 = 4.28086 loss)
I0814 06:32:34.825132  1670 sgd_solver.cpp:138] Iteration 8900, lr = 0.0001
I0814 06:41:55.238548  1670 solver.cpp:243] Iteration 9000, loss = 5.17298
I0814 06:41:55.239845  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.88066 (* 1 = 6.88066 loss)
I0814 06:41:55.239852  1670 sgd_solver.cpp:138] Iteration 9000, lr = 0.0001
I0814 06:51:16.694281  1670 solver.cpp:243] Iteration 9100, loss = 3.97976
I0814 06:51:16.695536  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.3278 (* 1 = 4.3278 loss)
I0814 06:51:16.695544  1670 sgd_solver.cpp:138] Iteration 9100, lr = 0.0001
I0814 07:00:38.951300  1670 solver.cpp:243] Iteration 9200, loss = 5.17808
I0814 07:00:38.953294  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.73562 (* 1 = 5.73562 loss)
I0814 07:00:38.953302  1670 sgd_solver.cpp:138] Iteration 9200, lr = 0.0001
I0814 07:09:59.500246  1670 solver.cpp:243] Iteration 9300, loss = 4.10033
I0814 07:09:59.500988  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.24654 (* 1 = 4.24654 loss)
I0814 07:09:59.500995  1670 sgd_solver.cpp:138] Iteration 9300, lr = 0.0001
I0814 07:19:21.751272  1670 solver.cpp:243] Iteration 9400, loss = 4.83146
I0814 07:19:21.752053  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.95503 (* 1 = 4.95503 loss)
I0814 07:19:21.752060  1670 sgd_solver.cpp:138] Iteration 9400, lr = 0.0001
I0814 07:28:41.230309  1670 solver.cpp:243] Iteration 9500, loss = 3.79119
I0814 07:28:41.231580  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.99622 (* 1 = 4.99622 loss)
I0814 07:28:41.231586  1670 sgd_solver.cpp:138] Iteration 9500, lr = 0.0001
I0814 07:38:04.471828  1670 solver.cpp:243] Iteration 9600, loss = 4.44924
I0814 07:38:04.472168  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.62007 (* 1 = 4.62007 loss)
I0814 07:38:04.472174  1670 sgd_solver.cpp:138] Iteration 9600, lr = 0.0001
I0814 07:47:23.759863  1670 solver.cpp:243] Iteration 9700, loss = 3.51937
I0814 07:47:23.761127  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.70329 (* 1 = 3.70329 loss)
I0814 07:47:23.761133  1670 sgd_solver.cpp:138] Iteration 9700, lr = 0.0001
I0814 07:56:47.661680  1670 solver.cpp:243] Iteration 9800, loss = 3.96292
I0814 07:56:47.662937  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.44762 (* 1 = 4.44762 loss)
I0814 07:56:47.662945  1670 sgd_solver.cpp:138] Iteration 9800, lr = 0.0001
I0814 08:06:06.464046  1670 solver.cpp:243] Iteration 9900, loss = 3.56892
I0814 08:06:06.465250  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.69913 (* 1 = 3.69913 loss)
I0814 08:06:06.465255  1670 sgd_solver.cpp:138] Iteration 9900, lr = 0.0001
I0814 08:15:24.402076  1670 solver.cpp:433] Iteration 10000, Testing net (#0)
I0814 08:15:24.883929  1670 net.cpp:693] Ignoring source layer mbox_loss
W0814 08:18:01.247814  1670 solver.cpp:524] Missing true_pos for label: 10
W0814 08:18:01.247927  1670 solver.cpp:524] Missing true_pos for label: 17
W0814 08:18:01.247937  1670 solver.cpp:524] Missing true_pos for label: 19
W0814 08:18:01.247941  1670 solver.cpp:524] Missing true_pos for label: 20
W0814 08:18:01.247954  1670 solver.cpp:524] Missing true_pos for label: 22
I0814 08:18:01.247958  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.155435
I0814 08:18:06.394847  1670 solver.cpp:243] Iteration 10000, loss = 3.97173
I0814 08:18:06.394871  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.42292 (* 1 = 4.42292 loss)
I0814 08:18:06.394877  1670 sgd_solver.cpp:138] Iteration 10000, lr = 0.0001
I0814 08:27:24.592476  1670 solver.cpp:243] Iteration 10100, loss = 3.25874
I0814 08:27:24.594017  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.82429 (* 1 = 1.82429 loss)
I0814 08:27:24.594023  1670 sgd_solver.cpp:138] Iteration 10100, lr = 0.0001
I0814 08:36:49.276429  1670 solver.cpp:243] Iteration 10200, loss = 4.14816
I0814 08:36:49.277644  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.35508 (* 1 = 6.35508 loss)
I0814 08:36:49.277652  1670 sgd_solver.cpp:138] Iteration 10200, lr = 0.0001
I0814 08:46:07.470885  1670 solver.cpp:243] Iteration 10300, loss = 3.27991
I0814 08:46:07.470963  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.83786 (* 1 = 1.83786 loss)
I0814 08:46:07.470970  1670 sgd_solver.cpp:138] Iteration 10300, lr = 0.0001
I0814 08:55:32.850001  1670 solver.cpp:243] Iteration 10400, loss = 4.56119
I0814 08:55:32.851279  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.94805 (* 1 = 4.94805 loss)
I0814 08:55:32.851286  1670 sgd_solver.cpp:138] Iteration 10400, lr = 0.0001
I0814 09:04:50.831894  1670 solver.cpp:243] Iteration 10500, loss = 3.72173
I0814 09:04:50.832051  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.11923 (* 1 = 4.11923 loss)
I0814 09:04:50.832057  1670 sgd_solver.cpp:138] Iteration 10500, lr = 0.0001
I0814 09:14:15.466851  1670 solver.cpp:243] Iteration 10600, loss = 4.39031
I0814 09:14:15.468394  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.60806 (* 1 = 3.60806 loss)
I0814 09:14:15.468400  1670 sgd_solver.cpp:138] Iteration 10600, lr = 0.0001
I0814 09:23:33.617043  1670 solver.cpp:243] Iteration 10700, loss = 3.6299
I0814 09:23:33.618309  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.74099 (* 1 = 3.74099 loss)
I0814 09:23:33.618315  1670 sgd_solver.cpp:138] Iteration 10700, lr = 0.0001
I0814 09:32:59.085172  1670 solver.cpp:243] Iteration 10800, loss = 3.68799
I0814 09:32:59.086380  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.56857 (* 1 = 4.56857 loss)
I0814 09:32:59.086387  1670 sgd_solver.cpp:138] Iteration 10800, lr = 0.0001
I0814 09:42:16.107331  1670 solver.cpp:243] Iteration 10900, loss = 3.46015
I0814 09:42:16.108026  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.44343 (* 1 = 3.44343 loss)
I0814 09:42:16.108033  1670 sgd_solver.cpp:138] Iteration 10900, lr = 0.0001
I0814 09:51:40.847712  1670 solver.cpp:243] Iteration 11000, loss = 3.69518
I0814 09:51:40.847970  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.53822 (* 1 = 3.53822 loss)
I0814 09:51:40.847975  1670 sgd_solver.cpp:138] Iteration 11000, lr = 0.0001
I0814 10:00:58.638087  1670 solver.cpp:243] Iteration 11100, loss = 3.13288
I0814 10:00:58.639477  1670 solver.cpp:259]     Train net output #0: mbox_loss = 7.7092 (* 1 = 7.7092 loss)
I0814 10:00:58.639487  1670 sgd_solver.cpp:138] Iteration 11100, lr = 0.0001
I0814 10:10:20.952600  1670 solver.cpp:243] Iteration 11200, loss = 3.92125
I0814 10:10:20.952673  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.40213 (* 1 = 4.40213 loss)
I0814 10:10:20.952679  1670 sgd_solver.cpp:138] Iteration 11200, lr = 0.0001
I0814 10:19:41.224654  1670 solver.cpp:243] Iteration 11300, loss = 6.05504
I0814 10:19:41.225921  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.37882 (* 1 = 5.37882 loss)
I0814 10:19:41.225927  1670 sgd_solver.cpp:138] Iteration 11300, lr = 0.0001
I0814 10:29:00.945466  1670 solver.cpp:243] Iteration 11400, loss = 3.78072
I0814 10:29:00.945781  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.20725 (* 1 = 4.20725 loss)
I0814 10:29:00.945787  1670 sgd_solver.cpp:138] Iteration 11400, lr = 0.0001
I0814 10:38:21.182593  1670 solver.cpp:243] Iteration 11500, loss = 4.94673
I0814 10:38:21.182679  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.66892 (* 1 = 5.66892 loss)
I0814 10:38:21.182685  1670 sgd_solver.cpp:138] Iteration 11500, lr = 0.0001
I0814 10:47:39.528494  1670 solver.cpp:243] Iteration 11600, loss = 3.88481
I0814 10:47:39.529741  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.26943 (* 1 = 4.26943 loss)
I0814 10:47:39.529747  1670 sgd_solver.cpp:138] Iteration 11600, lr = 0.0001
I0814 10:57:01.636334  1670 solver.cpp:243] Iteration 11700, loss = 4.50475
I0814 10:57:01.637643  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.589 (* 1 = 5.589 loss)
I0814 10:57:01.637650  1670 sgd_solver.cpp:138] Iteration 11700, lr = 0.0001
I0814 11:06:19.446792  1670 solver.cpp:243] Iteration 11800, loss = 3.49636
I0814 11:06:19.447950  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.34863 (* 1 = 2.34863 loss)
I0814 11:06:19.447957  1670 sgd_solver.cpp:138] Iteration 11800, lr = 0.0001
I0814 11:15:41.102697  1670 solver.cpp:243] Iteration 11900, loss = 4.17103
I0814 11:15:41.103965  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.03776 (* 1 = 4.03776 loss)
I0814 11:15:41.103972  1670 sgd_solver.cpp:138] Iteration 11900, lr = 0.0001
I0814 11:24:57.851212  1670 solver.cpp:243] Iteration 12000, loss = 3.59564
I0814 11:24:57.852447  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.28428 (* 1 = 4.28428 loss)
I0814 11:24:57.852453  1670 sgd_solver.cpp:138] Iteration 12000, lr = 0.0001
I0814 11:34:19.217944  1670 solver.cpp:243] Iteration 12100, loss = 3.76583
I0814 11:34:19.219158  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.42838 (* 1 = 3.42838 loss)
I0814 11:34:19.219172  1670 sgd_solver.cpp:138] Iteration 12100, lr = 0.0001
I0814 11:43:36.048208  1670 solver.cpp:243] Iteration 12200, loss = 3.17316
I0814 11:43:36.049444  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.08085 (* 1 = 3.08085 loss)
I0814 11:43:36.049451  1670 sgd_solver.cpp:138] Iteration 12200, lr = 0.0001
I0814 11:52:58.192097  1670 solver.cpp:243] Iteration 12300, loss = 3.79362
I0814 11:52:58.193361  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.78097 (* 1 = 3.78097 loss)
I0814 11:52:58.193367  1670 sgd_solver.cpp:138] Iteration 12300, lr = 0.0001
I0814 12:02:15.010848  1670 solver.cpp:243] Iteration 12400, loss = 3.00872
I0814 12:02:15.011968  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.64322 (* 1 = 3.64322 loss)
I0814 12:02:15.011987  1670 sgd_solver.cpp:138] Iteration 12400, lr = 0.0001
I0814 12:11:37.678426  1670 solver.cpp:243] Iteration 12500, loss = 4.14557
I0814 12:11:37.680018  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.7247 (* 1 = 3.7247 loss)
I0814 12:11:37.680024  1670 sgd_solver.cpp:138] Iteration 12500, lr = 0.0001
I0814 12:20:53.190129  1670 solver.cpp:243] Iteration 12600, loss = 3.31913
I0814 12:20:53.191383  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.75175 (* 1 = 3.75175 loss)
I0814 12:20:53.191390  1670 sgd_solver.cpp:138] Iteration 12600, lr = 0.0001
I0814 12:30:16.917385  1670 solver.cpp:243] Iteration 12700, loss = 4.20211
I0814 12:30:16.918622  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.33072 (* 1 = 4.33072 loss)
I0814 12:30:16.918627  1670 sgd_solver.cpp:138] Iteration 12700, lr = 0.0001
I0814 12:39:32.562183  1670 solver.cpp:243] Iteration 12800, loss = 3.49638
I0814 12:39:32.563500  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.83702 (* 1 = 2.83702 loss)
I0814 12:39:32.563506  1670 sgd_solver.cpp:138] Iteration 12800, lr = 0.0001
I0814 12:48:55.511312  1670 solver.cpp:243] Iteration 12900, loss = 4.04208
I0814 12:48:55.512003  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.87239 (* 1 = 3.87239 loss)
I0814 12:48:55.512012  1670 sgd_solver.cpp:138] Iteration 12900, lr = 0.0001
I0814 12:58:11.129904  1670 solver.cpp:243] Iteration 13000, loss = 3.45774
I0814 12:58:11.131208  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.26666 (* 1 = 4.26666 loss)
I0814 12:58:11.131216  1670 sgd_solver.cpp:138] Iteration 13000, lr = 0.0001
I0814 13:07:34.186452  1670 solver.cpp:243] Iteration 13100, loss = 3.49401
I0814 13:07:34.186533  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.58283 (* 1 = 4.58283 loss)
I0814 13:07:34.186540  1670 sgd_solver.cpp:138] Iteration 13100, lr = 0.0001
I0814 13:16:49.519798  1670 solver.cpp:243] Iteration 13200, loss = 2.79312
I0814 13:16:49.520030  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.05306 (* 1 = 1.05306 loss)
I0814 13:16:49.520038  1670 sgd_solver.cpp:138] Iteration 13200, lr = 0.0001
I0814 13:26:13.318132  1670 solver.cpp:243] Iteration 13300, loss = 3.7496
I0814 13:26:13.319397  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.59772 (* 1 = 3.59772 loss)
I0814 13:26:13.319404  1670 sgd_solver.cpp:138] Iteration 13300, lr = 0.0001
I0814 13:35:32.542346  1670 solver.cpp:243] Iteration 13400, loss = 4.35621
I0814 13:35:32.543586  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.0036 (* 1 = 5.0036 loss)
I0814 13:35:32.543599  1670 sgd_solver.cpp:138] Iteration 13400, lr = 0.0001
I0814 13:44:51.949193  1670 solver.cpp:243] Iteration 13500, loss = 3.66448
I0814 13:44:51.950368  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.31768 (* 1 = 4.31768 loss)
I0814 13:44:51.950374  1670 sgd_solver.cpp:138] Iteration 13500, lr = 0.0001
I0814 13:54:11.751461  1670 solver.cpp:243] Iteration 13600, loss = 5.10329
I0814 13:54:11.751996  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.94026 (* 1 = 4.94026 loss)
I0814 13:54:11.752002  1670 sgd_solver.cpp:138] Iteration 13600, lr = 0.0001
I0814 14:03:29.938055  1670 solver.cpp:243] Iteration 13700, loss = 3.81421
I0814 14:03:29.939368  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.39928 (* 1 = 2.39928 loss)
I0814 14:03:29.939376  1670 sgd_solver.cpp:138] Iteration 13700, lr = 0.0001
I0814 14:12:50.874722  1670 solver.cpp:243] Iteration 13800, loss = 4.74063
I0814 14:12:50.876031  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.4292 (* 1 = 3.4292 loss)
I0814 14:12:50.876037  1670 sgd_solver.cpp:138] Iteration 13800, lr = 0.0001
I0814 14:22:08.930557  1670 solver.cpp:243] Iteration 13900, loss = 3.57556
I0814 14:22:08.931787  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.50288 (* 1 = 4.50288 loss)
I0814 14:22:08.931794  1670 sgd_solver.cpp:138] Iteration 13900, lr = 0.0001
I0814 14:31:30.428627  1670 solver.cpp:243] Iteration 14000, loss = 4.34709
I0814 14:31:30.429801  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.39036 (* 1 = 4.39036 loss)
I0814 14:31:30.429807  1670 sgd_solver.cpp:138] Iteration 14000, lr = 0.0001
I0814 14:40:47.525028  1670 solver.cpp:243] Iteration 14100, loss = 3.37451
I0814 14:40:47.526173  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.2632 (* 1 = 3.2632 loss)
I0814 14:40:47.526180  1670 sgd_solver.cpp:138] Iteration 14100, lr = 0.0001
I0814 14:50:09.997706  1670 solver.cpp:243] Iteration 14200, loss = 3.87167
I0814 14:50:09.997781  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.56778 (* 1 = 3.56778 loss)
I0814 14:50:09.997787  1670 sgd_solver.cpp:138] Iteration 14200, lr = 0.0001
I0814 14:59:26.890013  1670 solver.cpp:243] Iteration 14300, loss = 3.40406
I0814 14:59:26.891368  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.70795 (* 1 = 2.70795 loss)
I0814 14:59:26.891378  1670 sgd_solver.cpp:138] Iteration 14300, lr = 0.0001
I0814 15:08:48.443779  1670 solver.cpp:243] Iteration 14400, loss = 3.63991
I0814 15:08:48.444241  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.27972 (* 1 = 4.27972 loss)
I0814 15:08:48.444247  1670 sgd_solver.cpp:138] Iteration 14400, lr = 0.0001
I0814 15:18:05.103569  1670 solver.cpp:243] Iteration 14500, loss = 2.9
I0814 15:18:05.103960  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85119 (* 1 = 2.85119 loss)
I0814 15:18:05.103967  1670 sgd_solver.cpp:138] Iteration 14500, lr = 0.0001
I0814 15:27:27.466210  1670 solver.cpp:243] Iteration 14600, loss = 3.7673
I0814 15:27:27.467495  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.48986 (* 1 = 1.48986 loss)
I0814 15:27:27.467502  1670 sgd_solver.cpp:138] Iteration 14600, lr = 0.0001
I0814 15:36:43.699906  1670 solver.cpp:243] Iteration 14700, loss = 3.00897
I0814 15:36:43.701052  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.40933 (* 1 = 3.40933 loss)
I0814 15:36:43.701059  1670 sgd_solver.cpp:138] Iteration 14700, lr = 0.0001
I0814 15:46:06.484465  1670 solver.cpp:243] Iteration 14800, loss = 4.25766
I0814 15:46:06.485654  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.10222 (* 1 = 4.10222 loss)
I0814 15:46:06.485661  1670 sgd_solver.cpp:138] Iteration 14800, lr = 0.0001
I0814 15:55:22.104732  1670 solver.cpp:243] Iteration 14900, loss = 3.26385
I0814 15:55:22.106034  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.84866 (* 1 = 2.84866 loss)
I0814 15:55:22.106040  1670 sgd_solver.cpp:138] Iteration 14900, lr = 0.0001
I0814 16:04:44.823632  1670 solver.cpp:243] Iteration 15000, loss = 4.16434
I0814 16:04:44.823945  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.95374 (* 1 = 3.95374 loss)
I0814 16:04:44.823951  1670 sgd_solver.cpp:138] Iteration 15000, lr = 0.0001
I0814 16:14:00.156843  1670 solver.cpp:243] Iteration 15100, loss = 3.39001
I0814 16:14:00.158030  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.79833 (* 1 = 2.79833 loss)
I0814 16:14:00.158037  1670 sgd_solver.cpp:138] Iteration 15100, lr = 0.0001
I0814 16:23:22.398277  1670 solver.cpp:243] Iteration 15200, loss = 3.69195
I0814 16:23:22.399508  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.04211 (* 1 = 4.04211 loss)
I0814 16:23:22.399518  1670 sgd_solver.cpp:138] Iteration 15200, lr = 0.0001
I0814 16:32:38.089644  1670 solver.cpp:243] Iteration 15300, loss = 3.3105
I0814 16:32:38.090895  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.25181 (* 1 = 3.25181 loss)
I0814 16:32:38.090904  1670 sgd_solver.cpp:138] Iteration 15300, lr = 0.0001
I0814 16:42:01.048262  1670 solver.cpp:243] Iteration 15400, loss = 3.34609
I0814 16:42:01.049757  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.07169 (* 1 = 4.07169 loss)
I0814 16:42:01.049763  1670 sgd_solver.cpp:138] Iteration 15400, lr = 0.0001
I0814 16:51:16.481802  1670 solver.cpp:243] Iteration 15500, loss = 2.30112
I0814 16:51:16.483048  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.58327 (* 1 = 1.58327 loss)
I0814 16:51:16.483054  1670 sgd_solver.cpp:138] Iteration 15500, lr = 0.0001
I0814 17:00:40.087039  1670 solver.cpp:243] Iteration 15600, loss = 3.72166
I0814 17:00:40.087958  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.3841 (* 1 = 2.3841 loss)
I0814 17:00:40.087965  1670 sgd_solver.cpp:138] Iteration 15600, lr = 0.0001
I0814 17:09:59.965087  1670 solver.cpp:243] Iteration 15700, loss = 5.74176
I0814 17:09:59.966373  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.49639 (* 1 = 4.49639 loss)
I0814 17:09:59.966379  1670 sgd_solver.cpp:138] Iteration 15700, lr = 0.0001
I0814 17:19:19.117379  1670 solver.cpp:243] Iteration 15800, loss = 3.60101
I0814 17:19:19.118588  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.77521 (* 1 = 1.77521 loss)
I0814 17:19:19.118595  1670 sgd_solver.cpp:138] Iteration 15800, lr = 0.0001
I0814 17:28:39.023126  1670 solver.cpp:243] Iteration 15900, loss = 4.75606
I0814 17:28:39.023972  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.38914 (* 1 = 5.38914 loss)
I0814 17:28:39.023979  1670 sgd_solver.cpp:138] Iteration 15900, lr = 0.0001
I0814 17:37:57.745208  1670 solver.cpp:243] Iteration 16000, loss = 3.62947
I0814 17:37:57.746448  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.195 (* 1 = 3.195 loss)
I0814 17:37:57.746454  1670 sgd_solver.cpp:138] Iteration 16000, lr = 0.0001
I0814 17:47:18.442946  1670 solver.cpp:243] Iteration 16100, loss = 4.43754
I0814 17:47:18.443892  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.77449 (* 1 = 4.77449 loss)
I0814 17:47:18.443897  1670 sgd_solver.cpp:138] Iteration 16100, lr = 0.0001
I0814 17:56:35.562906  1670 solver.cpp:243] Iteration 16200, loss = 3.30768
I0814 17:56:35.563998  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.50356 (* 1 = 3.50356 loss)
I0814 17:56:35.564004  1670 sgd_solver.cpp:138] Iteration 16200, lr = 0.0001
I0814 18:05:56.062935  1670 solver.cpp:243] Iteration 16300, loss = 3.98169
I0814 18:05:56.063032  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.41417 (* 1 = 3.41417 loss)
I0814 18:05:56.063040  1670 sgd_solver.cpp:138] Iteration 16300, lr = 0.0001
I0814 18:15:12.553679  1670 solver.cpp:243] Iteration 16400, loss = 3.43501
I0814 18:15:12.554982  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.55858 (* 1 = 4.55858 loss)
I0814 18:15:12.554988  1670 sgd_solver.cpp:138] Iteration 16400, lr = 0.0001
I0814 18:24:34.372385  1670 solver.cpp:243] Iteration 16500, loss = 3.56947
I0814 18:24:34.373639  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.7054 (* 1 = 4.7054 loss)
I0814 18:24:34.373646  1670 sgd_solver.cpp:138] Iteration 16500, lr = 0.0001
I0814 18:33:51.115284  1670 solver.cpp:243] Iteration 16600, loss = 3.15266
I0814 18:33:51.116061  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.13272 (* 1 = 3.13272 loss)
I0814 18:33:51.116070  1670 sgd_solver.cpp:138] Iteration 16600, lr = 0.0001
I0814 18:43:12.346523  1670 solver.cpp:243] Iteration 16700, loss = 3.71826
I0814 18:43:12.346623  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.08995 (* 1 = 4.08995 loss)
I0814 18:43:12.346630  1670 sgd_solver.cpp:138] Iteration 16700, lr = 0.0001
I0814 18:52:28.277803  1670 solver.cpp:243] Iteration 16800, loss = 2.80157
I0814 18:52:28.279027  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.43254 (* 1 = 3.43254 loss)
I0814 18:52:28.279036  1670 sgd_solver.cpp:138] Iteration 16800, lr = 0.0001
I0814 19:01:49.777863  1670 solver.cpp:243] Iteration 16900, loss = 3.9153
I0814 19:01:49.779156  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.92313 (* 1 = 3.92313 loss)
I0814 19:01:49.779162  1670 sgd_solver.cpp:138] Iteration 16900, lr = 0.0001
I0814 19:11:05.256599  1670 solver.cpp:243] Iteration 17000, loss = 3.08282
I0814 19:11:05.258072  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.48444 (* 1 = 3.48444 loss)
I0814 19:11:05.258078  1670 sgd_solver.cpp:138] Iteration 17000, lr = 0.0001
I0814 19:20:28.112437  1670 solver.cpp:243] Iteration 17100, loss = 4.04708
I0814 19:20:28.113699  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.67061 (* 1 = 3.67061 loss)
I0814 19:20:28.113705  1670 sgd_solver.cpp:138] Iteration 17100, lr = 0.0001
I0814 19:29:43.356523  1670 solver.cpp:243] Iteration 17200, loss = 3.44233
I0814 19:29:43.356597  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.93192 (* 1 = 1.93192 loss)
I0814 19:29:43.356603  1670 sgd_solver.cpp:138] Iteration 17200, lr = 0.0001
I0814 19:39:06.361325  1670 solver.cpp:243] Iteration 17300, loss = 3.97943
I0814 19:39:06.362546  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.65466 (* 1 = 4.65466 loss)
I0814 19:39:06.362552  1670 sgd_solver.cpp:138] Iteration 17300, lr = 0.0001
I0814 19:48:21.597726  1670 solver.cpp:243] Iteration 17400, loss = 3.2429
I0814 19:48:21.598994  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.2006 (* 1 = 4.2006 loss)
I0814 19:48:21.598999  1670 sgd_solver.cpp:138] Iteration 17400, lr = 0.0001
I0814 19:57:44.631731  1670 solver.cpp:243] Iteration 17500, loss = 3.33736
I0814 19:57:44.635152  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.03403 (* 1 = 4.03403 loss)
I0814 19:57:44.635159  1670 sgd_solver.cpp:138] Iteration 17500, lr = 0.0001
I0814 20:07:00.497313  1670 solver.cpp:243] Iteration 17600, loss = 2.7672
I0814 20:07:00.498594  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85595 (* 1 = 2.85595 loss)
I0814 20:07:00.498601  1670 sgd_solver.cpp:138] Iteration 17600, lr = 0.0001
I0814 20:16:25.104249  1670 solver.cpp:243] Iteration 17700, loss = 3.50478
I0814 20:16:25.105532  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.11062 (* 1 = 3.11062 loss)
I0814 20:16:25.105540  1670 sgd_solver.cpp:138] Iteration 17700, lr = 0.0001
I0814 20:25:44.303493  1670 solver.cpp:243] Iteration 17800, loss = 3.46721
I0814 20:25:44.303985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 7.82257 (* 1 = 7.82257 loss)
I0814 20:25:44.303992  1670 sgd_solver.cpp:138] Iteration 17800, lr = 0.0001
I0814 20:35:06.168272  1670 solver.cpp:243] Iteration 17900, loss = 3.55255
I0814 20:35:06.169464  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.64517 (* 1 = 4.64517 loss)
I0814 20:35:06.169471  1670 sgd_solver.cpp:138] Iteration 17900, lr = 0.0001
I0814 20:44:27.066948  1670 solver.cpp:243] Iteration 18000, loss = 5.2495
I0814 20:44:27.068090  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.68097 (* 1 = 4.68097 loss)
I0814 20:44:27.068097  1670 sgd_solver.cpp:138] Iteration 18000, lr = 0.0001
I0814 20:53:47.552294  1670 solver.cpp:243] Iteration 18100, loss = 3.6035
I0814 20:53:47.553587  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.73831 (* 1 = 4.73831 loss)
I0814 20:53:47.553594  1670 sgd_solver.cpp:138] Iteration 18100, lr = 0.0001
I0814 21:03:10.067970  1670 solver.cpp:243] Iteration 18200, loss = 4.66426
I0814 21:03:10.068032  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.46422 (* 1 = 4.46422 loss)
I0814 21:03:10.068038  1670 sgd_solver.cpp:138] Iteration 18200, lr = 0.0001
I0814 21:12:29.695552  1670 solver.cpp:243] Iteration 18300, loss = 3.49968
I0814 21:12:29.696015  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.38714 (* 1 = 3.38714 loss)
I0814 21:12:29.696023  1670 sgd_solver.cpp:138] Iteration 18300, lr = 0.0001
I0814 21:21:52.229284  1670 solver.cpp:243] Iteration 18400, loss = 4.09609
I0814 21:21:52.230491  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.73939 (* 1 = 3.73939 loss)
I0814 21:21:52.230497  1670 sgd_solver.cpp:138] Iteration 18400, lr = 0.0001
I0814 21:31:10.675762  1670 solver.cpp:243] Iteration 18500, loss = 3.12182
I0814 21:31:10.675940  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.07622 (* 1 = 2.07622 loss)
I0814 21:31:10.675948  1670 sgd_solver.cpp:138] Iteration 18500, lr = 0.0001
I0814 21:40:33.994877  1670 solver.cpp:243] Iteration 18600, loss = 3.81615
I0814 21:40:33.995945  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.33283 (* 1 = 3.33283 loss)
I0814 21:40:33.995952  1670 sgd_solver.cpp:138] Iteration 18600, lr = 0.0001
I0814 21:49:52.361865  1670 solver.cpp:243] Iteration 18700, loss = 3.24886
I0814 21:49:52.363216  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.39383 (* 1 = 2.39383 loss)
I0814 21:49:52.363224  1670 sgd_solver.cpp:138] Iteration 18700, lr = 0.0001
I0814 21:59:15.026635  1670 solver.cpp:243] Iteration 18800, loss = 3.5588
I0814 21:59:15.027917  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.95514 (* 1 = 3.95514 loss)
I0814 21:59:15.027925  1670 sgd_solver.cpp:138] Iteration 18800, lr = 0.0001
I0814 22:08:33.386189  1670 solver.cpp:243] Iteration 18900, loss = 2.73466
I0814 22:08:33.387540  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.7301 (* 1 = 2.7301 loss)
I0814 22:08:33.387549  1670 sgd_solver.cpp:138] Iteration 18900, lr = 0.0001
I0814 22:17:57.086941  1670 solver.cpp:243] Iteration 19000, loss = 3.58431
I0814 22:17:57.088130  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.15377 (* 1 = 4.15377 loss)
I0814 22:17:57.088140  1670 sgd_solver.cpp:138] Iteration 19000, lr = 0.0001
I0814 22:27:14.437355  1670 solver.cpp:243] Iteration 19100, loss = 2.79905
I0814 22:27:14.438666  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.15996 (* 1 = 2.15996 loss)
I0814 22:27:14.438673  1670 sgd_solver.cpp:138] Iteration 19100, lr = 0.0001
I0814 22:36:38.997723  1670 solver.cpp:243] Iteration 19200, loss = 3.87153
I0814 22:36:38.999037  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.04102 (* 1 = 4.04102 loss)
I0814 22:36:38.999044  1670 sgd_solver.cpp:138] Iteration 19200, lr = 0.0001
I0814 22:45:56.537583  1670 solver.cpp:243] Iteration 19300, loss = 3.127
I0814 22:45:56.538874  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52518 (* 1 = 2.52518 loss)
I0814 22:45:56.538882  1670 sgd_solver.cpp:138] Iteration 19300, lr = 0.0001
I0814 22:55:21.328212  1670 solver.cpp:243] Iteration 19400, loss = 3.90335
I0814 22:55:21.329470  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.69582 (* 1 = 2.69582 loss)
I0814 22:55:21.329479  1670 sgd_solver.cpp:138] Iteration 19400, lr = 0.0001
I0814 23:04:38.972777  1670 solver.cpp:243] Iteration 19500, loss = 3.30511
I0814 23:04:38.973991  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.41569 (* 1 = 3.41569 loss)
I0814 23:04:38.973997  1670 sgd_solver.cpp:138] Iteration 19500, lr = 0.0001
I0814 23:14:03.660956  1670 solver.cpp:243] Iteration 19600, loss = 3.63805
I0814 23:14:03.662156  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.45075 (* 1 = 3.45075 loss)
I0814 23:14:03.662163  1670 sgd_solver.cpp:138] Iteration 19600, lr = 0.0001
I0814 23:23:21.247632  1670 solver.cpp:243] Iteration 19700, loss = 3.21521
I0814 23:23:21.248013  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.41912 (* 1 = 3.41912 loss)
I0814 23:23:21.248019  1670 sgd_solver.cpp:138] Iteration 19700, lr = 0.0001
I0814 23:32:45.567567  1670 solver.cpp:243] Iteration 19800, loss = 3.24093
I0814 23:32:45.567983  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.41609 (* 1 = 3.41609 loss)
I0814 23:32:45.567989  1670 sgd_solver.cpp:138] Iteration 19800, lr = 0.0001
I0814 23:42:02.681740  1670 solver.cpp:243] Iteration 19900, loss = 2.42361
I0814 23:42:02.683010  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85421 (* 1 = 2.85421 loss)
I0814 23:42:02.683019  1670 sgd_solver.cpp:138] Iteration 19900, lr = 0.0001
I0814 23:51:21.817814  1670 solver.cpp:433] Iteration 20000, Testing net (#0)
I0814 23:51:21.819159  1670 net.cpp:693] Ignoring source layer mbox_loss
I0814 23:53:56.901584  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.225657
I0814 23:54:01.980182  1670 solver.cpp:243] Iteration 20000, loss = 3.46788
I0814 23:54:01.980204  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.81747 (* 1 = 3.81747 loss)
I0814 23:54:01.980211  1670 sgd_solver.cpp:138] Iteration 20000, lr = 0.0001
I0815 00:03:22.891906  1670 solver.cpp:243] Iteration 20100, loss = 4.91166
I0815 00:03:22.892127  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.57524 (* 1 = 5.57524 loss)
I0815 00:03:22.892134  1670 sgd_solver.cpp:138] Iteration 20100, lr = 0.0001
I0815 00:12:44.301367  1670 solver.cpp:243] Iteration 20200, loss = 3.54875
I0815 00:12:44.301862  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.54754 (* 1 = 3.54754 loss)
I0815 00:12:44.301869  1670 sgd_solver.cpp:138] Iteration 20200, lr = 0.0001
I0815 00:22:06.193075  1670 solver.cpp:243] Iteration 20300, loss = 4.72129
I0815 00:22:06.193152  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.46292 (* 1 = 5.46292 loss)
I0815 00:22:06.193158  1670 sgd_solver.cpp:138] Iteration 20300, lr = 0.0001
I0815 00:31:26.084496  1670 solver.cpp:243] Iteration 20400, loss = 3.62835
I0815 00:31:26.085706  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.58618 (* 1 = 3.58618 loss)
I0815 00:31:26.085712  1670 sgd_solver.cpp:138] Iteration 20400, lr = 0.0001
I0815 00:40:49.086330  1670 solver.cpp:243] Iteration 20500, loss = 4.2447
I0815 00:40:49.086614  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.4254 (* 1 = 3.4254 loss)
I0815 00:40:49.086622  1670 sgd_solver.cpp:138] Iteration 20500, lr = 0.0001
I0815 00:50:08.697659  1670 solver.cpp:243] Iteration 20600, loss = 3.22764
I0815 00:50:08.699652  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.77416 (* 1 = 2.77416 loss)
I0815 00:50:08.699674  1670 sgd_solver.cpp:138] Iteration 20600, lr = 0.0001
I0815 00:59:32.875380  1670 solver.cpp:243] Iteration 20700, loss = 4.03521
I0815 00:59:32.875975  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.45414 (* 1 = 4.45414 loss)
I0815 00:59:32.875982  1670 sgd_solver.cpp:138] Iteration 20700, lr = 0.0001
I0815 01:08:51.761229  1670 solver.cpp:243] Iteration 20800, loss = 3.13955
I0815 01:08:51.762423  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.77452 (* 1 = 3.77452 loss)
I0815 01:08:51.762428  1670 sgd_solver.cpp:138] Iteration 20800, lr = 0.0001
I0815 01:18:15.106266  1670 solver.cpp:243] Iteration 20900, loss = 3.53393
I0815 01:18:15.107455  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.52775 (* 1 = 3.52775 loss)
I0815 01:18:15.107461  1670 sgd_solver.cpp:138] Iteration 20900, lr = 0.0001
I0815 01:27:33.374152  1670 solver.cpp:243] Iteration 21000, loss = 2.97576
I0815 01:27:33.375339  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.00007 (* 1 = 2.00007 loss)
I0815 01:27:33.375347  1670 sgd_solver.cpp:138] Iteration 21000, lr = 0.0001
I0815 01:36:57.144664  1670 solver.cpp:243] Iteration 21100, loss = 3.48235
I0815 01:36:57.145891  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.70825 (* 1 = 3.70825 loss)
I0815 01:36:57.145897  1670 sgd_solver.cpp:138] Iteration 21100, lr = 0.0001
I0815 01:46:15.539214  1670 solver.cpp:243] Iteration 21200, loss = 2.67114
I0815 01:46:15.539976  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.98166 (* 1 = 1.98166 loss)
I0815 01:46:15.539983  1670 sgd_solver.cpp:138] Iteration 21200, lr = 0.0001
I0815 01:55:39.411471  1670 solver.cpp:243] Iteration 21300, loss = 3.65244
I0815 01:55:39.411962  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.76676 (* 1 = 4.76676 loss)
I0815 01:55:39.411969  1670 sgd_solver.cpp:138] Iteration 21300, lr = 0.0001
I0815 02:04:56.737231  1670 solver.cpp:243] Iteration 21400, loss = 2.72504
I0815 02:04:56.739161  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.77694 (* 1 = 2.77694 loss)
I0815 02:04:56.739167  1670 sgd_solver.cpp:138] Iteration 21400, lr = 0.0001
I0815 02:14:20.296386  1670 solver.cpp:243] Iteration 21500, loss = 3.93746
I0815 02:14:20.297966  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.65514 (* 1 = 2.65514 loss)
I0815 02:14:20.297971  1670 sgd_solver.cpp:138] Iteration 21500, lr = 0.0001
I0815 02:23:37.294379  1670 solver.cpp:243] Iteration 21600, loss = 3.31596
I0815 02:23:37.295663  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.06488 (* 1 = 3.06488 loss)
I0815 02:23:37.295670  1670 sgd_solver.cpp:138] Iteration 21600, lr = 0.0001
I0815 02:33:02.237498  1670 solver.cpp:243] Iteration 21700, loss = 3.72018
I0815 02:33:02.238755  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.77043 (* 1 = 3.77043 loss)
I0815 02:33:02.238767  1670 sgd_solver.cpp:138] Iteration 21700, lr = 0.0001
I0815 02:42:19.577507  1670 solver.cpp:243] Iteration 21800, loss = 3.18208
I0815 02:42:19.577584  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.04897 (* 1 = 3.04897 loss)
I0815 02:42:19.577590  1670 sgd_solver.cpp:138] Iteration 21800, lr = 0.0001
I0815 02:51:44.585508  1670 solver.cpp:243] Iteration 21900, loss = 3.37244
I0815 02:51:44.586730  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.42807 (* 1 = 2.42807 loss)
I0815 02:51:44.586735  1670 sgd_solver.cpp:138] Iteration 21900, lr = 0.0001
I0815 03:01:01.746369  1670 solver.cpp:243] Iteration 22000, loss = 2.85393
I0815 03:01:01.747874  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.01152 (* 1 = 2.01152 loss)
I0815 03:01:01.747879  1670 sgd_solver.cpp:138] Iteration 22000, lr = 0.0001
I0815 03:10:26.101105  1670 solver.cpp:243] Iteration 22100, loss = 3.17417
I0815 03:10:26.102318  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.28464 (* 1 = 4.28464 loss)
I0815 03:10:26.102324  1670 sgd_solver.cpp:138] Iteration 22100, lr = 0.0001
I0815 03:19:44.954555  1670 solver.cpp:243] Iteration 22200, loss = 2.79136
I0815 03:19:44.955178  1670 solver.cpp:259]     Train net output #0: mbox_loss = 8.48426 (* 1 = 8.48426 loss)
I0815 03:19:44.955185  1670 sgd_solver.cpp:138] Iteration 22200, lr = 0.0001
I0815 03:29:07.934420  1670 solver.cpp:243] Iteration 22300, loss = 3.58156
I0815 03:29:07.936009  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.92241 (* 1 = 4.92241 loss)
I0815 03:29:07.936017  1670 sgd_solver.cpp:138] Iteration 22300, lr = 0.0001
I0815 03:38:29.836938  1670 solver.cpp:243] Iteration 22400, loss = 5.47815
I0815 03:38:29.838275  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.55557 (* 1 = 3.55557 loss)
I0815 03:38:29.838281  1670 sgd_solver.cpp:138] Iteration 22400, lr = 0.0001
I0815 03:47:50.291440  1670 solver.cpp:243] Iteration 22500, loss = 3.42097
I0815 03:47:50.292016  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52877 (* 1 = 2.52877 loss)
I0815 03:47:50.292022  1670 sgd_solver.cpp:138] Iteration 22500, lr = 0.0001
I0815 03:57:11.795894  1670 solver.cpp:243] Iteration 22600, loss = 4.42573
I0815 03:57:11.796030  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.16303 (* 1 = 5.16303 loss)
I0815 03:57:11.796036  1670 sgd_solver.cpp:138] Iteration 22600, lr = 0.0001
I0815 04:06:31.029819  1670 solver.cpp:243] Iteration 22700, loss = 3.40303
I0815 04:06:31.031105  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.92025 (* 1 = 3.92025 loss)
I0815 04:06:31.031111  1670 sgd_solver.cpp:138] Iteration 22700, lr = 0.0001
I0815 04:15:53.100994  1670 solver.cpp:243] Iteration 22800, loss = 4.0689
I0815 04:15:53.102288  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.95159 (* 1 = 2.95159 loss)
I0815 04:15:53.102294  1670 sgd_solver.cpp:138] Iteration 22800, lr = 0.0001
I0815 04:25:11.801002  1670 solver.cpp:243] Iteration 22900, loss = 3.09579
I0815 04:25:11.803020  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.21419 (* 1 = 2.21419 loss)
I0815 04:25:11.803027  1670 sgd_solver.cpp:138] Iteration 22900, lr = 0.0001
I0815 04:34:34.520869  1670 solver.cpp:243] Iteration 23000, loss = 3.81876
I0815 04:34:34.520947  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.92665 (* 1 = 3.92665 loss)
I0815 04:34:34.520952  1670 sgd_solver.cpp:138] Iteration 23000, lr = 0.0001
I0815 04:43:52.704164  1670 solver.cpp:243] Iteration 23100, loss = 3.22647
I0815 04:43:52.705379  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.2501 (* 1 = 3.2501 loss)
I0815 04:43:52.705384  1670 sgd_solver.cpp:138] Iteration 23100, lr = 0.0001
I0815 04:53:14.975184  1670 solver.cpp:243] Iteration 23200, loss = 3.21459
I0815 04:53:14.975988  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.36577 (* 1 = 3.36577 loss)
I0815 04:53:14.975996  1670 sgd_solver.cpp:138] Iteration 23200, lr = 0.0001
I0815 05:02:32.750252  1670 solver.cpp:243] Iteration 23300, loss = 2.70177
I0815 05:02:32.751467  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.66625 (* 1 = 2.66625 loss)
I0815 05:02:32.751482  1670 sgd_solver.cpp:138] Iteration 23300, lr = 0.0001
I0815 05:11:55.227567  1670 solver.cpp:243] Iteration 23400, loss = 3.47088
I0815 05:11:55.228044  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.48501 (* 1 = 1.48501 loss)
I0815 05:11:55.228049  1670 sgd_solver.cpp:138] Iteration 23400, lr = 0.0001
I0815 05:21:12.685753  1670 solver.cpp:243] Iteration 23500, loss = 2.53225
I0815 05:21:12.687360  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.02549 (* 1 = 2.02549 loss)
I0815 05:21:12.687369  1670 sgd_solver.cpp:138] Iteration 23500, lr = 0.0001
I0815 05:30:36.831715  1670 solver.cpp:243] Iteration 23600, loss = 3.61498
I0815 05:30:36.831953  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.43238 (* 1 = 4.43238 loss)
I0815 05:30:36.831961  1670 sgd_solver.cpp:138] Iteration 23600, lr = 0.0001
I0815 05:39:54.357832  1670 solver.cpp:243] Iteration 23700, loss = 2.95433
I0815 05:39:54.359131  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.98993 (* 1 = 2.98993 loss)
I0815 05:39:54.359138  1670 sgd_solver.cpp:138] Iteration 23700, lr = 0.0001
I0815 05:49:18.880308  1670 solver.cpp:243] Iteration 23800, loss = 3.64204
I0815 05:49:18.881517  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.88701 (* 1 = 2.88701 loss)
I0815 05:49:18.881523  1670 sgd_solver.cpp:138] Iteration 23800, lr = 0.0001
I0815 05:58:35.825388  1670 solver.cpp:243] Iteration 23900, loss = 3.27081
I0815 05:58:35.826647  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.89322 (* 1 = 2.89322 loss)
I0815 05:58:35.826653  1670 sgd_solver.cpp:138] Iteration 23900, lr = 0.0001
I0815 06:08:00.492410  1670 solver.cpp:243] Iteration 24000, loss = 3.63056
I0815 06:08:00.494422  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.67916 (* 1 = 3.67916 loss)
I0815 06:08:00.494444  1670 sgd_solver.cpp:138] Iteration 24000, lr = 0.0001
I0815 06:17:17.402886  1670 solver.cpp:243] Iteration 24100, loss = 3.02631
I0815 06:17:17.403869  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.19173 (* 1 = 2.19173 loss)
I0815 06:17:17.403875  1670 sgd_solver.cpp:138] Iteration 24100, lr = 0.0001
I0815 06:26:42.233323  1670 solver.cpp:243] Iteration 24200, loss = 3.21389
I0815 06:26:42.234562  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.44933 (* 1 = 1.44933 loss)
I0815 06:26:42.234570  1670 sgd_solver.cpp:138] Iteration 24200, lr = 0.0001
I0815 06:35:59.669488  1670 solver.cpp:243] Iteration 24300, loss = 2.51058
I0815 06:35:59.670657  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.395 (* 1 = 2.395 loss)
I0815 06:35:59.670663  1670 sgd_solver.cpp:138] Iteration 24300, lr = 0.0001
I0815 06:45:24.186800  1670 solver.cpp:243] Iteration 24400, loss = 3.34547
I0815 06:45:24.187944  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.90387 (* 1 = 2.90387 loss)
I0815 06:45:24.187950  1670 sgd_solver.cpp:138] Iteration 24400, lr = 0.0001
I0815 06:54:44.743261  1670 solver.cpp:243] Iteration 24500, loss = 4.37851
I0815 06:54:44.743883  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.36902 (* 1 = 5.36902 loss)
I0815 06:54:44.743891  1670 sgd_solver.cpp:138] Iteration 24500, lr = 0.0001
I0815 07:04:06.313627  1670 solver.cpp:243] Iteration 24600, loss = 3.36876
I0815 07:04:06.315033  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.49929 (* 1 = 3.49929 loss)
I0815 07:04:06.315042  1670 sgd_solver.cpp:138] Iteration 24600, lr = 0.0001
I0815 07:13:28.101974  1670 solver.cpp:243] Iteration 24700, loss = 4.61564
I0815 07:13:28.103524  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.8351 (* 1 = 3.8351 loss)
I0815 07:13:28.103533  1670 sgd_solver.cpp:138] Iteration 24700, lr = 0.0001
I0815 07:22:48.615970  1670 solver.cpp:243] Iteration 24800, loss = 3.40918
I0815 07:22:48.616075  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.66497 (* 1 = 2.66497 loss)
I0815 07:22:48.616083  1670 sgd_solver.cpp:138] Iteration 24800, lr = 0.0001
I0815 07:32:11.385694  1670 solver.cpp:243] Iteration 24900, loss = 4.22255
I0815 07:32:11.386936  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.23108 (* 1 = 4.23108 loss)
I0815 07:32:11.386946  1670 sgd_solver.cpp:138] Iteration 24900, lr = 0.0001
I0815 07:41:30.960877  1670 solver.cpp:243] Iteration 25000, loss = 3.23182
I0815 07:41:30.961946  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82887 (* 1 = 2.82887 loss)
I0815 07:41:30.961951  1670 sgd_solver.cpp:138] Iteration 25000, lr = 0.0001
I0815 07:50:54.965632  1670 solver.cpp:243] Iteration 25100, loss = 3.91178
I0815 07:50:54.967023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.90294 (* 1 = 4.90294 loss)
I0815 07:50:54.967031  1670 sgd_solver.cpp:138] Iteration 25100, lr = 0.0001
I0815 08:00:13.523846  1670 solver.cpp:243] Iteration 25200, loss = 3.06922
I0815 08:00:13.523937  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82749 (* 1 = 2.82749 loss)
I0815 08:00:13.523943  1670 sgd_solver.cpp:138] Iteration 25200, lr = 0.0001
I0815 08:09:37.053822  1670 solver.cpp:243] Iteration 25300, loss = 3.60333
I0815 08:09:37.053905  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.06415 (* 1 = 4.06415 loss)
I0815 08:09:37.053911  1670 sgd_solver.cpp:138] Iteration 25300, lr = 0.0001
I0815 08:18:55.769141  1670 solver.cpp:243] Iteration 25400, loss = 2.93376
I0815 08:18:55.770391  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.388 (* 1 = 2.388 loss)
I0815 08:18:55.770398  1670 sgd_solver.cpp:138] Iteration 25400, lr = 0.0001
I0815 08:28:19.701017  1670 solver.cpp:243] Iteration 25500, loss = 3.31608
I0815 08:28:19.701093  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.0971 (* 1 = 4.0971 loss)
I0815 08:28:19.701099  1670 sgd_solver.cpp:138] Iteration 25500, lr = 0.0001
I0815 08:37:38.345799  1670 solver.cpp:243] Iteration 25600, loss = 2.56621
I0815 08:37:38.347018  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.5402 (* 1 = 0.5402 loss)
I0815 08:37:38.347024  1670 sgd_solver.cpp:138] Iteration 25600, lr = 0.0001
I0815 08:47:03.178328  1670 solver.cpp:243] Iteration 25700, loss = 3.45143
I0815 08:47:03.179611  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.14703 (* 1 = 4.14703 loss)
I0815 08:47:03.179618  1670 sgd_solver.cpp:138] Iteration 25700, lr = 0.0001
I0815 08:56:21.324833  1670 solver.cpp:243] Iteration 25800, loss = 2.64549
I0815 08:56:21.326102  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85908 (* 1 = 2.85908 loss)
I0815 08:56:21.326108  1670 sgd_solver.cpp:138] Iteration 25800, lr = 0.0001
I0815 09:05:46.233657  1670 solver.cpp:243] Iteration 25900, loss = 3.8466
I0815 09:05:46.234937  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.34096 (* 1 = 3.34096 loss)
I0815 09:05:46.234944  1670 sgd_solver.cpp:138] Iteration 25900, lr = 0.0001
I0815 09:15:03.964434  1670 solver.cpp:243] Iteration 26000, loss = 3.06469
I0815 09:15:03.965669  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.35799 (* 1 = 2.35799 loss)
I0815 09:15:03.965675  1670 sgd_solver.cpp:138] Iteration 26000, lr = 0.0001
I0815 09:24:28.628878  1670 solver.cpp:243] Iteration 26100, loss = 3.67977
I0815 09:24:28.628958  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.20211 (* 1 = 2.20211 loss)
I0815 09:24:28.628964  1670 sgd_solver.cpp:138] Iteration 26100, lr = 0.0001
I0815 09:33:45.498001  1670 solver.cpp:243] Iteration 26200, loss = 3.11725
I0815 09:33:45.499238  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.17122 (* 1 = 3.17122 loss)
I0815 09:33:45.499248  1670 sgd_solver.cpp:138] Iteration 26200, lr = 0.0001
I0815 09:43:10.274323  1670 solver.cpp:243] Iteration 26300, loss = 3.32925
I0815 09:43:10.275605  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.36469 (* 1 = 2.36469 loss)
I0815 09:43:10.275611  1670 sgd_solver.cpp:138] Iteration 26300, lr = 0.0001
I0815 09:52:26.269799  1670 solver.cpp:243] Iteration 26400, loss = 2.99107
I0815 09:52:26.271045  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.45973 (* 1 = 2.45973 loss)
I0815 09:52:26.271054  1670 sgd_solver.cpp:138] Iteration 26400, lr = 0.0001
I0815 10:01:49.623680  1670 solver.cpp:243] Iteration 26500, loss = 3.03248
I0815 10:01:49.623746  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.11652 (* 1 = 3.11652 loss)
I0815 10:01:49.623752  1670 sgd_solver.cpp:138] Iteration 26500, lr = 0.0001
I0815 10:11:06.238334  1670 solver.cpp:243] Iteration 26600, loss = 1.99106
I0815 10:11:06.239608  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.28152 (* 1 = 1.28152 loss)
I0815 10:11:06.239614  1670 sgd_solver.cpp:138] Iteration 26600, lr = 0.0001
I0815 10:20:29.884613  1670 solver.cpp:243] Iteration 26700, loss = 3.34243
I0815 10:20:29.885787  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.5249 (* 1 = 2.5249 loss)
I0815 10:20:29.885794  1670 sgd_solver.cpp:138] Iteration 26700, lr = 0.0001
I0815 10:29:49.390691  1670 solver.cpp:243] Iteration 26800, loss = 5.08746
I0815 10:29:49.391993  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.26335 (* 1 = 4.26335 loss)
I0815 10:29:49.392000  1670 sgd_solver.cpp:138] Iteration 26800, lr = 0.0001
I0815 10:39:08.274595  1670 solver.cpp:243] Iteration 26900, loss = 3.38458
I0815 10:39:08.275805  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.3119 (* 1 = 4.3119 loss)
I0815 10:39:08.275812  1670 sgd_solver.cpp:138] Iteration 26900, lr = 0.0001
I0815 10:48:27.561239  1670 solver.cpp:243] Iteration 27000, loss = 4.34584
I0815 10:48:27.561312  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.17854 (* 1 = 5.17854 loss)
I0815 10:48:27.561321  1670 sgd_solver.cpp:138] Iteration 27000, lr = 0.0001
I0815 10:57:45.348433  1670 solver.cpp:243] Iteration 27100, loss = 3.33201
I0815 10:57:45.349673  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.56408 (* 1 = 3.56408 loss)
I0815 10:57:45.349679  1670 sgd_solver.cpp:138] Iteration 27100, lr = 0.0001
I0815 11:07:06.084729  1670 solver.cpp:243] Iteration 27200, loss = 4.04936
I0815 11:07:06.085992  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.20305 (* 1 = 3.20305 loss)
I0815 11:07:06.085999  1670 sgd_solver.cpp:138] Iteration 27200, lr = 0.0001
I0815 11:16:23.264708  1670 solver.cpp:243] Iteration 27300, loss = 3.02384
I0815 11:16:23.265985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.47355 (* 1 = 2.47355 loss)
I0815 11:16:23.265992  1670 sgd_solver.cpp:138] Iteration 27300, lr = 0.0001
I0815 11:25:44.803990  1670 solver.cpp:243] Iteration 27400, loss = 3.76152
I0815 11:25:44.805447  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.81656 (* 1 = 3.81656 loss)
I0815 11:25:44.805454  1670 sgd_solver.cpp:138] Iteration 27400, lr = 0.0001
I0815 11:35:01.068238  1670 solver.cpp:243] Iteration 27500, loss = 3.03436
I0815 11:35:01.068650  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.6941 (* 1 = 2.6941 loss)
I0815 11:35:01.068656  1670 sgd_solver.cpp:138] Iteration 27500, lr = 0.0001
I0815 11:44:22.531565  1670 solver.cpp:243] Iteration 27600, loss = 3.24735
I0815 11:44:22.532886  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.59762 (* 1 = 3.59762 loss)
I0815 11:44:22.532894  1670 sgd_solver.cpp:138] Iteration 27600, lr = 0.0001
I0815 11:53:39.549532  1670 solver.cpp:243] Iteration 27700, loss = 2.83559
I0815 11:53:39.550875  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.3463 (* 1 = 3.3463 loss)
I0815 11:53:39.550884  1670 sgd_solver.cpp:138] Iteration 27700, lr = 0.0001
I0815 12:03:02.404829  1670 solver.cpp:243] Iteration 27800, loss = 3.48014
I0815 12:03:02.406128  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.14434 (* 1 = 3.14434 loss)
I0815 12:03:02.406136  1670 sgd_solver.cpp:138] Iteration 27800, lr = 0.0001
I0815 12:12:19.698259  1670 solver.cpp:243] Iteration 27900, loss = 2.4982
I0815 12:12:19.699831  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.38914 (* 1 = 2.38914 loss)
I0815 12:12:19.699837  1670 sgd_solver.cpp:138] Iteration 27900, lr = 0.0001
I0815 12:21:43.353881  1670 solver.cpp:243] Iteration 28000, loss = 3.53576
I0815 12:21:43.355183  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.98257 (* 1 = 1.98257 loss)
I0815 12:21:43.355190  1670 sgd_solver.cpp:138] Iteration 28000, lr = 0.0001
I0815 12:30:59.578786  1670 solver.cpp:243] Iteration 28100, loss = 2.73858
I0815 12:30:59.578860  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.59925 (* 1 = 2.59925 loss)
I0815 12:30:59.578867  1670 sgd_solver.cpp:138] Iteration 28100, lr = 0.0001
I0815 12:40:23.608063  1670 solver.cpp:243] Iteration 28200, loss = 3.53518
I0815 12:40:23.608253  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.92005 (* 1 = 3.92005 loss)
I0815 12:40:23.608259  1670 sgd_solver.cpp:138] Iteration 28200, lr = 0.0001
I0815 12:49:40.278378  1670 solver.cpp:243] Iteration 28300, loss = 3.19037
I0815 12:49:40.279631  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82441 (* 1 = 2.82441 loss)
I0815 12:49:40.279641  1670 sgd_solver.cpp:138] Iteration 28300, lr = 0.0001
I0815 12:59:03.730648  1670 solver.cpp:243] Iteration 28400, loss = 3.50191
I0815 12:59:03.731915  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.47423 (* 1 = 3.47423 loss)
I0815 12:59:03.731921  1670 sgd_solver.cpp:138] Iteration 28400, lr = 0.0001
I0815 13:08:20.035392  1670 solver.cpp:243] Iteration 28500, loss = 2.99353
I0815 13:08:20.036048  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52489 (* 1 = 2.52489 loss)
I0815 13:08:20.036056  1670 sgd_solver.cpp:138] Iteration 28500, lr = 0.0001
I0815 13:17:43.913841  1670 solver.cpp:243] Iteration 28600, loss = 3.12721
I0815 13:17:43.915040  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.48781 (* 1 = 4.48781 loss)
I0815 13:17:43.915045  1670 sgd_solver.cpp:138] Iteration 28600, lr = 0.0001
I0815 13:26:59.979706  1670 solver.cpp:243] Iteration 28700, loss = 2.63453
I0815 13:26:59.979934  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.578378 (* 1 = 0.578378 loss)
I0815 13:26:59.979939  1670 sgd_solver.cpp:138] Iteration 28700, lr = 0.0001
I0815 13:36:24.023284  1670 solver.cpp:243] Iteration 28800, loss = 3.13351
I0815 13:36:24.023351  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.38492 (* 1 = 2.38492 loss)
I0815 13:36:24.023357  1670 sgd_solver.cpp:138] Iteration 28800, lr = 0.0001
I0815 13:45:43.062371  1670 solver.cpp:243] Iteration 28900, loss = 3.41038
I0815 13:45:43.063727  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.01638 (* 1 = 6.01638 loss)
I0815 13:45:43.063733  1670 sgd_solver.cpp:138] Iteration 28900, lr = 0.0001
I0815 13:55:04.395153  1670 solver.cpp:243] Iteration 29000, loss = 3.22923
I0815 13:55:04.396286  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.59911 (* 1 = 4.59911 loss)
I0815 13:55:04.396292  1670 sgd_solver.cpp:138] Iteration 29000, lr = 0.0001
I0815 14:04:24.877408  1670 solver.cpp:243] Iteration 29100, loss = 4.89535
I0815 14:04:24.878819  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.42822 (* 1 = 4.42822 loss)
I0815 14:04:24.878830  1670 sgd_solver.cpp:138] Iteration 29100, lr = 0.0001
I0815 14:13:44.467383  1670 solver.cpp:243] Iteration 29200, loss = 3.41514
I0815 14:13:44.467470  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.13178 (* 1 = 4.13178 loss)
I0815 14:13:44.467475  1670 sgd_solver.cpp:138] Iteration 29200, lr = 0.0001
I0815 14:23:05.723304  1670 solver.cpp:243] Iteration 29300, loss = 4.26201
I0815 14:23:05.723388  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.86576 (* 1 = 4.86576 loss)
I0815 14:23:05.723394  1670 sgd_solver.cpp:138] Iteration 29300, lr = 0.0001
I0815 14:32:24.094125  1670 solver.cpp:243] Iteration 29400, loss = 3.16531
I0815 14:32:24.095422  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.78183 (* 1 = 2.78183 loss)
I0815 14:32:24.095428  1670 sgd_solver.cpp:138] Iteration 29400, lr = 0.0001
I0815 14:41:45.640269  1670 solver.cpp:243] Iteration 29500, loss = 3.82376
I0815 14:41:45.640408  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.02726 (* 1 = 4.02726 loss)
I0815 14:41:45.640414  1670 sgd_solver.cpp:138] Iteration 29500, lr = 0.0001
I0815 14:51:03.632918  1670 solver.cpp:243] Iteration 29600, loss = 2.89312
I0815 14:51:03.633002  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.53172 (* 1 = 3.53172 loss)
I0815 14:51:03.633008  1670 sgd_solver.cpp:138] Iteration 29600, lr = 0.0001
I0815 15:00:26.057435  1670 solver.cpp:243] Iteration 29700, loss = 3.53732
I0815 15:00:26.058707  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.14794 (* 1 = 2.14794 loss)
I0815 15:00:26.058713  1670 sgd_solver.cpp:138] Iteration 29700, lr = 0.0001
I0815 15:09:43.875046  1670 solver.cpp:243] Iteration 29800, loss = 2.88711
I0815 15:09:43.876266  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.95831 (* 1 = 1.95831 loss)
I0815 15:09:43.876272  1670 sgd_solver.cpp:138] Iteration 29800, lr = 0.0001
I0815 15:19:06.449309  1670 solver.cpp:243] Iteration 29900, loss = 3.1092
I0815 15:19:06.449808  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.29413 (* 1 = 4.29413 loss)
I0815 15:19:06.449815  1670 sgd_solver.cpp:138] Iteration 29900, lr = 0.0001
I0815 15:28:18.635452  1670 solver.cpp:433] Iteration 30000, Testing net (#0)
I0815 15:28:18.635938  1670 net.cpp:693] Ignoring source layer mbox_loss
I0815 15:30:51.454936  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.244955
I0815 15:30:56.522303  1670 solver.cpp:243] Iteration 30000, loss = 2.41162
I0815 15:30:56.522330  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.24783 (* 1 = 2.24783 loss)
I0815 15:30:56.522334  1670 sgd_solver.cpp:138] Iteration 30000, lr = 0.0001
I0815 15:40:19.575083  1670 solver.cpp:243] Iteration 30100, loss = 3.40255
I0815 15:40:19.575990  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.73901 (* 1 = 4.73901 loss)
I0815 15:40:19.575996  1670 sgd_solver.cpp:138] Iteration 30100, lr = 0.0001
I0815 15:49:36.591959  1670 solver.cpp:243] Iteration 30200, loss = 2.55067
I0815 15:49:36.592033  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.852512 (* 1 = 0.852512 loss)
I0815 15:49:36.592041  1670 sgd_solver.cpp:138] Iteration 30200, lr = 0.0001
I0815 15:58:59.605902  1670 solver.cpp:243] Iteration 30300, loss = 3.62666
I0815 15:58:59.607240  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.11427 (* 1 = 3.11427 loss)
I0815 15:58:59.607251  1670 sgd_solver.cpp:138] Iteration 30300, lr = 0.0001
I0815 16:08:16.320751  1670 solver.cpp:243] Iteration 30400, loss = 2.91528
I0815 16:08:16.322019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.77776 (* 1 = 3.77776 loss)
I0815 16:08:16.322026  1670 sgd_solver.cpp:138] Iteration 30400, lr = 0.0001
I0815 16:17:40.529623  1670 solver.cpp:243] Iteration 30500, loss = 3.54074
I0815 16:17:40.531227  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.83732 (* 1 = 2.83732 loss)
I0815 16:17:40.531234  1670 sgd_solver.cpp:138] Iteration 30500, lr = 0.0001
I0815 16:26:57.074532  1670 solver.cpp:243] Iteration 30600, loss = 3.01766
I0815 16:26:57.074622  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.44957 (* 1 = 2.44957 loss)
I0815 16:26:57.074630  1670 sgd_solver.cpp:138] Iteration 30600, lr = 0.0001
I0815 16:36:21.090688  1670 solver.cpp:243] Iteration 30700, loss = 3.39166
I0815 16:36:21.091967  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.66845 (* 1 = 2.66845 loss)
I0815 16:36:21.091974  1670 sgd_solver.cpp:138] Iteration 30700, lr = 0.0001
I0815 16:45:37.870532  1670 solver.cpp:243] Iteration 30800, loss = 2.94522
I0815 16:45:37.871827  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.69619 (* 1 = 3.69619 loss)
I0815 16:45:37.871834  1670 sgd_solver.cpp:138] Iteration 30800, lr = 0.0001
I0815 16:55:01.553967  1670 solver.cpp:243] Iteration 30900, loss = 2.9266
I0815 16:55:01.555291  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.5475 (* 1 = 3.5475 loss)
I0815 16:55:01.555299  1670 sgd_solver.cpp:138] Iteration 30900, lr = 0.0001
I0815 17:04:17.779561  1670 solver.cpp:243] Iteration 31000, loss = 2.1483
I0815 17:04:17.780840  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.08333 (* 1 = 1.08333 loss)
I0815 17:04:17.780846  1670 sgd_solver.cpp:138] Iteration 31000, lr = 0.0001
I0815 17:13:42.398977  1670 solver.cpp:243] Iteration 31100, loss = 3.22736
I0815 17:13:42.400298  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.00538 (* 1 = 4.00538 loss)
I0815 17:13:42.400305  1670 sgd_solver.cpp:138] Iteration 31100, lr = 0.0001
I0815 17:23:02.580626  1670 solver.cpp:243] Iteration 31200, loss = 4.78118
I0815 17:23:02.582096  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.27974 (* 1 = 5.27974 loss)
I0815 17:23:02.582103  1670 sgd_solver.cpp:138] Iteration 31200, lr = 0.0001
I0815 17:32:22.434864  1670 solver.cpp:243] Iteration 31300, loss = 3.29203
I0815 17:32:22.434921  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.72563 (* 1 = 2.72563 loss)
I0815 17:32:22.434927  1670 sgd_solver.cpp:138] Iteration 31300, lr = 0.0001
I0815 17:41:43.254593  1670 solver.cpp:243] Iteration 31400, loss = 4.47541
I0815 17:41:43.255861  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.9126 (* 1 = 4.9126 loss)
I0815 17:41:43.255872  1670 sgd_solver.cpp:138] Iteration 31400, lr = 0.0001
I0815 17:51:02.181392  1670 solver.cpp:243] Iteration 31500, loss = 3.36143
I0815 17:51:02.182653  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.81107 (* 1 = 1.81107 loss)
I0815 17:51:02.182659  1670 sgd_solver.cpp:138] Iteration 31500, lr = 0.0001
I0815 18:00:23.713018  1670 solver.cpp:243] Iteration 31600, loss = 4.08019
I0815 18:00:23.714342  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.87899 (* 1 = 3.87899 loss)
I0815 18:00:23.714349  1670 sgd_solver.cpp:138] Iteration 31600, lr = 0.0001
I0815 18:09:41.791345  1670 solver.cpp:243] Iteration 31700, loss = 3.01197
I0815 18:09:41.792052  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.80362 (* 1 = 2.80362 loss)
I0815 18:09:41.792059  1670 sgd_solver.cpp:138] Iteration 31700, lr = 0.0001
I0815 18:19:04.179610  1670 solver.cpp:243] Iteration 31800, loss = 3.7564
I0815 18:19:04.179911  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.70327 (* 1 = 3.70327 loss)
I0815 18:19:04.179917  1670 sgd_solver.cpp:138] Iteration 31800, lr = 0.0001
I0815 18:28:21.546502  1670 solver.cpp:243] Iteration 31900, loss = 2.92444
I0815 18:28:21.547746  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.75626 (* 1 = 2.75626 loss)
I0815 18:28:21.547756  1670 sgd_solver.cpp:138] Iteration 31900, lr = 0.0001
I0815 18:37:43.568589  1670 solver.cpp:243] Iteration 32000, loss = 3.39089
I0815 18:37:43.569821  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.95831 (* 1 = 2.95831 loss)
I0815 18:37:43.569828  1670 sgd_solver.cpp:138] Iteration 32000, lr = 0.0001
I0815 18:47:00.637418  1670 solver.cpp:243] Iteration 32100, loss = 2.80066
I0815 18:47:00.639019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.79164 (* 1 = 2.79164 loss)
I0815 18:47:00.639026  1670 sgd_solver.cpp:138] Iteration 32100, lr = 0.0001
I0815 18:56:22.643259  1670 solver.cpp:243] Iteration 32200, loss = 3.27683
I0815 18:56:22.643929  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.99881 (* 1 = 3.99881 loss)
I0815 18:56:22.643934  1670 sgd_solver.cpp:138] Iteration 32200, lr = 0.0001
I0815 19:05:39.393913  1670 solver.cpp:243] Iteration 32300, loss = 2.41103
I0815 19:05:39.395246  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.97666 (* 1 = 3.97666 loss)
I0815 19:05:39.395253  1670 sgd_solver.cpp:138] Iteration 32300, lr = 0.0001
I0815 19:15:02.500018  1670 solver.cpp:243] Iteration 32400, loss = 3.42558
I0815 19:15:02.501242  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.43403 (* 1 = 4.43403 loss)
I0815 19:15:02.501261  1670 sgd_solver.cpp:138] Iteration 32400, lr = 0.0001
I0815 19:24:18.875816  1670 solver.cpp:243] Iteration 32500, loss = 2.4931
I0815 19:24:18.875924  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.4575 (* 1 = 2.4575 loss)
I0815 19:24:18.875931  1670 sgd_solver.cpp:138] Iteration 32500, lr = 0.0001
I0815 19:33:42.468603  1670 solver.cpp:243] Iteration 32600, loss = 3.59071
I0815 19:33:42.470165  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.64188 (* 1 = 1.64188 loss)
I0815 19:33:42.470170  1670 sgd_solver.cpp:138] Iteration 32600, lr = 0.0001
I0815 19:42:58.938274  1670 solver.cpp:243] Iteration 32700, loss = 2.91965
I0815 19:42:58.939486  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.84064 (* 1 = 2.84064 loss)
I0815 19:42:58.939494  1670 sgd_solver.cpp:138] Iteration 32700, lr = 0.0001
I0815 19:52:22.865929  1670 solver.cpp:243] Iteration 32800, loss = 3.43136
I0815 19:52:22.867161  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.56121 (* 1 = 4.56121 loss)
I0815 19:52:22.867166  1670 sgd_solver.cpp:138] Iteration 32800, lr = 0.0001
I0815 20:01:39.345044  1670 solver.cpp:243] Iteration 32900, loss = 2.97496
I0815 20:01:39.346268  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.21855 (* 1 = 3.21855 loss)
I0815 20:01:39.346276  1670 sgd_solver.cpp:138] Iteration 32900, lr = 0.0001
I0815 20:11:03.469964  1670 solver.cpp:243] Iteration 33000, loss = 3.09415
I0815 20:11:03.471191  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.46524 (* 1 = 2.46524 loss)
I0815 20:11:03.471199  1670 sgd_solver.cpp:138] Iteration 33000, lr = 0.0001
I0815 20:20:19.325682  1670 solver.cpp:243] Iteration 33100, loss = 2.6744
I0815 20:20:19.327019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.81024 (* 1 = 2.81024 loss)
I0815 20:20:19.327025  1670 sgd_solver.cpp:138] Iteration 33100, lr = 0.0001
I0815 20:29:42.593520  1670 solver.cpp:243] Iteration 33200, loss = 2.99398
I0815 20:29:42.595553  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.94634 (* 1 = 3.94634 loss)
I0815 20:29:42.595574  1670 sgd_solver.cpp:138] Iteration 33200, lr = 0.0001
I0815 20:39:00.782210  1670 solver.cpp:243] Iteration 33300, loss = 2.53255
I0815 20:39:00.783843  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.61163 (* 1 = 5.61163 loss)
I0815 20:39:00.783850  1670 sgd_solver.cpp:138] Iteration 33300, lr = 0.0001
I0815 20:48:22.656852  1670 solver.cpp:243] Iteration 33400, loss = 3.20871
I0815 20:48:22.658087  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.11907 (* 1 = 3.11907 loss)
I0815 20:48:22.658092  1670 sgd_solver.cpp:138] Iteration 33400, lr = 0.0001
I0815 20:57:43.478575  1670 solver.cpp:243] Iteration 33500, loss = 5.31826
I0815 20:57:43.479936  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.06924 (* 1 = 4.06924 loss)
I0815 20:57:43.479946  1670 sgd_solver.cpp:138] Iteration 33500, lr = 0.0001
I0815 21:07:03.391257  1670 solver.cpp:243] Iteration 33600, loss = 3.25591
I0815 21:07:03.392019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.45264 (* 1 = 5.45264 loss)
I0815 21:07:03.392025  1670 sgd_solver.cpp:138] Iteration 33600, lr = 0.0001
I0815 21:16:24.327936  1670 solver.cpp:243] Iteration 33700, loss = 4.17741
I0815 21:16:24.329116  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.07023 (* 1 = 5.07023 loss)
I0815 21:16:24.329123  1670 sgd_solver.cpp:138] Iteration 33700, lr = 0.0001
I0815 21:25:43.159963  1670 solver.cpp:243] Iteration 33800, loss = 3.08324
I0815 21:25:43.161360  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.45082 (* 1 = 1.45082 loss)
I0815 21:25:43.161365  1670 sgd_solver.cpp:138] Iteration 33800, lr = 0.0001
I0815 21:35:04.368618  1670 solver.cpp:243] Iteration 33900, loss = 3.76707
I0815 21:35:04.369940  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.20096 (* 1 = 4.20096 loss)
I0815 21:35:04.369947  1670 sgd_solver.cpp:138] Iteration 33900, lr = 0.0001
I0815 21:44:21.965970  1670 solver.cpp:243] Iteration 34000, loss = 2.89185
I0815 21:44:21.967267  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.86703 (* 1 = 1.86703 loss)
I0815 21:44:21.967274  1670 sgd_solver.cpp:138] Iteration 34000, lr = 0.0001
I0815 21:53:44.394862  1670 solver.cpp:243] Iteration 34100, loss = 3.59809
I0815 21:53:44.396008  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.48972 (* 1 = 2.48972 loss)
I0815 21:53:44.396014  1670 sgd_solver.cpp:138] Iteration 34100, lr = 0.0001
I0815 22:03:01.576756  1670 solver.cpp:243] Iteration 34200, loss = 3.00762
I0815 22:03:01.577836  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.94454 (* 1 = 1.94454 loss)
I0815 22:03:01.577843  1670 sgd_solver.cpp:138] Iteration 34200, lr = 0.0001
I0815 22:12:23.085151  1670 solver.cpp:243] Iteration 34300, loss = 3.11364
I0815 22:12:23.085225  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.09135 (* 1 = 4.09135 loss)
I0815 22:12:23.085232  1670 sgd_solver.cpp:138] Iteration 34300, lr = 0.0001
I0815 22:21:39.477207  1670 solver.cpp:243] Iteration 34400, loss = 2.45214
I0815 22:21:39.478463  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.39474 (* 1 = 1.39474 loss)
I0815 22:21:39.478471  1670 sgd_solver.cpp:138] Iteration 34400, lr = 0.0001
I0815 22:31:01.148036  1670 solver.cpp:243] Iteration 34500, loss = 3.26845
I0815 22:31:01.149242  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.21942 (* 1 = 3.21942 loss)
I0815 22:31:01.149248  1670 sgd_solver.cpp:138] Iteration 34500, lr = 0.0001
I0815 22:40:17.346633  1670 solver.cpp:243] Iteration 34600, loss = 2.33565
I0815 22:40:17.346734  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.47491 (* 1 = 3.47491 loss)
I0815 22:40:17.346741  1670 sgd_solver.cpp:138] Iteration 34600, lr = 0.0001
I0815 22:49:40.266333  1670 solver.cpp:243] Iteration 34700, loss = 3.39867
I0815 22:49:40.267627  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.14553 (* 1 = 1.14553 loss)
I0815 22:49:40.267634  1670 sgd_solver.cpp:138] Iteration 34700, lr = 0.0001
I0815 22:58:56.013396  1670 solver.cpp:243] Iteration 34800, loss = 2.75333
I0815 22:58:56.014698  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.89332 (* 1 = 2.89332 loss)
I0815 22:58:56.014704  1670 sgd_solver.cpp:138] Iteration 34800, lr = 0.0001
I0815 23:08:19.106654  1670 solver.cpp:243] Iteration 34900, loss = 3.38164
I0815 23:08:19.107905  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.87762 (* 1 = 2.87762 loss)
I0815 23:08:19.107913  1670 sgd_solver.cpp:138] Iteration 34900, lr = 0.0001
I0815 23:17:35.259037  1670 solver.cpp:243] Iteration 35000, loss = 2.98955
I0815 23:17:35.260573  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.51348 (* 1 = 3.51348 loss)
I0815 23:17:35.260579  1670 sgd_solver.cpp:138] Iteration 35000, lr = 0.0001
I0815 23:26:59.013339  1670 solver.cpp:243] Iteration 35100, loss = 3.2831
I0815 23:26:59.020278  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.02522 (* 1 = 4.02522 loss)
I0815 23:26:59.020285  1670 sgd_solver.cpp:138] Iteration 35100, lr = 0.0001
I0815 23:36:15.219164  1670 solver.cpp:243] Iteration 35200, loss = 2.77792
I0815 23:36:15.220176  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52288 (* 1 = 2.52288 loss)
I0815 23:36:15.220183  1670 sgd_solver.cpp:138] Iteration 35200, lr = 0.0001
I0815 23:45:38.444187  1670 solver.cpp:243] Iteration 35300, loss = 2.92228
I0815 23:45:38.444265  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.22469 (* 1 = 2.22469 loss)
I0815 23:45:38.444272  1670 sgd_solver.cpp:138] Iteration 35300, lr = 0.0001
I0815 23:54:54.192930  1670 solver.cpp:243] Iteration 35400, loss = 2.21069
I0815 23:54:54.194164  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.57916 (* 1 = 2.57916 loss)
I0815 23:54:54.194170  1670 sgd_solver.cpp:138] Iteration 35400, lr = 0.0001
I0816 00:04:18.004958  1670 solver.cpp:243] Iteration 35500, loss = 3.11044
I0816 00:04:18.006219  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.8636 (* 1 = 3.8636 loss)
I0816 00:04:18.006225  1670 sgd_solver.cpp:138] Iteration 35500, lr = 0.0001
I0816 00:13:36.811321  1670 solver.cpp:243] Iteration 35600, loss = 3.8927
I0816 00:13:36.812254  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.92506 (* 1 = 4.92506 loss)
I0816 00:13:36.812261  1670 sgd_solver.cpp:138] Iteration 35600, lr = 0.0001
I0816 00:22:57.273882  1670 solver.cpp:243] Iteration 35700, loss = 3.20973
I0816 00:22:57.275936  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.62665 (* 1 = 3.62665 loss)
I0816 00:22:57.275944  1670 sgd_solver.cpp:138] Iteration 35700, lr = 0.0001
I0816 00:32:17.197232  1670 solver.cpp:243] Iteration 35800, loss = 4.4652
I0816 00:32:17.198406  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.47695 (* 1 = 3.47695 loss)
I0816 00:32:17.198412  1670 sgd_solver.cpp:138] Iteration 35800, lr = 0.0001
I0816 00:41:36.493758  1670 solver.cpp:243] Iteration 35900, loss = 3.32773
I0816 00:41:36.494997  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.31506 (* 1 = 5.31506 loss)
I0816 00:41:36.495003  1670 sgd_solver.cpp:138] Iteration 35900, lr = 0.0001
I0816 00:50:58.186699  1670 solver.cpp:243] Iteration 36000, loss = 3.97447
I0816 00:50:58.187943  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.35826 (* 1 = 2.35826 loss)
I0816 00:50:58.187952  1670 sgd_solver.cpp:138] Iteration 36000, lr = 0.0001
I0816 01:00:16.450520  1670 solver.cpp:243] Iteration 36100, loss = 2.93177
I0816 01:00:16.451858  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.80893 (* 1 = 1.80893 loss)
I0816 01:00:16.451865  1670 sgd_solver.cpp:138] Iteration 36100, lr = 0.0001
I0816 01:09:38.006197  1670 solver.cpp:243] Iteration 36200, loss = 3.63995
I0816 01:09:38.007761  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.51088 (* 1 = 3.51088 loss)
I0816 01:09:38.007769  1670 sgd_solver.cpp:138] Iteration 36200, lr = 0.0001
I0816 01:18:55.307636  1670 solver.cpp:243] Iteration 36300, loss = 2.76592
I0816 01:18:55.307718  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.59644 (* 1 = 2.59644 loss)
I0816 01:18:55.307724  1670 sgd_solver.cpp:138] Iteration 36300, lr = 0.0001
I0816 01:28:17.091368  1670 solver.cpp:243] Iteration 36400, loss = 3.29208
I0816 01:28:17.092025  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.20998 (* 1 = 3.20998 loss)
I0816 01:28:17.092032  1670 sgd_solver.cpp:138] Iteration 36400, lr = 0.0001
I0816 01:37:34.400573  1670 solver.cpp:243] Iteration 36500, loss = 2.81382
I0816 01:37:34.401840  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.3055 (* 1 = 2.3055 loss)
I0816 01:37:34.401847  1670 sgd_solver.cpp:138] Iteration 36500, lr = 0.0001
I0816 01:46:56.201735  1670 solver.cpp:243] Iteration 36600, loss = 3.18377
I0816 01:46:56.203044  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.59844 (* 1 = 3.59844 loss)
I0816 01:46:56.203052  1670 sgd_solver.cpp:138] Iteration 36600, lr = 0.0001
I0816 01:56:12.883937  1670 solver.cpp:243] Iteration 36700, loss = 2.29128
I0816 01:56:12.884029  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.67182 (* 1 = 3.67182 loss)
I0816 01:56:12.884037  1670 sgd_solver.cpp:138] Iteration 36700, lr = 0.0001
I0816 02:05:35.029932  1670 solver.cpp:243] Iteration 36800, loss = 3.25643
I0816 02:05:35.031172  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.05624 (* 1 = 3.05624 loss)
I0816 02:05:35.031180  1670 sgd_solver.cpp:138] Iteration 36800, lr = 0.0001
I0816 02:14:51.101541  1670 solver.cpp:243] Iteration 36900, loss = 2.43206
I0816 02:14:51.102838  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.89495 (* 1 = 2.89495 loss)
I0816 02:14:51.102849  1670 sgd_solver.cpp:138] Iteration 36900, lr = 0.0001
I0816 02:24:14.487584  1670 solver.cpp:243] Iteration 37000, loss = 3.50243
I0816 02:24:14.488032  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.19693 (* 1 = 4.19693 loss)
I0816 02:24:14.488039  1670 sgd_solver.cpp:138] Iteration 37000, lr = 0.0001
I0816 02:33:30.066658  1670 solver.cpp:243] Iteration 37100, loss = 2.8803
I0816 02:33:30.067916  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.72905 (* 1 = 3.72905 loss)
I0816 02:33:30.067924  1670 sgd_solver.cpp:138] Iteration 37100, lr = 0.0001
I0816 02:42:52.437844  1670 solver.cpp:243] Iteration 37200, loss = 3.44086
I0816 02:42:52.439105  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.06571 (* 1 = 4.06571 loss)
I0816 02:42:52.439111  1670 sgd_solver.cpp:138] Iteration 37200, lr = 0.0001
I0816 02:52:07.845235  1670 solver.cpp:243] Iteration 37300, loss = 2.84213
I0816 02:52:07.846616  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.80082 (* 1 = 2.80082 loss)
I0816 02:52:07.846622  1670 sgd_solver.cpp:138] Iteration 37300, lr = 0.0001
I0816 03:01:30.190070  1670 solver.cpp:243] Iteration 37400, loss = 3.13351
I0816 03:01:30.191325  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.67942 (* 1 = 3.67942 loss)
I0816 03:01:30.191334  1670 sgd_solver.cpp:138] Iteration 37400, lr = 0.0001
I0816 03:10:45.406496  1670 solver.cpp:243] Iteration 37500, loss = 2.75525
I0816 03:10:45.407814  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.37377 (* 1 = 1.37377 loss)
I0816 03:10:45.407822  1670 sgd_solver.cpp:138] Iteration 37500, lr = 0.0001
I0816 03:20:08.998970  1670 solver.cpp:243] Iteration 37600, loss = 2.86059
I0816 03:20:09.000026  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.19497 (* 1 = 2.19497 loss)
I0816 03:20:09.000032  1670 sgd_solver.cpp:138] Iteration 37600, lr = 0.0001
I0816 03:29:24.339056  1670 solver.cpp:243] Iteration 37700, loss = 1.8288
I0816 03:29:24.339968  1670 solver.cpp:259]     Train net output #0: mbox_loss = 7.03206 (* 1 = 7.03206 loss)
I0816 03:29:24.339977  1670 sgd_solver.cpp:138] Iteration 37700, lr = 0.0001
I0816 03:38:46.855001  1670 solver.cpp:243] Iteration 37800, loss = 3.12572
I0816 03:38:46.855088  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.67305 (* 1 = 4.67305 loss)
I0816 03:38:46.855094  1670 sgd_solver.cpp:138] Iteration 37800, lr = 0.0001
I0816 03:48:06.101101  1670 solver.cpp:243] Iteration 37900, loss = 5.09219
I0816 03:48:06.102440  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.47533 (* 1 = 4.47533 loss)
I0816 03:48:06.102448  1670 sgd_solver.cpp:138] Iteration 37900, lr = 0.0001
I0816 03:57:24.767658  1670 solver.cpp:243] Iteration 38000, loss = 3.1434
I0816 03:57:24.768035  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.74851 (* 1 = 3.74851 loss)
I0816 03:57:24.768041  1670 sgd_solver.cpp:138] Iteration 38000, lr = 0.0001
I0816 04:06:45.098032  1670 solver.cpp:243] Iteration 38100, loss = 4.12411
I0816 04:06:45.099426  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.92441 (* 1 = 3.92441 loss)
I0816 04:06:45.099434  1670 sgd_solver.cpp:138] Iteration 38100, lr = 0.0001
I0816 04:16:02.944403  1670 solver.cpp:243] Iteration 38200, loss = 3.16863
I0816 04:16:02.945643  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.10082 (* 1 = 2.10082 loss)
I0816 04:16:02.945650  1670 sgd_solver.cpp:138] Iteration 38200, lr = 0.0001
I0816 04:25:23.708762  1670 solver.cpp:243] Iteration 38300, loss = 3.81754
I0816 04:25:23.709982  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.9268 (* 1 = 3.9268 loss)
I0816 04:25:23.709988  1670 sgd_solver.cpp:138] Iteration 38300, lr = 0.0001
I0816 04:34:41.132195  1670 solver.cpp:243] Iteration 38400, loss = 2.87454
I0816 04:34:41.133512  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.80639 (* 1 = 1.80639 loss)
I0816 04:34:41.133517  1670 sgd_solver.cpp:138] Iteration 38400, lr = 0.0001
I0816 04:44:03.326133  1670 solver.cpp:243] Iteration 38500, loss = 3.6645
I0816 04:44:03.327448  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.86166 (* 1 = 2.86166 loss)
I0816 04:44:03.327455  1670 sgd_solver.cpp:138] Iteration 38500, lr = 0.0001
I0816 04:53:19.730792  1670 solver.cpp:243] Iteration 38600, loss = 2.91633
I0816 04:53:19.730872  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.99093 (* 1 = 1.99093 loss)
I0816 04:53:19.730880  1670 sgd_solver.cpp:138] Iteration 38600, lr = 0.0001
I0816 05:02:40.856842  1670 solver.cpp:243] Iteration 38700, loss = 2.98293
I0816 05:02:40.858125  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.26937 (* 1 = 3.26937 loss)
I0816 05:02:40.858131  1670 sgd_solver.cpp:138] Iteration 38700, lr = 0.0001
I0816 05:11:57.519217  1670 solver.cpp:243] Iteration 38800, loss = 2.55519
I0816 05:11:57.519934  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.81477 (* 1 = 1.81477 loss)
I0816 05:11:57.519942  1670 sgd_solver.cpp:138] Iteration 38800, lr = 0.0001
I0816 05:21:18.821166  1670 solver.cpp:243] Iteration 38900, loss = 3.22258
I0816 05:21:18.822541  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.43544 (* 1 = 3.43544 loss)
I0816 05:21:18.822546  1670 sgd_solver.cpp:138] Iteration 38900, lr = 0.0001
I0816 05:30:34.495250  1670 solver.cpp:243] Iteration 39000, loss = 2.33924
I0816 05:30:34.495982  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.79665 (* 1 = 1.79665 loss)
I0816 05:30:34.495988  1670 sgd_solver.cpp:138] Iteration 39000, lr = 0.0001
I0816 05:39:57.123843  1670 solver.cpp:243] Iteration 39100, loss = 3.42832
I0816 05:39:57.123973  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.3433 (* 1 = 4.3433 loss)
I0816 05:39:57.123980  1670 sgd_solver.cpp:138] Iteration 39100, lr = 0.0001
I0816 05:49:12.359151  1670 solver.cpp:243] Iteration 39200, loss = 2.53029
I0816 05:49:12.359987  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.06087 (* 1 = 3.06087 loss)
I0816 05:49:12.359992  1670 sgd_solver.cpp:138] Iteration 39200, lr = 0.0001
I0816 05:58:35.016556  1670 solver.cpp:243] Iteration 39300, loss = 3.32861
I0816 05:58:35.017855  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.7809 (* 1 = 4.7809 loss)
I0816 05:58:35.017861  1670 sgd_solver.cpp:138] Iteration 39300, lr = 0.0001
I0816 06:07:50.159353  1670 solver.cpp:243] Iteration 39400, loss = 2.90333
I0816 06:07:50.160019  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.09395 (* 1 = 3.09395 loss)
I0816 06:07:50.160025  1670 sgd_solver.cpp:138] Iteration 39400, lr = 0.0001
I0816 06:17:12.690408  1670 solver.cpp:243] Iteration 39500, loss = 3.23282
I0816 06:17:12.691692  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.963533 (* 1 = 0.963533 loss)
I0816 06:17:12.691699  1670 sgd_solver.cpp:138] Iteration 39500, lr = 0.0001
I0816 06:26:28.073906  1670 solver.cpp:243] Iteration 39600, loss = 2.83032
I0816 06:26:28.073987  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.97368 (* 1 = 1.97368 loss)
I0816 06:26:28.073993  1670 sgd_solver.cpp:138] Iteration 39600, lr = 0.0001
I0816 06:35:50.888948  1670 solver.cpp:243] Iteration 39700, loss = 2.90762
I0816 06:35:50.890177  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.86486 (* 1 = 1.86486 loss)
I0816 06:35:50.890183  1670 sgd_solver.cpp:138] Iteration 39700, lr = 0.0001
I0816 06:45:05.872016  1670 solver.cpp:243] Iteration 39800, loss = 2.36017
I0816 06:45:05.873271  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.54034 (* 1 = 1.54034 loss)
I0816 06:45:05.873277  1670 sgd_solver.cpp:138] Iteration 39800, lr = 0.0001
I0816 06:54:28.851285  1670 solver.cpp:243] Iteration 39900, loss = 2.85958
I0816 06:54:28.851910  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.02727 (* 1 = 4.02727 loss)
I0816 06:54:28.851917  1670 sgd_solver.cpp:138] Iteration 39900, lr = 0.0001
I0816 07:03:40.967885  1670 solver.cpp:433] Iteration 40000, Testing net (#0)
I0816 07:03:40.967995  1670 net.cpp:693] Ignoring source layer mbox_loss
W0816 07:06:13.481349  1670 solver.cpp:524] Missing true_pos for label: 22
I0816 07:06:13.481833  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.30178
I0816 07:06:19.098784  1670 solver.cpp:243] Iteration 40000, loss = 3.23083
I0816 07:06:19.098807  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.75076 (* 1 = 4.75076 loss)
I0816 07:06:19.098812  1670 sgd_solver.cpp:138] Iteration 40000, lr = 0.0001
I0816 07:15:39.288687  1670 solver.cpp:243] Iteration 40100, loss = 3.13329
I0816 07:15:39.290006  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.54351 (* 1 = 2.54351 loss)
I0816 07:15:39.290014  1670 sgd_solver.cpp:138] Iteration 40100, lr = 0.0001
I0816 07:24:59.175396  1670 solver.cpp:243] Iteration 40200, loss = 4.6508
I0816 07:24:59.175973  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.83607 (* 1 = 4.83607 loss)
I0816 07:24:59.175979  1670 sgd_solver.cpp:138] Iteration 40200, lr = 0.0001
I0816 07:34:19.026268  1670 solver.cpp:243] Iteration 40300, loss = 3.2671
I0816 07:34:19.027294  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.22692 (* 1 = 2.22692 loss)
I0816 07:34:19.027302  1670 sgd_solver.cpp:138] Iteration 40300, lr = 0.0001
I0816 07:43:39.604151  1670 solver.cpp:243] Iteration 40400, loss = 4.12188
I0816 07:43:39.605367  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.61967 (* 1 = 3.61967 loss)
I0816 07:43:39.605374  1670 sgd_solver.cpp:138] Iteration 40400, lr = 0.0001
I0816 07:52:58.138546  1670 solver.cpp:243] Iteration 40500, loss = 2.94478
I0816 07:52:58.139789  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.75124 (* 1 = 1.75124 loss)
I0816 07:52:58.139797  1670 sgd_solver.cpp:138] Iteration 40500, lr = 0.0001
I0816 08:02:19.797701  1670 solver.cpp:243] Iteration 40600, loss = 3.73341
I0816 08:02:19.798979  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.99146 (* 1 = 3.99146 loss)
I0816 08:02:19.798985  1670 sgd_solver.cpp:138] Iteration 40600, lr = 0.0001
I0816 08:11:37.802733  1670 solver.cpp:243] Iteration 40700, loss = 2.6624
I0816 08:11:37.804018  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.55263 (* 1 = 2.55263 loss)
I0816 08:11:37.804023  1670 sgd_solver.cpp:138] Iteration 40700, lr = 0.0001
I0816 08:21:00.370800  1670 solver.cpp:243] Iteration 40800, loss = 3.43689
I0816 08:21:00.370874  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.50645 (* 1 = 2.50645 loss)
I0816 08:21:00.370882  1670 sgd_solver.cpp:138] Iteration 40800, lr = 0.0001
I0816 08:30:18.560886  1670 solver.cpp:243] Iteration 40900, loss = 2.82419
I0816 08:30:18.562139  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.73894 (* 1 = 1.73894 loss)
I0816 08:30:18.562145  1670 sgd_solver.cpp:138] Iteration 40900, lr = 0.0001
I0816 08:39:41.739259  1670 solver.cpp:243] Iteration 41000, loss = 3.03293
I0816 08:39:41.740046  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.25959 (* 1 = 3.25959 loss)
I0816 08:39:41.740052  1670 sgd_solver.cpp:138] Iteration 41000, lr = 0.0001
I0816 08:48:59.107195  1670 solver.cpp:243] Iteration 41100, loss = 2.36162
I0816 08:48:59.107991  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.78149 (* 1 = 2.78149 loss)
I0816 08:48:59.107998  1670 sgd_solver.cpp:138] Iteration 41100, lr = 0.0001
I0816 08:58:22.356786  1670 solver.cpp:243] Iteration 41200, loss = 3.19503
I0816 08:58:22.358074  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.4739 (* 1 = 4.4739 loss)
I0816 08:58:22.358080  1670 sgd_solver.cpp:138] Iteration 41200, lr = 0.0001
I0816 09:07:39.954818  1670 solver.cpp:243] Iteration 41300, loss = 2.37302
I0816 09:07:39.955993  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.6887 (* 1 = 1.6887 loss)
I0816 09:07:39.955999  1670 sgd_solver.cpp:138] Iteration 41300, lr = 0.0001
I0816 09:17:03.662499  1670 solver.cpp:243] Iteration 41400, loss = 3.55358
I0816 09:17:03.663810  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.51676 (* 1 = 3.51676 loss)
I0816 09:17:03.663818  1670 sgd_solver.cpp:138] Iteration 41400, lr = 0.0001
I0816 09:26:20.387370  1670 solver.cpp:243] Iteration 41500, loss = 2.58051
I0816 09:26:20.388049  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.01296 (* 1 = 3.01296 loss)
I0816 09:26:20.388054  1670 sgd_solver.cpp:138] Iteration 41500, lr = 0.0001
I0816 09:35:43.852237  1670 solver.cpp:243] Iteration 41600, loss = 3.2511
I0816 09:35:43.853462  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.55273 (* 1 = 4.55273 loss)
I0816 09:35:43.853468  1670 sgd_solver.cpp:138] Iteration 41600, lr = 0.0001
I0816 09:44:59.388293  1670 solver.cpp:243] Iteration 41700, loss = 2.79907
I0816 09:44:59.389793  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.59486 (* 1 = 2.59486 loss)
I0816 09:44:59.389801  1670 sgd_solver.cpp:138] Iteration 41700, lr = 0.0001
I0816 09:54:21.898505  1670 solver.cpp:243] Iteration 41800, loss = 3.17145
I0816 09:54:21.899788  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.67584 (* 1 = 3.67584 loss)
I0816 09:54:21.899796  1670 sgd_solver.cpp:138] Iteration 41800, lr = 0.0001
I0816 10:03:37.363849  1670 solver.cpp:243] Iteration 41900, loss = 2.79001
I0816 10:03:37.364030  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.72611 (* 1 = 2.72611 loss)
I0816 10:03:37.364037  1670 sgd_solver.cpp:138] Iteration 41900, lr = 0.0001
I0816 10:12:59.730614  1670 solver.cpp:243] Iteration 42000, loss = 2.76718
I0816 10:12:59.730682  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.6065 (* 1 = 3.6065 loss)
I0816 10:12:59.730689  1670 sgd_solver.cpp:138] Iteration 42000, lr = 0.0001
I0816 10:22:15.450812  1670 solver.cpp:243] Iteration 42100, loss = 1.90671
I0816 10:22:15.451978  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.998297 (* 1 = 0.998297 loss)
I0816 10:22:15.451987  1670 sgd_solver.cpp:138] Iteration 42100, lr = 0.0001
I0816 10:31:39.470598  1670 solver.cpp:243] Iteration 42200, loss = 2.9647
I0816 10:31:39.472199  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.8031 (* 1 = 2.8031 loss)
I0816 10:31:39.472208  1670 sgd_solver.cpp:138] Iteration 42200, lr = 0.0001
I0816 10:40:59.856329  1670 solver.cpp:243] Iteration 42300, loss = 4.60197
I0816 10:40:59.857755  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.8799 (* 1 = 4.8799 loss)
I0816 10:40:59.857761  1670 sgd_solver.cpp:138] Iteration 42300, lr = 0.0001
I0816 10:50:19.510272  1670 solver.cpp:243] Iteration 42400, loss = 3.10416
I0816 10:50:19.510347  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.96967 (* 1 = 2.96967 loss)
I0816 10:50:19.510354  1670 sgd_solver.cpp:138] Iteration 42400, lr = 0.0001
I0816 10:59:41.282454  1670 solver.cpp:243] Iteration 42500, loss = 4.23788
I0816 10:59:41.283844  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.09246 (* 1 = 4.09246 loss)
I0816 10:59:41.283852  1670 sgd_solver.cpp:138] Iteration 42500, lr = 0.0001
I0816 11:09:00.745034  1670 solver.cpp:243] Iteration 42600, loss = 3.22177
I0816 11:09:00.745110  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.50858 (* 1 = 3.50858 loss)
I0816 11:09:00.745115  1670 sgd_solver.cpp:138] Iteration 42600, lr = 0.0001
I0816 11:18:21.346283  1670 solver.cpp:243] Iteration 42700, loss = 3.83334
I0816 11:18:21.347537  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.24464 (* 1 = 4.24464 loss)
I0816 11:18:21.347543  1670 sgd_solver.cpp:138] Iteration 42700, lr = 0.0001
I0816 11:27:39.830286  1670 solver.cpp:243] Iteration 42800, loss = 2.8935
I0816 11:27:39.831528  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.20036 (* 1 = 2.20036 loss)
I0816 11:27:39.831537  1670 sgd_solver.cpp:138] Iteration 42800, lr = 0.0001
I0816 11:37:02.149153  1670 solver.cpp:243] Iteration 42900, loss = 3.66189
I0816 11:37:02.150425  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.23804 (* 1 = 4.23804 loss)
I0816 11:37:02.150431  1670 sgd_solver.cpp:138] Iteration 42900, lr = 0.0001
I0816 11:46:20.086724  1670 solver.cpp:243] Iteration 43000, loss = 2.77128
I0816 11:46:20.088018  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.6566 (* 1 = 2.6566 loss)
I0816 11:46:20.088027  1670 sgd_solver.cpp:138] Iteration 43000, lr = 0.0001
I0816 11:55:42.712085  1670 solver.cpp:243] Iteration 43100, loss = 3.03897
I0816 11:55:42.712168  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.38861 (* 1 = 2.38861 loss)
I0816 11:55:42.712174  1670 sgd_solver.cpp:138] Iteration 43100, lr = 0.0001
I0816 12:04:59.732643  1670 solver.cpp:243] Iteration 43200, loss = 2.54486
I0816 12:04:59.733939  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.40821 (* 1 = 1.40821 loss)
I0816 12:04:59.733945  1670 sgd_solver.cpp:138] Iteration 43200, lr = 0.0001
I0816 12:14:21.490605  1670 solver.cpp:243] Iteration 43300, loss = 3.09462
I0816 12:14:21.491904  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.49622 (* 1 = 3.49622 loss)
I0816 12:14:21.491910  1670 sgd_solver.cpp:138] Iteration 43300, lr = 0.0001
I0816 12:23:38.277210  1670 solver.cpp:243] Iteration 43400, loss = 2.22941
I0816 12:23:38.278530  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.86857 (* 1 = 1.86857 loss)
I0816 12:23:38.278537  1670 sgd_solver.cpp:138] Iteration 43400, lr = 0.0001
I0816 12:33:01.197808  1670 solver.cpp:243] Iteration 43500, loss = 3.30361
I0816 12:33:01.199406  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.75452 (* 1 = 3.75452 loss)
I0816 12:33:01.199414  1670 sgd_solver.cpp:138] Iteration 43500, lr = 0.0001
I0816 12:42:17.700311  1670 solver.cpp:243] Iteration 43600, loss = 2.31751
I0816 12:42:17.701562  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.03472 (* 1 = 1.03472 loss)
I0816 12:42:17.701570  1670 sgd_solver.cpp:138] Iteration 43600, lr = 0.0001
I0816 12:51:41.303009  1670 solver.cpp:243] Iteration 43700, loss = 3.37467
I0816 12:51:41.303977  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.08396 (* 1 = 3.08396 loss)
I0816 12:51:41.303982  1670 sgd_solver.cpp:138] Iteration 43700, lr = 0.0001
I0816 13:00:57.293494  1670 solver.cpp:243] Iteration 43800, loss = 2.875
I0816 13:00:57.294745  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.33363 (* 1 = 4.33363 loss)
I0816 13:00:57.294751  1670 sgd_solver.cpp:138] Iteration 43800, lr = 0.0001
I0816 13:10:20.096761  1670 solver.cpp:243] Iteration 43900, loss = 3.19321
I0816 13:10:20.098085  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.12529 (* 1 = 2.12529 loss)
I0816 13:10:20.098091  1670 sgd_solver.cpp:138] Iteration 43900, lr = 0.0001
I0816 13:19:36.172628  1670 solver.cpp:243] Iteration 44000, loss = 2.80816
I0816 13:19:36.173902  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.40232 (* 1 = 3.40232 loss)
I0816 13:19:36.173908  1670 sgd_solver.cpp:138] Iteration 44000, lr = 0.0001
I0816 13:28:59.701238  1670 solver.cpp:243] Iteration 44100, loss = 3.00442
I0816 13:28:59.702486  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.24442 (* 1 = 2.24442 loss)
I0816 13:28:59.702492  1670 sgd_solver.cpp:138] Iteration 44100, lr = 0.0001
I0816 13:38:15.776556  1670 solver.cpp:243] Iteration 44200, loss = 2.52358
I0816 13:38:15.777740  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.835627 (* 1 = 0.835627 loss)
I0816 13:38:15.777745  1670 sgd_solver.cpp:138] Iteration 44200, lr = 0.0001
I0816 13:47:40.400573  1670 solver.cpp:243] Iteration 44300, loss = 2.7486
I0816 13:47:40.402112  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.29802 (* 1 = 3.29802 loss)
I0816 13:47:40.402118  1670 sgd_solver.cpp:138] Iteration 44300, lr = 0.0001
I0816 13:56:58.057848  1670 solver.cpp:243] Iteration 44400, loss = 2.54679
I0816 13:56:58.059167  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.07506 (* 1 = 6.07506 loss)
I0816 13:56:58.059175  1670 sgd_solver.cpp:138] Iteration 44400, lr = 0.0001
I0816 14:06:20.041448  1670 solver.cpp:243] Iteration 44500, loss = 3.1079
I0816 14:06:20.042755  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.57591 (* 1 = 1.57591 loss)
I0816 14:06:20.042768  1670 sgd_solver.cpp:138] Iteration 44500, lr = 0.0001
I0816 14:15:40.324239  1670 solver.cpp:243] Iteration 44600, loss = 4.96122
I0816 14:15:40.325476  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.17993 (* 1 = 5.17993 loss)
I0816 14:15:40.325482  1670 sgd_solver.cpp:138] Iteration 44600, lr = 0.0001
I0816 14:24:59.647930  1670 solver.cpp:243] Iteration 44700, loss = 3.21817
I0816 14:24:59.648017  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.4832 (* 1 = 4.4832 loss)
I0816 14:24:59.648026  1670 sgd_solver.cpp:138] Iteration 44700, lr = 0.0001
I0816 14:34:19.727471  1670 solver.cpp:243] Iteration 44800, loss = 4.10615
I0816 14:34:19.727568  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.48201 (* 1 = 3.48201 loss)
I0816 14:34:19.727574  1670 sgd_solver.cpp:138] Iteration 44800, lr = 0.0001
I0816 14:43:37.995597  1670 solver.cpp:243] Iteration 44900, loss = 3.04449
I0816 14:43:37.996027  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85793 (* 1 = 2.85793 loss)
I0816 14:43:37.996033  1670 sgd_solver.cpp:138] Iteration 44900, lr = 0.0001
I0816 14:52:59.373070  1670 solver.cpp:243] Iteration 45000, loss = 3.66596
I0816 14:52:59.374385  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.54816 (* 1 = 3.54816 loss)
I0816 14:52:59.374392  1670 sgd_solver.cpp:138] Iteration 45000, lr = 0.0001
I0816 15:02:16.677656  1670 solver.cpp:243] Iteration 45100, loss = 2.70469
I0816 15:02:16.677875  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.87904 (* 1 = 1.87904 loss)
I0816 15:02:16.677881  1670 sgd_solver.cpp:138] Iteration 45100, lr = 0.0001
I0816 15:11:38.687228  1670 solver.cpp:243] Iteration 45200, loss = 3.49683
I0816 15:11:38.688761  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.45743 (* 1 = 4.45743 loss)
I0816 15:11:38.688767  1670 sgd_solver.cpp:138] Iteration 45200, lr = 0.0001
I0816 15:20:55.688380  1670 solver.cpp:243] Iteration 45300, loss = 2.83824
I0816 15:20:55.689656  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.89634 (* 1 = 1.89634 loss)
I0816 15:20:55.689662  1670 sgd_solver.cpp:138] Iteration 45300, lr = 0.0001
I0816 15:30:17.535641  1670 solver.cpp:243] Iteration 45400, loss = 2.96161
I0816 15:30:17.535914  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.48086 (* 1 = 3.48086 loss)
I0816 15:30:17.535921  1670 sgd_solver.cpp:138] Iteration 45400, lr = 0.0001
I0816 15:39:34.481786  1670 solver.cpp:243] Iteration 45500, loss = 2.28956
I0816 15:39:34.483036  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.3822 (* 1 = 1.3822 loss)
I0816 15:39:34.483043  1670 sgd_solver.cpp:138] Iteration 45500, lr = 0.0001
I0816 15:48:56.699929  1670 solver.cpp:243] Iteration 45600, loss = 3.04208
I0816 15:48:56.701222  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.61 (* 1 = 2.61 loss)
I0816 15:48:56.701228  1670 sgd_solver.cpp:138] Iteration 45600, lr = 0.0001
I0816 15:58:13.513546  1670 solver.cpp:243] Iteration 45700, loss = 2.19431
I0816 15:58:13.514894  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.14576 (* 1 = 2.14576 loss)
I0816 15:58:13.514904  1670 sgd_solver.cpp:138] Iteration 45700, lr = 0.0001
I0816 16:07:35.917417  1670 solver.cpp:243] Iteration 45800, loss = 3.23553
I0816 16:07:35.918676  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.83491 (* 1 = 1.83491 loss)
I0816 16:07:35.918682  1670 sgd_solver.cpp:138] Iteration 45800, lr = 0.0001
I0816 16:16:52.434634  1670 solver.cpp:243] Iteration 45900, loss = 2.47708
I0816 16:16:52.435987  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.14054 (* 1 = 4.14054 loss)
I0816 16:16:52.435994  1670 sgd_solver.cpp:138] Iteration 45900, lr = 0.0001
I0816 16:26:15.928665  1670 solver.cpp:243] Iteration 46000, loss = 3.08555
I0816 16:26:15.929870  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.0645 (* 1 = 3.0645 loss)
I0816 16:26:15.929877  1670 sgd_solver.cpp:138] Iteration 46000, lr = 0.0001
I0816 16:35:31.752399  1670 solver.cpp:243] Iteration 46100, loss = 2.70246
I0816 16:35:31.752512  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.3089 (* 1 = 2.3089 loss)
I0816 16:35:31.752521  1670 sgd_solver.cpp:138] Iteration 46100, lr = 0.0001
I0816 16:44:55.423573  1670 solver.cpp:243] Iteration 46200, loss = 3.22581
I0816 16:44:55.424093  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.71912 (* 1 = 3.71912 loss)
I0816 16:44:55.424100  1670 sgd_solver.cpp:138] Iteration 46200, lr = 0.0001
I0816 16:54:11.504515  1670 solver.cpp:243] Iteration 46300, loss = 2.66464
I0816 16:54:11.505782  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.81031 (* 1 = 1.81031 loss)
I0816 16:54:11.505789  1670 sgd_solver.cpp:138] Iteration 46300, lr = 0.0001
I0816 17:03:34.498968  1670 solver.cpp:243] Iteration 46400, loss = 2.84635
I0816 17:03:34.500005  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.52967 (* 1 = 3.52967 loss)
I0816 17:03:34.500023  1670 sgd_solver.cpp:138] Iteration 46400, lr = 0.0001
I0816 17:12:50.253947  1670 solver.cpp:243] Iteration 46500, loss = 2.07483
I0816 17:12:50.255272  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.706763 (* 1 = 0.706763 loss)
I0816 17:12:50.255280  1670 sgd_solver.cpp:138] Iteration 46500, lr = 0.0001
I0816 17:22:14.260761  1670 solver.cpp:243] Iteration 46600, loss = 2.81088
I0816 17:22:14.261947  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.67017 (* 1 = 2.67017 loss)
I0816 17:22:14.261953  1670 sgd_solver.cpp:138] Iteration 46600, lr = 0.0001
I0816 17:31:33.414547  1670 solver.cpp:243] Iteration 46700, loss = 3.95407
I0816 17:31:33.415859  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.7558 (* 1 = 3.7558 loss)
I0816 17:31:33.415865  1670 sgd_solver.cpp:138] Iteration 46700, lr = 0.0001
I0816 17:40:53.662775  1670 solver.cpp:243] Iteration 46800, loss = 2.97603
I0816 17:40:53.662997  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.21887 (* 1 = 5.21887 loss)
I0816 17:40:53.663003  1670 sgd_solver.cpp:138] Iteration 46800, lr = 0.0001
I0816 17:50:14.021330  1670 solver.cpp:243] Iteration 46900, loss = 4.22857
I0816 17:50:14.022590  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.286 (* 1 = 2.286 loss)
I0816 17:50:14.022595  1670 sgd_solver.cpp:138] Iteration 46900, lr = 0.0001
I0816 17:59:33.316927  1670 solver.cpp:243] Iteration 47000, loss = 3.13819
I0816 17:59:33.318151  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.473 (* 1 = 3.473 loss)
I0816 17:59:33.318157  1670 sgd_solver.cpp:138] Iteration 47000, lr = 0.0001
I0816 18:08:54.587823  1670 solver.cpp:243] Iteration 47100, loss = 3.88698
I0816 18:08:54.589076  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.70382 (* 1 = 4.70382 loss)
I0816 18:08:54.589083  1670 sgd_solver.cpp:138] Iteration 47100, lr = 0.0001
I0816 18:18:12.854106  1670 solver.cpp:243] Iteration 47200, loss = 2.91517
I0816 18:18:12.854187  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.18819 (* 1 = 2.18819 loss)
I0816 18:18:12.854192  1670 sgd_solver.cpp:138] Iteration 47200, lr = 0.0001
I0816 18:27:34.170403  1670 solver.cpp:243] Iteration 47300, loss = 3.57209
I0816 18:27:34.170480  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.4635 (* 1 = 3.4635 loss)
I0816 18:27:34.170486  1670 sgd_solver.cpp:138] Iteration 47300, lr = 0.0001
I0816 18:36:51.206401  1670 solver.cpp:243] Iteration 47400, loss = 2.63462
I0816 18:36:51.207659  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.44513 (* 1 = 2.44513 loss)
I0816 18:36:51.207667  1670 sgd_solver.cpp:138] Iteration 47400, lr = 0.0001
I0816 18:46:13.624061  1670 solver.cpp:243] Iteration 47500, loss = 3.19901
I0816 18:46:13.625370  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.29265 (* 1 = 3.29265 loss)
I0816 18:46:13.625376  1670 sgd_solver.cpp:138] Iteration 47500, lr = 0.0001
I0816 18:55:30.922590  1670 solver.cpp:243] Iteration 47600, loss = 2.47993
I0816 18:55:30.923907  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.54801 (* 1 = 2.54801 loss)
I0816 18:55:30.923918  1670 sgd_solver.cpp:138] Iteration 47600, lr = 0.0001
I0816 19:04:53.233167  1670 solver.cpp:243] Iteration 47700, loss = 2.99297
I0816 19:04:53.233247  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.3909 (* 1 = 3.3909 loss)
I0816 19:04:53.233253  1670 sgd_solver.cpp:138] Iteration 47700, lr = 0.0001
I0816 19:14:10.578503  1670 solver.cpp:243] Iteration 47800, loss = 2.20424
I0816 19:14:10.579808  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.6821 (* 1 = 1.6821 loss)
I0816 19:14:10.579816  1670 sgd_solver.cpp:138] Iteration 47800, lr = 0.0001
I0816 19:23:33.886565  1670 solver.cpp:243] Iteration 47900, loss = 3.11148
I0816 19:23:33.887814  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.32541 (* 1 = 1.32541 loss)
I0816 19:23:33.887821  1670 sgd_solver.cpp:138] Iteration 47900, lr = 0.0001
I0816 19:32:51.272912  1670 solver.cpp:243] Iteration 48000, loss = 2.20018
I0816 19:32:51.274155  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.5477 (* 1 = 2.5477 loss)
I0816 19:32:51.274163  1670 sgd_solver.cpp:138] Iteration 48000, lr = 0.0001
I0816 19:42:14.959484  1670 solver.cpp:243] Iteration 48100, loss = 3.26376
I0816 19:42:14.959981  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.75707 (* 1 = 2.75707 loss)
I0816 19:42:14.960001  1670 sgd_solver.cpp:138] Iteration 48100, lr = 0.0001
I0816 19:51:31.755049  1670 solver.cpp:243] Iteration 48200, loss = 2.62601
I0816 19:51:31.756296  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.73547 (* 1 = 2.73547 loss)
I0816 19:51:31.756304  1670 sgd_solver.cpp:138] Iteration 48200, lr = 0.0001
I0816 20:00:56.016187  1670 solver.cpp:243] Iteration 48300, loss = 3.09338
I0816 20:00:56.016288  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.70201 (* 1 = 1.70201 loss)
I0816 20:00:56.016296  1670 sgd_solver.cpp:138] Iteration 48300, lr = 0.0001
I0816 20:10:12.814898  1670 solver.cpp:243] Iteration 48400, loss = 2.67815
I0816 20:10:12.815985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.06892 (* 1 = 3.06892 loss)
I0816 20:10:12.815991  1670 sgd_solver.cpp:138] Iteration 48400, lr = 0.0001
I0816 20:19:36.602447  1670 solver.cpp:243] Iteration 48500, loss = 3.03485
I0816 20:19:36.603744  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.52608 (* 1 = 3.52608 loss)
I0816 20:19:36.603752  1670 sgd_solver.cpp:138] Iteration 48500, lr = 0.0001
I0816 20:28:53.329996  1670 solver.cpp:243] Iteration 48600, loss = 2.5899
I0816 20:28:53.331614  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.50152 (* 1 = 2.50152 loss)
I0816 20:28:53.331624  1670 sgd_solver.cpp:138] Iteration 48600, lr = 0.0001
I0816 20:38:17.629794  1670 solver.cpp:243] Iteration 48700, loss = 2.7199
I0816 20:38:17.631106  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.74698 (* 1 = 2.74698 loss)
I0816 20:38:17.631112  1670 sgd_solver.cpp:138] Iteration 48700, lr = 0.0001
I0816 20:47:34.625844  1670 solver.cpp:243] Iteration 48800, loss = 1.88097
I0816 20:47:34.627022  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.15352 (* 1 = 6.15352 loss)
I0816 20:47:34.627032  1670 sgd_solver.cpp:138] Iteration 48800, lr = 0.0001
I0816 20:56:58.254361  1670 solver.cpp:243] Iteration 48900, loss = 2.99881
I0816 20:56:58.255656  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.46845 (* 1 = 3.46845 loss)
I0816 20:56:58.255663  1670 sgd_solver.cpp:138] Iteration 48900, lr = 0.0001
I0816 21:06:19.461863  1670 solver.cpp:243] Iteration 49000, loss = 4.89705
I0816 21:06:19.463167  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.38553 (* 1 = 3.38553 loss)
I0816 21:06:19.463176  1670 sgd_solver.cpp:138] Iteration 49000, lr = 0.0001
I0816 21:15:39.626766  1670 solver.cpp:243] Iteration 49100, loss = 3.02995
I0816 21:15:39.627960  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.21035 (* 1 = 4.21035 loss)
I0816 21:15:39.627966  1670 sgd_solver.cpp:138] Iteration 49100, lr = 0.0001
I0816 21:25:01.199285  1670 solver.cpp:243] Iteration 49200, loss = 4.06424
I0816 21:25:01.199992  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.73318 (* 1 = 4.73318 loss)
I0816 21:25:01.199998  1670 sgd_solver.cpp:138] Iteration 49200, lr = 0.0001
I0816 21:34:20.541318  1670 solver.cpp:243] Iteration 49300, loss = 2.93299
I0816 21:34:20.542517  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.55085 (* 1 = 2.55085 loss)
I0816 21:34:20.542523  1670 sgd_solver.cpp:138] Iteration 49300, lr = 0.0001
I0816 21:43:42.647656  1670 solver.cpp:243] Iteration 49400, loss = 3.59626
I0816 21:43:42.647969  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.53986 (* 1 = 2.53986 loss)
I0816 21:43:42.647974  1670 sgd_solver.cpp:138] Iteration 49400, lr = 0.0001
I0816 21:53:01.031291  1670 solver.cpp:243] Iteration 49500, loss = 2.65737
I0816 21:53:01.032171  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.22475 (* 1 = 3.22475 loss)
I0816 21:53:01.032177  1670 sgd_solver.cpp:138] Iteration 49500, lr = 0.0001
I0816 22:02:24.365622  1670 solver.cpp:243] Iteration 49600, loss = 3.45204
I0816 22:02:24.367626  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.95817 (* 1 = 3.95817 loss)
I0816 22:02:24.367633  1670 sgd_solver.cpp:138] Iteration 49600, lr = 0.0001
I0816 22:11:41.988360  1670 solver.cpp:243] Iteration 49700, loss = 2.77101
I0816 22:11:41.989825  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.62274 (* 1 = 2.62274 loss)
I0816 22:11:41.989833  1670 sgd_solver.cpp:138] Iteration 49700, lr = 0.0001
I0816 22:21:04.511993  1670 solver.cpp:243] Iteration 49800, loss = 2.84617
I0816 22:21:04.513180  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.08288 (* 1 = 2.08288 loss)
I0816 22:21:04.513187  1670 sgd_solver.cpp:138] Iteration 49800, lr = 0.0001
I0816 22:30:22.467514  1670 solver.cpp:243] Iteration 49900, loss = 2.40972
I0816 22:30:22.468855  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.69444 (* 1 = 2.69444 loss)
I0816 22:30:22.468861  1670 sgd_solver.cpp:138] Iteration 49900, lr = 0.0001
I0816 22:39:39.991379  1670 solver.cpp:596] Snapshotting to binary proto file ./snapshot/VGGNet/YUUAV/SSD_300x300/VGG_YUUAV_SSD_300x300_iter_50000.caffemodel
I0816 22:39:40.642961  1670 sgd_solver.cpp:307] Snapshotting solver state to binary proto file ./snapshot/VGGNet/YUUAV/SSD_300x300/VGG_YUUAV_SSD_300x300_iter_50000.solverstate
I0816 22:39:40.725984  1670 solver.cpp:433] Iteration 50000, Testing net (#0)
I0816 22:39:40.726037  1670 net.cpp:693] Ignoring source layer mbox_loss
W0816 22:42:13.290501  1670 solver.cpp:524] Missing true_pos for label: 20
W0816 22:42:13.291890  1670 solver.cpp:524] Missing true_pos for label: 22
I0816 22:42:13.291899  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.333199
I0816 22:42:18.365501  1670 solver.cpp:243] Iteration 50000, loss = 3.05681
I0816 22:42:18.365523  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.70626 (* 1 = 2.70626 loss)
I0816 22:42:18.365527  1670 sgd_solver.cpp:47] MultiStep Status: Iteration 50000, step = 1
I0816 22:42:18.365530  1670 sgd_solver.cpp:138] Iteration 50000, lr = 1e-05
I0816 22:51:35.363981  1670 solver.cpp:243] Iteration 50100, loss = 2.10245
I0816 22:51:35.365130  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.62497 (* 1 = 2.62497 loss)
I0816 22:51:35.365136  1670 sgd_solver.cpp:138] Iteration 50100, lr = 1e-05
I0816 23:00:58.780834  1670 solver.cpp:243] Iteration 50200, loss = 3.16014
I0816 23:00:58.782050  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.7117 (* 1 = 2.7117 loss)
I0816 23:00:58.782057  1670 sgd_solver.cpp:138] Iteration 50200, lr = 1e-05
I0816 23:10:15.766346  1670 solver.cpp:243] Iteration 50300, loss = 2.34922
I0816 23:10:15.766422  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.59878 (* 1 = 2.59878 loss)
I0816 23:10:15.766428  1670 sgd_solver.cpp:138] Iteration 50300, lr = 1e-05
I0816 23:19:39.860893  1670 solver.cpp:243] Iteration 50400, loss = 3.09604
I0816 23:19:39.862161  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.29173 (* 1 = 2.29173 loss)
I0816 23:19:39.862167  1670 sgd_solver.cpp:138] Iteration 50400, lr = 1e-05
I0816 23:28:56.262456  1670 solver.cpp:243] Iteration 50500, loss = 2.70938
I0816 23:28:56.262562  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52575 (* 1 = 2.52575 loss)
I0816 23:28:56.262569  1670 sgd_solver.cpp:138] Iteration 50500, lr = 1e-05
I0816 23:38:20.471029  1670 solver.cpp:243] Iteration 50600, loss = 3.13303
I0816 23:38:20.471923  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.12443 (* 1 = 2.12443 loss)
I0816 23:38:20.471930  1670 sgd_solver.cpp:138] Iteration 50600, lr = 1e-05
I0816 23:47:37.327988  1670 solver.cpp:243] Iteration 50700, loss = 2.59078
I0816 23:47:37.329304  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.73503 (* 1 = 3.73503 loss)
I0816 23:47:37.329311  1670 sgd_solver.cpp:138] Iteration 50700, lr = 1e-05
I0816 23:57:02.297711  1670 solver.cpp:243] Iteration 50800, loss = 2.81849
I0816 23:57:02.298935  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.13425 (* 1 = 3.13425 loss)
I0816 23:57:02.298943  1670 sgd_solver.cpp:138] Iteration 50800, lr = 1e-05
I0817 00:06:18.435518  1670 solver.cpp:243] Iteration 50900, loss = 2.19553
I0817 00:06:18.435995  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85854 (* 1 = 2.85854 loss)
I0817 00:06:18.436007  1670 sgd_solver.cpp:138] Iteration 50900, lr = 1e-05
I0817 00:15:42.250612  1670 solver.cpp:243] Iteration 51000, loss = 2.66566
I0817 00:15:42.252018  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.14739 (* 1 = 2.14739 loss)
I0817 00:15:42.252027  1670 sgd_solver.cpp:138] Iteration 51000, lr = 1e-05
I0817 00:25:01.981426  1670 solver.cpp:243] Iteration 51100, loss = 3.25446
I0817 00:25:01.982739  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.31608 (* 1 = 5.31608 loss)
I0817 00:25:01.982745  1670 sgd_solver.cpp:138] Iteration 51100, lr = 1e-05
I0817 00:34:23.109494  1670 solver.cpp:243] Iteration 51200, loss = 2.98387
I0817 00:34:23.110741  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.42482 (* 1 = 3.42482 loss)
I0817 00:34:23.110747  1670 sgd_solver.cpp:138] Iteration 51200, lr = 1e-05
I0817 00:43:43.806718  1670 solver.cpp:243] Iteration 51300, loss = 4.38106
I0817 00:43:43.807966  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.98016 (* 1 = 5.98016 loss)
I0817 00:43:43.807986  1670 sgd_solver.cpp:138] Iteration 51300, lr = 1e-05
I0817 00:53:03.301631  1670 solver.cpp:243] Iteration 51400, loss = 2.98057
I0817 00:53:03.302861  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.64958 (* 1 = 1.64958 loss)
I0817 00:53:03.302867  1670 sgd_solver.cpp:138] Iteration 51400, lr = 1e-05
I0817 01:02:24.527246  1670 solver.cpp:243] Iteration 51500, loss = 3.86202
I0817 01:02:24.527915  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.0009 (* 1 = 5.0009 loss)
I0817 01:02:24.527921  1670 sgd_solver.cpp:138] Iteration 51500, lr = 1e-05
I0817 01:11:42.948218  1670 solver.cpp:243] Iteration 51600, loss = 2.82326
I0817 01:11:42.949556  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.85197 (* 1 = 3.85197 loss)
I0817 01:11:42.949563  1670 sgd_solver.cpp:138] Iteration 51600, lr = 1e-05
I0817 01:21:05.258970  1670 solver.cpp:243] Iteration 51700, loss = 3.49358
I0817 01:21:05.260004  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.94989 (* 1 = 2.94989 loss)
I0817 01:21:05.260010  1670 sgd_solver.cpp:138] Iteration 51700, lr = 1e-05
I0817 01:30:22.868877  1670 solver.cpp:243] Iteration 51800, loss = 2.6406
I0817 01:30:22.870172  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.05826 (* 1 = 2.05826 loss)
I0817 01:30:22.870177  1670 sgd_solver.cpp:138] Iteration 51800, lr = 1e-05
I0817 01:39:45.238647  1670 solver.cpp:243] Iteration 51900, loss = 3.24006
I0817 01:39:45.239874  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.02164 (* 1 = 3.02164 loss)
I0817 01:39:45.239881  1670 sgd_solver.cpp:138] Iteration 51900, lr = 1e-05
I0817 01:49:02.904685  1670 solver.cpp:243] Iteration 52000, loss = 2.61167
I0817 01:49:02.906173  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.16391 (* 1 = 2.16391 loss)
I0817 01:49:02.906179  1670 sgd_solver.cpp:138] Iteration 52000, lr = 1e-05
I0817 01:58:24.951957  1670 solver.cpp:243] Iteration 52100, loss = 2.87165
I0817 01:58:24.953207  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.5236 (* 1 = 3.5236 loss)
I0817 01:58:24.953213  1670 sgd_solver.cpp:138] Iteration 52100, lr = 1e-05
I0817 02:07:41.942471  1670 solver.cpp:243] Iteration 52200, loss = 2.13133
I0817 02:07:41.942553  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.61962 (* 1 = 1.61962 loss)
I0817 02:07:41.942559  1670 sgd_solver.cpp:138] Iteration 52200, lr = 1e-05
I0817 02:17:04.222463  1670 solver.cpp:243] Iteration 52300, loss = 2.97162
I0817 02:17:04.223803  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.0682 (* 1 = 3.0682 loss)
I0817 02:17:04.223809  1670 sgd_solver.cpp:138] Iteration 52300, lr = 1e-05
I0817 02:26:20.869117  1670 solver.cpp:243] Iteration 52400, loss = 2.13745
I0817 02:26:20.870350  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.69608 (* 1 = 1.69608 loss)
I0817 02:26:20.870355  1670 sgd_solver.cpp:138] Iteration 52400, lr = 1e-05
I0817 02:35:43.379745  1670 solver.cpp:243] Iteration 52500, loss = 3.20986
I0817 02:35:43.380049  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.76131 (* 1 = 3.76131 loss)
I0817 02:35:43.380056  1670 sgd_solver.cpp:138] Iteration 52500, lr = 1e-05
I0817 02:44:59.723112  1670 solver.cpp:243] Iteration 52600, loss = 2.49918
I0817 02:44:59.724658  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.01338 (* 1 = 3.01338 loss)
I0817 02:44:59.724665  1670 sgd_solver.cpp:138] Iteration 52600, lr = 1e-05
I0817 02:54:22.612706  1670 solver.cpp:243] Iteration 52700, loss = 3.16195
I0817 02:54:22.613939  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.7256 (* 1 = 5.7256 loss)
I0817 02:54:22.613945  1670 sgd_solver.cpp:138] Iteration 52700, lr = 1e-05
I0817 03:03:38.618096  1670 solver.cpp:243] Iteration 52800, loss = 2.63531
I0817 03:03:38.619330  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.94857 (* 1 = 2.94857 loss)
I0817 03:03:38.619345  1670 sgd_solver.cpp:138] Iteration 52800, lr = 1e-05
I0817 03:13:01.749009  1670 solver.cpp:243] Iteration 52900, loss = 3.08482
I0817 03:13:01.749084  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.63058 (* 1 = 3.63058 loss)
I0817 03:13:01.749089  1670 sgd_solver.cpp:138] Iteration 52900, lr = 1e-05
I0817 03:22:17.674080  1670 solver.cpp:243] Iteration 53000, loss = 2.62615
I0817 03:22:17.675390  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.82144 (* 1 = 3.82144 loss)
I0817 03:22:17.675397  1670 sgd_solver.cpp:138] Iteration 53000, lr = 1e-05
I0817 03:31:41.003592  1670 solver.cpp:243] Iteration 53100, loss = 2.66896
I0817 03:31:41.003973  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.62135 (* 1 = 2.62135 loss)
I0817 03:31:41.003979  1670 sgd_solver.cpp:138] Iteration 53100, lr = 1e-05
I0817 03:40:56.469152  1670 solver.cpp:243] Iteration 53200, loss = 1.94857
I0817 03:40:56.470436  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.55546 (* 1 = 2.55546 loss)
I0817 03:40:56.470443  1670 sgd_solver.cpp:138] Iteration 53200, lr = 1e-05
I0817 03:50:20.868955  1670 solver.cpp:243] Iteration 53300, loss = 2.87351
I0817 03:50:20.870290  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.90457 (* 1 = 1.90457 loss)
I0817 03:50:20.870296  1670 sgd_solver.cpp:138] Iteration 53300, lr = 1e-05
I0817 03:59:41.297384  1670 solver.cpp:243] Iteration 53400, loss = 4.36583
I0817 03:59:41.298452  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.37958 (* 1 = 4.37958 loss)
I0817 03:59:41.298458  1670 sgd_solver.cpp:138] Iteration 53400, lr = 1e-05
I0817 04:09:01.580844  1670 solver.cpp:243] Iteration 53500, loss = 3.03498
I0817 04:09:01.582059  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.23316 (* 1 = 3.23316 loss)
I0817 04:09:01.582067  1670 sgd_solver.cpp:138] Iteration 53500, lr = 1e-05
I0817 04:18:22.827812  1670 solver.cpp:243] Iteration 53600, loss = 4.06946
I0817 04:18:22.829069  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.72529 (* 1 = 1.72529 loss)
I0817 04:18:22.829077  1670 sgd_solver.cpp:138] Iteration 53600, lr = 1e-05
I0817 04:27:41.982436  1670 solver.cpp:243] Iteration 53700, loss = 2.88023
I0817 04:27:41.983752  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.90829 (* 1 = 1.90829 loss)
I0817 04:27:41.983760  1670 sgd_solver.cpp:138] Iteration 53700, lr = 1e-05
I0817 04:37:03.611933  1670 solver.cpp:243] Iteration 53800, loss = 3.6649
I0817 04:37:03.613210  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.26272 (* 1 = 4.26272 loss)
I0817 04:37:03.613219  1670 sgd_solver.cpp:138] Iteration 53800, lr = 1e-05
I0817 04:46:21.650061  1670 solver.cpp:243] Iteration 53900, loss = 2.74511
I0817 04:46:21.651324  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.38183 (* 1 = 3.38183 loss)
I0817 04:46:21.651332  1670 sgd_solver.cpp:138] Iteration 53900, lr = 1e-05
I0817 04:55:44.419150  1670 solver.cpp:243] Iteration 54000, loss = 3.58981
I0817 04:55:44.420262  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.03135 (* 1 = 2.03135 loss)
I0817 04:55:44.420269  1670 sgd_solver.cpp:138] Iteration 54000, lr = 1e-05
I0817 05:05:01.870698  1670 solver.cpp:243] Iteration 54100, loss = 2.58184
I0817 05:05:01.871954  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.73262 (* 1 = 1.73262 loss)
I0817 05:05:01.871961  1670 sgd_solver.cpp:138] Iteration 54100, lr = 1e-05
I0817 05:14:23.288733  1670 solver.cpp:243] Iteration 54200, loss = 2.89434
I0817 05:14:23.289923  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.19539 (* 1 = 3.19539 loss)
I0817 05:14:23.289929  1670 sgd_solver.cpp:138] Iteration 54200, lr = 1e-05
I0817 05:23:40.905627  1670 solver.cpp:243] Iteration 54300, loss = 2.49791
I0817 05:23:40.906975  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.45136 (* 1 = 2.45136 loss)
I0817 05:23:40.906983  1670 sgd_solver.cpp:138] Iteration 54300, lr = 1e-05
I0817 05:33:03.149940  1670 solver.cpp:243] Iteration 54400, loss = 3.04667
I0817 05:33:03.151217  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.35553 (* 1 = 3.35553 loss)
I0817 05:33:03.151226  1670 sgd_solver.cpp:138] Iteration 54400, lr = 1e-05
I0817 05:42:20.203799  1670 solver.cpp:243] Iteration 54500, loss = 2.13421
I0817 05:42:20.203891  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.14026 (* 1 = 2.14026 loss)
I0817 05:42:20.203897  1670 sgd_solver.cpp:138] Iteration 54500, lr = 1e-05
I0817 05:51:43.148273  1670 solver.cpp:243] Iteration 54600, loss = 3.11367
I0817 05:51:43.149556  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.0623 (* 1 = 4.0623 loss)
I0817 05:51:43.149562  1670 sgd_solver.cpp:138] Iteration 54600, lr = 1e-05
I0817 06:00:59.368458  1670 solver.cpp:243] Iteration 54700, loss = 2.17892
I0817 06:00:59.369647  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.06163 (* 1 = 3.06163 loss)
I0817 06:00:59.369652  1670 sgd_solver.cpp:138] Iteration 54700, lr = 1e-05
I0817 06:10:22.171103  1670 solver.cpp:243] Iteration 54800, loss = 3.11938
I0817 06:10:22.172058  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.56675 (* 1 = 3.56675 loss)
I0817 06:10:22.172065  1670 sgd_solver.cpp:138] Iteration 54800, lr = 1e-05
I0817 06:19:38.007622  1670 solver.cpp:243] Iteration 54900, loss = 2.76469
I0817 06:19:38.008083  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.43108 (* 1 = 2.43108 loss)
I0817 06:19:38.008090  1670 sgd_solver.cpp:138] Iteration 54900, lr = 1e-05
I0817 06:29:00.980499  1670 solver.cpp:243] Iteration 55000, loss = 3.10098
I0817 06:29:00.981760  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.62113 (* 1 = 3.62113 loss)
I0817 06:29:00.981766  1670 sgd_solver.cpp:138] Iteration 55000, lr = 1e-05
I0817 06:38:16.892899  1670 solver.cpp:243] Iteration 55100, loss = 2.6605
I0817 06:38:16.894150  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.88737 (* 1 = 1.88737 loss)
I0817 06:38:16.894157  1670 sgd_solver.cpp:138] Iteration 55100, lr = 1e-05
I0817 06:47:39.256234  1670 solver.cpp:243] Iteration 55200, loss = 2.84869
I0817 06:47:39.257483  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.27273 (* 1 = 3.27273 loss)
I0817 06:47:39.257489  1670 sgd_solver.cpp:138] Iteration 55200, lr = 1e-05
I0817 06:56:54.665496  1670 solver.cpp:243] Iteration 55300, loss = 2.22522
I0817 06:56:54.666730  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.14498 (* 1 = 1.14498 loss)
I0817 06:56:54.666736  1670 sgd_solver.cpp:138] Iteration 55300, lr = 1e-05
I0817 07:06:18.454850  1670 solver.cpp:243] Iteration 55400, loss = 2.75824
I0817 07:06:18.456023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.68767 (* 1 = 1.68767 loss)
I0817 07:06:18.456030  1670 sgd_solver.cpp:138] Iteration 55400, lr = 1e-05
I0817 07:15:36.513613  1670 solver.cpp:243] Iteration 55500, loss = 2.55915
I0817 07:15:36.514927  1670 solver.cpp:259]     Train net output #0: mbox_loss = 7.35563 (* 1 = 7.35563 loss)
I0817 07:15:36.514933  1670 sgd_solver.cpp:138] Iteration 55500, lr = 1e-05
I0817 07:24:57.743409  1670 solver.cpp:243] Iteration 55600, loss = 2.8746
I0817 07:24:57.743505  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.05997 (* 1 = 3.05997 loss)
I0817 07:24:57.743511  1670 sgd_solver.cpp:138] Iteration 55600, lr = 1e-05
I0817 07:34:18.041350  1670 solver.cpp:243] Iteration 55700, loss = 4.73899
I0817 07:34:18.041437  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.09768 (* 1 = 4.09768 loss)
I0817 07:34:18.041443  1670 sgd_solver.cpp:138] Iteration 55700, lr = 1e-05
I0817 07:43:37.760031  1670 solver.cpp:243] Iteration 55800, loss = 3.01695
I0817 07:43:37.761250  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.15773 (* 1 = 3.15773 loss)
I0817 07:43:37.761257  1670 sgd_solver.cpp:138] Iteration 55800, lr = 1e-05
I0817 07:52:58.785034  1670 solver.cpp:243] Iteration 55900, loss = 3.83479
I0817 07:52:58.786233  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.77243 (* 1 = 3.77243 loss)
I0817 07:52:58.786239  1670 sgd_solver.cpp:138] Iteration 55900, lr = 1e-05
I0817 08:02:17.740198  1670 solver.cpp:243] Iteration 56000, loss = 2.92342
I0817 08:02:17.741437  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.47026 (* 1 = 2.47026 loss)
I0817 08:02:17.741442  1670 sgd_solver.cpp:138] Iteration 56000, lr = 1e-05
I0817 08:11:39.121696  1670 solver.cpp:243] Iteration 56100, loss = 3.54253
I0817 08:11:39.122645  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.72228 (* 1 = 3.72228 loss)
I0817 08:11:39.122653  1670 sgd_solver.cpp:138] Iteration 56100, lr = 1e-05
I0817 08:20:56.884848  1670 solver.cpp:243] Iteration 56200, loss = 2.67746
I0817 08:20:56.886103  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.15441 (* 1 = 2.15441 loss)
I0817 08:20:56.886109  1670 sgd_solver.cpp:138] Iteration 56200, lr = 1e-05
I0817 08:30:19.564828  1670 solver.cpp:243] Iteration 56300, loss = 3.35171
I0817 08:30:19.564903  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.47873 (* 1 = 4.47873 loss)
I0817 08:30:19.564908  1670 sgd_solver.cpp:138] Iteration 56300, lr = 1e-05
I0817 08:39:37.520692  1670 solver.cpp:243] Iteration 56400, loss = 2.66991
I0817 08:39:37.521982  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.90423 (* 1 = 1.90423 loss)
I0817 08:39:37.521988  1670 sgd_solver.cpp:138] Iteration 56400, lr = 1e-05
I0817 08:49:00.831257  1670 solver.cpp:243] Iteration 56500, loss = 2.77303
I0817 08:49:00.832074  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.30171 (* 1 = 3.30171 loss)
I0817 08:49:00.832082  1670 sgd_solver.cpp:138] Iteration 56500, lr = 1e-05
I0817 08:58:18.286026  1670 solver.cpp:243] Iteration 56600, loss = 2.2006
I0817 08:58:18.287326  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.66557 (* 1 = 2.66557 loss)
I0817 08:58:18.287334  1670 sgd_solver.cpp:138] Iteration 56600, lr = 1e-05
I0817 09:07:41.223140  1670 solver.cpp:243] Iteration 56700, loss = 2.99394
I0817 09:07:41.223923  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.0083 (* 1 = 2.0083 loss)
I0817 09:07:41.223930  1670 sgd_solver.cpp:138] Iteration 56700, lr = 1e-05
I0817 09:16:58.576082  1670 solver.cpp:243] Iteration 56800, loss = 2.09517
I0817 09:16:58.577620  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.6441 (* 1 = 3.6441 loss)
I0817 09:16:58.577626  1670 sgd_solver.cpp:138] Iteration 56800, lr = 1e-05
I0817 09:26:21.924039  1670 solver.cpp:243] Iteration 56900, loss = 3.00709
I0817 09:26:21.925230  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.07139 (* 1 = 4.07139 loss)
I0817 09:26:21.925235  1670 sgd_solver.cpp:138] Iteration 56900, lr = 1e-05
I0817 09:35:37.912580  1670 solver.cpp:243] Iteration 57000, loss = 2.34136
I0817 09:35:37.913893  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.89165 (* 1 = 3.89165 loss)
I0817 09:35:37.913900  1670 sgd_solver.cpp:138] Iteration 57000, lr = 1e-05
I0817 09:45:00.375684  1670 solver.cpp:243] Iteration 57100, loss = 3.05408
I0817 09:45:00.375890  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.10965 (* 1 = 3.10965 loss)
I0817 09:45:00.375895  1670 sgd_solver.cpp:138] Iteration 57100, lr = 1e-05
I0817 09:54:15.998148  1670 solver.cpp:243] Iteration 57200, loss = 2.64161
I0817 09:54:15.998764  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.4997 (* 1 = 2.4997 loss)
I0817 09:54:15.998770  1670 sgd_solver.cpp:138] Iteration 57200, lr = 1e-05
I0817 10:03:38.776111  1670 solver.cpp:243] Iteration 57300, loss = 3.03571
I0817 10:03:38.777365  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.04577 (* 1 = 2.04577 loss)
I0817 10:03:38.777372  1670 sgd_solver.cpp:138] Iteration 57300, lr = 1e-05
I0817 10:12:54.197481  1670 solver.cpp:243] Iteration 57400, loss = 2.6355
I0817 10:12:54.197638  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.80754 (* 1 = 2.80754 loss)
I0817 10:12:54.197644  1670 sgd_solver.cpp:138] Iteration 57400, lr = 1e-05
I0817 10:22:17.002466  1670 solver.cpp:243] Iteration 57500, loss = 2.68569
I0817 10:22:17.003757  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.09665 (* 1 = 3.09665 loss)
I0817 10:22:17.003767  1670 sgd_solver.cpp:138] Iteration 57500, lr = 1e-05
I0817 10:31:31.983702  1670 solver.cpp:243] Iteration 57600, loss = 1.96122
I0817 10:31:31.985007  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.25273 (* 1 = 2.25273 loss)
I0817 10:31:31.985014  1670 sgd_solver.cpp:138] Iteration 57600, lr = 1e-05
I0817 10:40:55.131839  1670 solver.cpp:243] Iteration 57700, loss = 2.83188
I0817 10:40:55.131963  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.53917 (* 1 = 2.53917 loss)
I0817 10:40:55.131969  1670 sgd_solver.cpp:138] Iteration 57700, lr = 1e-05
I0817 10:50:13.590991  1670 solver.cpp:243] Iteration 57800, loss = 3.79461
I0817 10:50:13.592023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 7.10322 (* 1 = 7.10322 loss)
I0817 10:50:13.592031  1670 sgd_solver.cpp:138] Iteration 57800, lr = 1e-05
I0817 10:59:33.144789  1670 solver.cpp:243] Iteration 57900, loss = 2.97645
I0817 10:59:33.145958  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.44314 (* 1 = 3.44314 loss)
I0817 10:59:33.145964  1670 sgd_solver.cpp:138] Iteration 57900, lr = 1e-05
I0817 11:08:53.578727  1670 solver.cpp:243] Iteration 58000, loss = 4.22911
I0817 11:08:53.579985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.395 (* 1 = 4.395 loss)
I0817 11:08:53.579993  1670 sgd_solver.cpp:138] Iteration 58000, lr = 1e-05
I0817 11:18:12.115514  1670 solver.cpp:243] Iteration 58100, loss = 2.99936
I0817 11:18:12.115952  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.14245 (* 1 = 2.14245 loss)
I0817 11:18:12.115958  1670 sgd_solver.cpp:138] Iteration 58100, lr = 1e-05
I0817 11:27:32.349053  1670 solver.cpp:243] Iteration 58200, loss = 3.74471
I0817 11:27:32.350265  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.36484 (* 1 = 4.36484 loss)
I0817 11:27:32.350271  1670 sgd_solver.cpp:138] Iteration 58200, lr = 1e-05
I0817 11:36:49.486837  1670 solver.cpp:243] Iteration 58300, loss = 2.81208
I0817 11:36:49.488255  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.42395 (* 1 = 2.42395 loss)
I0817 11:36:49.488261  1670 sgd_solver.cpp:138] Iteration 58300, lr = 1e-05
I0817 11:46:10.072432  1670 solver.cpp:243] Iteration 58400, loss = 3.50687
I0817 11:46:10.073755  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.41058 (* 1 = 2.41058 loss)
I0817 11:46:10.073761  1670 sgd_solver.cpp:138] Iteration 58400, lr = 1e-05
I0817 11:55:26.418186  1670 solver.cpp:243] Iteration 58500, loss = 2.5311
I0817 11:55:26.419577  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.94114 (* 1 = 2.94114 loss)
I0817 11:55:26.419587  1670 sgd_solver.cpp:138] Iteration 58500, lr = 1e-05
I0817 12:04:47.994863  1670 solver.cpp:243] Iteration 58600, loss = 3.03031
I0817 12:04:47.995944  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.50053 (* 1 = 3.50053 loss)
I0817 12:04:47.995950  1670 sgd_solver.cpp:138] Iteration 58600, lr = 1e-05
I0817 12:14:03.981412  1670 solver.cpp:243] Iteration 58700, loss = 2.53411
I0817 12:14:03.982707  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.12497 (* 1 = 2.12497 loss)
I0817 12:14:03.982713  1670 sgd_solver.cpp:138] Iteration 58700, lr = 1e-05
I0817 12:23:25.295389  1670 solver.cpp:243] Iteration 58800, loss = 2.97245
I0817 12:23:25.295994  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.55878 (* 1 = 3.55878 loss)
I0817 12:23:25.296000  1670 sgd_solver.cpp:138] Iteration 58800, lr = 1e-05
I0817 12:32:40.982281  1670 solver.cpp:243] Iteration 58900, loss = 2.08159
I0817 12:32:40.983564  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.76518 (* 1 = 1.76518 loss)
I0817 12:32:40.983573  1670 sgd_solver.cpp:138] Iteration 58900, lr = 1e-05
I0817 12:42:02.912418  1670 solver.cpp:243] Iteration 59000, loss = 2.91295
I0817 12:42:02.913681  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.6218 (* 1 = 3.6218 loss)
I0817 12:42:02.913689  1670 sgd_solver.cpp:138] Iteration 59000, lr = 1e-05
I0817 12:51:18.522586  1670 solver.cpp:243] Iteration 59100, loss = 2.15794
I0817 12:51:18.523924  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.87391 (* 1 = 1.87391 loss)
I0817 12:51:18.523932  1670 sgd_solver.cpp:138] Iteration 59100, lr = 1e-05
I0817 13:00:41.336666  1670 solver.cpp:243] Iteration 59200, loss = 3.10266
I0817 13:00:41.336742  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.4544 (* 1 = 3.4544 loss)
I0817 13:00:41.336750  1670 sgd_solver.cpp:138] Iteration 59200, lr = 1e-05
I0817 13:09:56.384369  1670 solver.cpp:243] Iteration 59300, loss = 2.68289
I0817 13:09:56.385609  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.43222 (* 1 = 4.43222 loss)
I0817 13:09:56.385615  1670 sgd_solver.cpp:138] Iteration 59300, lr = 1e-05
I0817 13:19:18.902027  1670 solver.cpp:243] Iteration 59400, loss = 3.06949
I0817 13:19:18.903380  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.94529 (* 1 = 2.94529 loss)
I0817 13:19:18.903389  1670 sgd_solver.cpp:138] Iteration 59400, lr = 1e-05
I0817 13:28:34.694391  1670 solver.cpp:243] Iteration 59500, loss = 2.627
I0817 13:28:34.695739  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.86199 (* 1 = 3.86199 loss)
I0817 13:28:34.695749  1670 sgd_solver.cpp:138] Iteration 59500, lr = 1e-05
I0817 13:37:58.356348  1670 solver.cpp:243] Iteration 59600, loss = 2.96902
I0817 13:37:58.357725  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.97959 (* 1 = 1.97959 loss)
I0817 13:37:58.357730  1670 sgd_solver.cpp:138] Iteration 59600, lr = 1e-05
I0817 13:47:14.370899  1670 solver.cpp:243] Iteration 59700, loss = 2.49922
I0817 13:47:14.371990  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.6376 (* 1 = 1.6376 loss)
I0817 13:47:14.371999  1670 sgd_solver.cpp:138] Iteration 59700, lr = 1e-05
I0817 13:56:37.503633  1670 solver.cpp:243] Iteration 59800, loss = 2.61002
I0817 13:56:37.503962  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.62308 (* 1 = 3.62308 loss)
I0817 13:56:37.503970  1670 sgd_solver.cpp:138] Iteration 59800, lr = 1e-05
I0817 14:05:53.979868  1670 solver.cpp:243] Iteration 59900, loss = 1.86794
I0817 14:05:53.980068  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.55327 (* 1 = 5.55327 loss)
I0817 14:05:53.980077  1670 sgd_solver.cpp:138] Iteration 59900, lr = 1e-05
I0817 14:15:11.075839  1670 solver.cpp:433] Iteration 60000, Testing net (#0)
I0817 14:15:11.076030  1670 net.cpp:693] Ignoring source layer mbox_loss
W0817 14:17:44.002264  1670 solver.cpp:524] Missing true_pos for label: 20
W0817 14:17:44.003561  1670 solver.cpp:524] Missing true_pos for label: 22
I0817 14:17:44.003572  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.358103
I0817 14:17:49.168285  1670 solver.cpp:243] Iteration 60000, loss = 2.92123
I0817 14:17:49.168310  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.67097 (* 1 = 2.67097 loss)
I0817 14:17:49.168316  1670 sgd_solver.cpp:138] Iteration 60000, lr = 1e-05
I0817 14:27:09.454793  1670 solver.cpp:243] Iteration 60100, loss = 4.63901
I0817 14:27:09.455945  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.83567 (* 1 = 2.83567 loss)
I0817 14:27:09.455965  1670 sgd_solver.cpp:138] Iteration 60100, lr = 1e-05
I0817 14:36:29.919184  1670 solver.cpp:243] Iteration 60200, loss = 2.94808
I0817 14:36:29.920301  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.04375 (* 1 = 2.04375 loss)
I0817 14:36:29.920308  1670 sgd_solver.cpp:138] Iteration 60200, lr = 1e-05
I0817 14:45:50.570533  1670 solver.cpp:243] Iteration 60300, loss = 3.72668
I0817 14:45:50.571831  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.53668 (* 1 = 2.53668 loss)
I0817 14:45:50.571841  1670 sgd_solver.cpp:138] Iteration 60300, lr = 1e-05
I0817 14:55:08.839201  1670 solver.cpp:243] Iteration 60400, loss = 2.85992
I0817 14:55:08.840065  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.69693 (* 1 = 2.69693 loss)
I0817 14:55:08.840070  1670 sgd_solver.cpp:138] Iteration 60400, lr = 1e-05
I0817 15:04:30.311761  1670 solver.cpp:243] Iteration 60500, loss = 3.66256
I0817 15:04:30.311940  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.53458 (* 1 = 3.53458 loss)
I0817 15:04:30.311945  1670 sgd_solver.cpp:138] Iteration 60500, lr = 1e-05
I0817 15:13:47.946224  1670 solver.cpp:243] Iteration 60600, loss = 2.68266
I0817 15:13:47.947481  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.48536 (* 1 = 2.48536 loss)
I0817 15:13:47.947487  1670 sgd_solver.cpp:138] Iteration 60600, lr = 1e-05
I0817 15:23:09.413923  1670 solver.cpp:243] Iteration 60700, loss = 3.4187
I0817 15:23:09.413990  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.47627 (* 1 = 3.47627 loss)
I0817 15:23:09.413997  1670 sgd_solver.cpp:138] Iteration 60700, lr = 1e-05
I0817 15:32:26.626559  1670 solver.cpp:243] Iteration 60800, loss = 2.66321
I0817 15:32:26.627912  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.00886 (* 1 = 2.00886 loss)
I0817 15:32:26.627918  1670 sgd_solver.cpp:138] Iteration 60800, lr = 1e-05
I0817 15:41:49.349185  1670 solver.cpp:243] Iteration 60900, loss = 2.88188
I0817 15:41:49.350455  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.40208 (* 1 = 2.40208 loss)
I0817 15:41:49.350462  1670 sgd_solver.cpp:138] Iteration 60900, lr = 1e-05
I0817 15:51:06.449692  1670 solver.cpp:243] Iteration 61000, loss = 2.32474
I0817 15:51:06.451460  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.07256 (* 1 = 1.07256 loss)
I0817 15:51:06.451483  1670 sgd_solver.cpp:138] Iteration 61000, lr = 1e-05
I0817 16:00:28.825722  1670 solver.cpp:243] Iteration 61100, loss = 3.03727
I0817 16:00:28.825806  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.29115 (* 1 = 1.29115 loss)
I0817 16:00:28.825812  1670 sgd_solver.cpp:138] Iteration 61100, lr = 1e-05
I0817 16:09:45.013923  1670 solver.cpp:243] Iteration 61200, loss = 2.04287
I0817 16:09:45.015355  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.35304 (* 1 = 2.35304 loss)
I0817 16:09:45.015364  1670 sgd_solver.cpp:138] Iteration 61200, lr = 1e-05
I0817 16:19:08.490626  1670 solver.cpp:243] Iteration 61300, loss = 2.98109
I0817 16:19:08.492023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.58008 (* 1 = 4.58008 loss)
I0817 16:19:08.492031  1670 sgd_solver.cpp:138] Iteration 61300, lr = 1e-05
I0817 16:28:24.204414  1670 solver.cpp:243] Iteration 61400, loss = 2.35479
I0817 16:28:24.205689  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.7072 (* 1 = 3.7072 loss)
I0817 16:28:24.205695  1670 sgd_solver.cpp:138] Iteration 61400, lr = 1e-05
I0817 16:37:47.937820  1670 solver.cpp:243] Iteration 61500, loss = 2.9818
I0817 16:37:47.939077  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.5436 (* 1 = 3.5436 loss)
I0817 16:37:47.939083  1670 sgd_solver.cpp:138] Iteration 61500, lr = 1e-05
I0817 16:47:04.322376  1670 solver.cpp:243] Iteration 61600, loss = 2.6636
I0817 16:47:04.322463  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.81878 (* 1 = 1.81878 loss)
I0817 16:47:04.322470  1670 sgd_solver.cpp:138] Iteration 61600, lr = 1e-05
I0817 16:56:27.608994  1670 solver.cpp:243] Iteration 61700, loss = 3.04943
I0817 16:56:27.609426  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.12898 (* 1 = 3.12898 loss)
I0817 16:56:27.609433  1670 sgd_solver.cpp:138] Iteration 61700, lr = 1e-05
I0817 17:05:43.531116  1670 solver.cpp:243] Iteration 61800, loss = 2.53315
I0817 17:05:43.531205  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.48543 (* 1 = 2.48543 loss)
I0817 17:05:43.531211  1670 sgd_solver.cpp:138] Iteration 61800, lr = 1e-05
I0817 17:15:06.953647  1670 solver.cpp:243] Iteration 61900, loss = 2.81074
I0817 17:15:06.953722  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.89658 (* 1 = 3.89658 loss)
I0817 17:15:06.953729  1670 sgd_solver.cpp:138] Iteration 61900, lr = 1e-05
I0817 17:24:22.986739  1670 solver.cpp:243] Iteration 62000, loss = 2.16401
I0817 17:24:22.988014  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82741 (* 1 = 2.82741 loss)
I0817 17:24:22.988021  1670 sgd_solver.cpp:138] Iteration 62000, lr = 1e-05
I0817 17:33:46.288655  1670 solver.cpp:243] Iteration 62100, loss = 2.61042
I0817 17:33:46.290215  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.85784 (* 1 = 1.85784 loss)
I0817 17:33:46.290221  1670 sgd_solver.cpp:138] Iteration 62100, lr = 1e-05
I0817 17:43:05.313033  1670 solver.cpp:243] Iteration 62200, loss = 3.30177
I0817 17:43:05.313113  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.13591 (* 1 = 5.13591 loss)
I0817 17:43:05.313120  1670 sgd_solver.cpp:138] Iteration 62200, lr = 1e-05
I0817 17:52:26.242084  1670 solver.cpp:243] Iteration 62300, loss = 2.85368
I0817 17:52:26.243374  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.9368 (* 1 = 3.9368 loss)
I0817 17:52:26.243383  1670 sgd_solver.cpp:138] Iteration 62300, lr = 1e-05
I0817 18:01:45.841075  1670 solver.cpp:243] Iteration 62400, loss = 4.37246
I0817 18:01:45.842284  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.35229 (* 1 = 4.35229 loss)
I0817 18:01:45.842290  1670 sgd_solver.cpp:138] Iteration 62400, lr = 1e-05
I0817 18:11:05.484207  1670 solver.cpp:243] Iteration 62500, loss = 3.04424
I0817 18:11:05.484284  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.28811 (* 1 = 2.28811 loss)
I0817 18:11:05.484290  1670 sgd_solver.cpp:138] Iteration 62500, lr = 1e-05
I0817 18:20:26.277559  1670 solver.cpp:243] Iteration 62600, loss = 3.88423
I0817 18:20:26.278842  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.90888 (* 1 = 1.90888 loss)
I0817 18:20:26.278852  1670 sgd_solver.cpp:138] Iteration 62600, lr = 1e-05
I0817 18:29:44.355412  1670 solver.cpp:243] Iteration 62700, loss = 2.78595
I0817 18:29:44.357035  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.15573 (* 1 = 3.15573 loss)
I0817 18:29:44.357041  1670 sgd_solver.cpp:138] Iteration 62700, lr = 1e-05
I0817 18:39:05.104249  1670 solver.cpp:243] Iteration 62800, loss = 3.44641
I0817 18:39:05.113059  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.78168 (* 1 = 4.78168 loss)
I0817 18:39:05.113066  1670 sgd_solver.cpp:138] Iteration 62800, lr = 1e-05
I0817 18:48:21.985081  1670 solver.cpp:243] Iteration 62900, loss = 2.65505
I0817 18:48:21.986115  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.21738 (* 1 = 3.21738 loss)
I0817 18:48:21.986124  1670 sgd_solver.cpp:138] Iteration 62900, lr = 1e-05
I0817 18:57:43.920465  1670 solver.cpp:243] Iteration 63000, loss = 3.09767
I0817 18:57:43.921751  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.12208 (* 1 = 3.12208 loss)
I0817 18:57:43.921756  1670 sgd_solver.cpp:138] Iteration 63000, lr = 1e-05
I0817 19:07:00.814528  1670 solver.cpp:243] Iteration 63100, loss = 2.5408
I0817 19:07:00.815791  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.72954 (* 1 = 2.72954 loss)
I0817 19:07:00.815799  1670 sgd_solver.cpp:138] Iteration 63100, lr = 1e-05
I0817 19:16:22.704771  1670 solver.cpp:243] Iteration 63200, loss = 2.88498
I0817 19:16:22.706055  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.59893 (* 1 = 3.59893 loss)
I0817 19:16:22.706063  1670 sgd_solver.cpp:138] Iteration 63200, lr = 1e-05
I0817 19:25:39.660775  1670 solver.cpp:243] Iteration 63300, loss = 2.13216
I0817 19:25:39.661981  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.43989 (* 1 = 1.43989 loss)
I0817 19:25:39.661988  1670 sgd_solver.cpp:138] Iteration 63300, lr = 1e-05
I0817 19:35:02.317982  1670 solver.cpp:243] Iteration 63400, loss = 3.07081
I0817 19:35:02.319288  1670 solver.cpp:259]     Train net output #0: mbox_loss = 5.08682 (* 1 = 5.08682 loss)
I0817 19:35:02.319295  1670 sgd_solver.cpp:138] Iteration 63400, lr = 1e-05
I0817 19:44:18.586907  1670 solver.cpp:243] Iteration 63500, loss = 2.11987
I0817 19:44:18.587960  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.33102 (* 1 = 3.33102 loss)
I0817 19:44:18.587966  1670 sgd_solver.cpp:138] Iteration 63500, lr = 1e-05
I0817 19:53:41.735873  1670 solver.cpp:243] Iteration 63600, loss = 3.20916
I0817 19:53:41.735958  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.33109 (* 1 = 3.33109 loss)
I0817 19:53:41.735965  1670 sgd_solver.cpp:138] Iteration 63600, lr = 1e-05
I0817 20:02:57.409970  1670 solver.cpp:243] Iteration 63700, loss = 2.48331
I0817 20:02:57.411278  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.31014 (* 1 = 2.31014 loss)
I0817 20:02:57.411288  1670 sgd_solver.cpp:138] Iteration 63700, lr = 1e-05
I0817 20:12:20.280012  1670 solver.cpp:243] Iteration 63800, loss = 2.96695
I0817 20:12:20.280467  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.5873 (* 1 = 2.5873 loss)
I0817 20:12:20.280477  1670 sgd_solver.cpp:138] Iteration 63800, lr = 1e-05
I0817 20:21:36.075158  1670 solver.cpp:243] Iteration 63900, loss = 2.69954
I0817 20:21:36.075960  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.86876 (* 1 = 2.86876 loss)
I0817 20:21:36.075965  1670 sgd_solver.cpp:138] Iteration 63900, lr = 1e-05
I0817 20:30:59.975970  1670 solver.cpp:243] Iteration 64000, loss = 3.11901
I0817 20:30:59.977206  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.61314 (* 1 = 1.61314 loss)
I0817 20:30:59.977213  1670 sgd_solver.cpp:138] Iteration 64000, lr = 1e-05
I0817 20:40:15.491127  1670 solver.cpp:243] Iteration 64100, loss = 2.58933
I0817 20:40:15.491930  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.42515 (* 1 = 2.42515 loss)
I0817 20:40:15.491936  1670 sgd_solver.cpp:138] Iteration 64100, lr = 1e-05
I0817 20:49:39.292234  1670 solver.cpp:243] Iteration 64200, loss = 2.64444
I0817 20:49:39.293534  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.34177 (* 1 = 3.34177 loss)
I0817 20:49:39.293540  1670 sgd_solver.cpp:138] Iteration 64200, lr = 1e-05
I0817 20:58:55.589131  1670 solver.cpp:243] Iteration 64300, loss = 1.73093
I0817 20:58:55.590680  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.350198 (* 1 = 0.350198 loss)
I0817 20:58:55.590687  1670 sgd_solver.cpp:138] Iteration 64300, lr = 1e-05
I0817 21:08:19.980929  1670 solver.cpp:243] Iteration 64400, loss = 2.84693
I0817 21:08:19.982264  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.5713 (* 1 = 1.5713 loss)
I0817 21:08:19.982270  1670 sgd_solver.cpp:138] Iteration 64400, lr = 1e-05
I0817 21:17:39.926810  1670 solver.cpp:243] Iteration 64500, loss = 4.18106
I0817 21:17:39.926882  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.73845 (* 1 = 3.73845 loss)
I0817 21:17:39.926887  1670 sgd_solver.cpp:138] Iteration 64500, lr = 1e-05
I0817 21:26:59.450664  1670 solver.cpp:243] Iteration 64600, loss = 2.9421
I0817 21:26:59.451912  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.744 (* 1 = 2.744 loss)
I0817 21:26:59.451921  1670 sgd_solver.cpp:138] Iteration 64600, lr = 1e-05
I0817 21:36:20.124416  1670 solver.cpp:243] Iteration 64700, loss = 3.95675
I0817 21:36:20.125722  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.88235 (* 1 = 3.88235 loss)
I0817 21:36:20.125728  1670 sgd_solver.cpp:138] Iteration 64700, lr = 1e-05
I0817 21:45:39.038231  1670 solver.cpp:243] Iteration 64800, loss = 3.03277
I0817 21:45:39.038326  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.01533 (* 1 = 2.01533 loss)
I0817 21:45:39.038331  1670 sgd_solver.cpp:138] Iteration 64800, lr = 1e-05
I0817 21:55:00.401376  1670 solver.cpp:243] Iteration 64900, loss = 3.55554
I0817 21:55:00.402626  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.01764 (* 1 = 2.01764 loss)
I0817 21:55:00.402632  1670 sgd_solver.cpp:138] Iteration 64900, lr = 1e-05
I0817 22:04:18.665714  1670 solver.cpp:243] Iteration 65000, loss = 2.65873
I0817 22:04:18.667011  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.05352 (* 1 = 3.05352 loss)
I0817 22:04:18.667017  1670 sgd_solver.cpp:138] Iteration 65000, lr = 1e-05
I0817 22:13:40.589741  1670 solver.cpp:243] Iteration 65100, loss = 3.4595
I0817 22:13:40.591133  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.22596 (* 1 = 2.22596 loss)
I0817 22:13:40.591140  1670 sgd_solver.cpp:138] Iteration 65100, lr = 1e-05
I0817 22:22:57.867013  1670 solver.cpp:243] Iteration 65200, loss = 2.77859
I0817 22:22:57.867080  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.16042 (* 1 = 3.16042 loss)
I0817 22:22:57.867086  1670 sgd_solver.cpp:138] Iteration 65200, lr = 1e-05
I0817 22:32:20.742072  1670 solver.cpp:243] Iteration 65300, loss = 2.91358
I0817 22:32:20.743270  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82504 (* 1 = 2.82504 loss)
I0817 22:32:20.743276  1670 sgd_solver.cpp:138] Iteration 65300, lr = 1e-05
I0817 22:41:38.179971  1670 solver.cpp:243] Iteration 65400, loss = 2.48199
I0817 22:41:38.180052  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.41602 (* 1 = 2.41602 loss)
I0817 22:41:38.180058  1670 sgd_solver.cpp:138] Iteration 65400, lr = 1e-05
I0817 22:51:01.059255  1670 solver.cpp:243] Iteration 65500, loss = 3.1069
I0817 22:51:01.060030  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.58971 (* 1 = 3.58971 loss)
I0817 22:51:01.060036  1670 sgd_solver.cpp:138] Iteration 65500, lr = 1e-05
I0817 23:00:17.977454  1670 solver.cpp:243] Iteration 65600, loss = 2.11224
I0817 23:00:17.979063  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.78586 (* 1 = 2.78586 loss)
I0817 23:00:17.979071  1670 sgd_solver.cpp:138] Iteration 65600, lr = 1e-05
I0817 23:09:41.479146  1670 solver.cpp:243] Iteration 65700, loss = 3.0275
I0817 23:09:41.479914  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.23911 (* 1 = 4.23911 loss)
I0817 23:09:41.479934  1670 sgd_solver.cpp:138] Iteration 65700, lr = 1e-05
I0817 23:18:58.373661  1670 solver.cpp:243] Iteration 65800, loss = 2.2096
I0817 23:18:58.374945  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.46675 (* 1 = 2.46675 loss)
I0817 23:18:58.374953  1670 sgd_solver.cpp:138] Iteration 65800, lr = 1e-05
I0817 23:28:21.739941  1670 solver.cpp:243] Iteration 65900, loss = 3.03283
I0817 23:28:21.741255  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.369 (* 1 = 2.369 loss)
I0817 23:28:21.741263  1670 sgd_solver.cpp:138] Iteration 65900, lr = 1e-05
I0817 23:37:38.413463  1670 solver.cpp:243] Iteration 66000, loss = 2.65744
I0817 23:37:38.414752  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.70085 (* 1 = 2.70085 loss)
I0817 23:37:38.414764  1670 sgd_solver.cpp:138] Iteration 66000, lr = 1e-05
I0817 23:47:02.912981  1670 solver.cpp:243] Iteration 66100, loss = 3.03569
I0817 23:47:02.914278  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.13336 (* 1 = 3.13336 loss)
I0817 23:47:02.914283  1670 sgd_solver.cpp:138] Iteration 66100, lr = 1e-05
I0817 23:56:19.705893  1670 solver.cpp:243] Iteration 66200, loss = 2.61134
I0817 23:56:19.707124  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.6728 (* 1 = 2.6728 loss)
I0817 23:56:19.707132  1670 sgd_solver.cpp:138] Iteration 66200, lr = 1e-05
I0818 00:05:44.565906  1670 solver.cpp:243] Iteration 66300, loss = 2.82654
I0818 00:05:44.567221  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.39716 (* 1 = 1.39716 loss)
I0818 00:05:44.567229  1670 sgd_solver.cpp:138] Iteration 66300, lr = 1e-05
I0818 00:15:01.502974  1670 solver.cpp:243] Iteration 66400, loss = 2.27578
I0818 00:15:01.503969  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.06334 (* 1 = 2.06334 loss)
I0818 00:15:01.503978  1670 sgd_solver.cpp:138] Iteration 66400, lr = 1e-05
I0818 00:24:26.036712  1670 solver.cpp:243] Iteration 66500, loss = 2.68043
I0818 00:24:26.038004  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.75517 (* 1 = 3.75517 loss)
I0818 00:24:26.038012  1670 sgd_solver.cpp:138] Iteration 66500, lr = 1e-05
I0818 00:33:45.501549  1670 solver.cpp:243] Iteration 66600, loss = 2.69132
I0818 00:33:45.502851  1670 solver.cpp:259]     Train net output #0: mbox_loss = 6.21377 (* 1 = 6.21377 loss)
I0818 00:33:45.502861  1670 sgd_solver.cpp:138] Iteration 66600, lr = 1e-05
I0818 00:43:07.863857  1670 solver.cpp:243] Iteration 66700, loss = 2.95852
I0818 00:43:07.863991  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.02042 (* 1 = 4.02042 loss)
I0818 00:43:07.863998  1670 sgd_solver.cpp:138] Iteration 66700, lr = 1e-05
I0818 00:52:29.258018  1670 solver.cpp:243] Iteration 66800, loss = 4.60889
I0818 00:52:29.259611  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.822 (* 1 = 1.822 loss)
I0818 00:52:29.259621  1670 sgd_solver.cpp:138] Iteration 66800, lr = 1e-05
I0818 01:01:49.948210  1670 solver.cpp:243] Iteration 66900, loss = 2.95326
I0818 01:01:49.949378  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.70871 (* 1 = 1.70871 loss)
I0818 01:01:49.949383  1670 sgd_solver.cpp:138] Iteration 66900, lr = 1e-05
I0818 01:11:11.715070  1670 solver.cpp:243] Iteration 67000, loss = 3.79124
I0818 01:11:11.716066  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.59828 (* 1 = 2.59828 loss)
I0818 01:11:11.716073  1670 sgd_solver.cpp:138] Iteration 67000, lr = 1e-05
I0818 01:20:30.859638  1670 solver.cpp:243] Iteration 67100, loss = 2.81291
I0818 01:20:30.859943  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.62785 (* 1 = 1.62785 loss)
I0818 01:20:30.859949  1670 sgd_solver.cpp:138] Iteration 67100, lr = 1e-05
I0818 01:29:54.142541  1670 solver.cpp:243] Iteration 67200, loss = 3.51036
I0818 01:29:54.143929  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.7199 (* 1 = 3.7199 loss)
I0818 01:29:54.143935  1670 sgd_solver.cpp:138] Iteration 67200, lr = 1e-05
I0818 01:39:12.643744  1670 solver.cpp:243] Iteration 67300, loss = 2.61049
I0818 01:39:12.644023  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.08682 (* 1 = 3.08682 loss)
I0818 01:39:12.644031  1670 sgd_solver.cpp:138] Iteration 67300, lr = 1e-05
I0818 01:48:35.411929  1670 solver.cpp:243] Iteration 67400, loss = 3.36156
I0818 01:48:35.413148  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.7345 (* 1 = 2.7345 loss)
I0818 01:48:35.413154  1670 sgd_solver.cpp:138] Iteration 67400, lr = 1e-05
I0818 01:57:53.455893  1670 solver.cpp:243] Iteration 67500, loss = 2.66418
I0818 01:57:53.455983  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.82805 (* 1 = 2.82805 loss)
I0818 01:57:53.455989  1670 sgd_solver.cpp:138] Iteration 67500, lr = 1e-05
I0818 02:07:17.212193  1670 solver.cpp:243] Iteration 67600, loss = 2.85463
I0818 02:07:17.213433  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.19689 (* 1 = 3.19689 loss)
I0818 02:07:17.213438  1670 sgd_solver.cpp:138] Iteration 67600, lr = 1e-05
I0818 02:16:35.643252  1670 solver.cpp:243] Iteration 67700, loss = 2.1969
I0818 02:16:35.643987  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.14172 (* 1 = 3.14172 loss)
I0818 02:16:35.643996  1670 sgd_solver.cpp:138] Iteration 67700, lr = 1e-05
I0818 02:25:58.890430  1670 solver.cpp:243] Iteration 67800, loss = 2.99032
I0818 02:25:58.891760  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.53405 (* 1 = 3.53405 loss)
I0818 02:25:58.891767  1670 sgd_solver.cpp:138] Iteration 67800, lr = 1e-05
I0818 02:35:16.292246  1670 solver.cpp:243] Iteration 67900, loss = 2.05255
I0818 02:35:16.292325  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.386 (* 1 = 1.386 loss)
I0818 02:35:16.292331  1670 sgd_solver.cpp:138] Iteration 67900, lr = 1e-05
I0818 02:44:40.435072  1670 solver.cpp:243] Iteration 68000, loss = 3.10896
I0818 02:44:40.435976  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.48126 (* 1 = 3.48126 loss)
I0818 02:44:40.435983  1670 sgd_solver.cpp:138] Iteration 68000, lr = 1e-05
I0818 02:53:57.220741  1670 solver.cpp:243] Iteration 68100, loss = 2.41958
I0818 02:53:57.220814  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.22042 (* 1 = 2.22042 loss)
I0818 02:53:57.220820  1670 sgd_solver.cpp:138] Iteration 68100, lr = 1e-05
I0818 03:03:21.059448  1670 solver.cpp:243] Iteration 68200, loss = 2.93759
I0818 03:03:21.059969  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.8968 (* 1 = 2.8968 loss)
I0818 03:03:21.059975  1670 sgd_solver.cpp:138] Iteration 68200, lr = 1e-05
I0818 03:12:37.720831  1670 solver.cpp:243] Iteration 68300, loss = 2.66951
I0818 03:12:37.722134  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.38557 (* 1 = 3.38557 loss)
I0818 03:12:37.722141  1670 sgd_solver.cpp:138] Iteration 68300, lr = 1e-05
I0818 03:22:02.637470  1670 solver.cpp:243] Iteration 68400, loss = 2.9329
I0818 03:22:02.638914  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.76947 (* 1 = 2.76947 loss)
I0818 03:22:02.638922  1670 sgd_solver.cpp:138] Iteration 68400, lr = 1e-05
I0818 03:31:19.257688  1670 solver.cpp:243] Iteration 68500, loss = 2.51221
I0818 03:31:19.257767  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.39989 (* 1 = 2.39989 loss)
I0818 03:31:19.257773  1670 sgd_solver.cpp:138] Iteration 68500, lr = 1e-05
I0818 03:40:42.215085  1670 solver.cpp:243] Iteration 68600, loss = 2.58405
I0818 03:40:42.215997  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.648098 (* 1 = 0.648098 loss)
I0818 03:40:42.216004  1670 sgd_solver.cpp:138] Iteration 68600, lr = 1e-05
I0818 03:49:58.916590  1670 solver.cpp:243] Iteration 68700, loss = 2.03033
I0818 03:49:58.917835  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.51921 (* 1 = 1.51921 loss)
I0818 03:49:58.917841  1670 sgd_solver.cpp:138] Iteration 68700, lr = 1e-05
I0818 03:59:23.521104  1670 solver.cpp:243] Iteration 68800, loss = 2.68001
I0818 03:59:23.522449  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.98782 (* 1 = 2.98782 loss)
I0818 03:59:23.522456  1670 sgd_solver.cpp:138] Iteration 68800, lr = 1e-05
I0818 04:08:43.249887  1670 solver.cpp:243] Iteration 68900, loss = 3.76155
I0818 04:08:43.255672  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.03595 (* 1 = 4.03595 loss)
I0818 04:08:43.255681  1670 sgd_solver.cpp:138] Iteration 68900, lr = 1e-05
I0818 04:18:04.467535  1670 solver.cpp:243] Iteration 69000, loss = 2.92626
I0818 04:18:04.467998  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.46861 (* 1 = 2.46861 loss)
I0818 04:18:04.468005  1670 sgd_solver.cpp:138] Iteration 69000, lr = 1e-05
I0818 04:27:25.005496  1670 solver.cpp:243] Iteration 69100, loss = 4.03034
I0818 04:27:25.006837  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.23564 (* 1 = 3.23564 loss)
I0818 04:27:25.006845  1670 sgd_solver.cpp:138] Iteration 69100, lr = 1e-05
I0818 04:36:43.944247  1670 solver.cpp:243] Iteration 69200, loss = 3.03534
I0818 04:36:43.945646  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.62783 (* 1 = 3.62783 loss)
I0818 04:36:43.945652  1670 sgd_solver.cpp:138] Iteration 69200, lr = 1e-05
I0818 04:46:04.436458  1670 solver.cpp:243] Iteration 69300, loss = 3.61917
I0818 04:46:04.437728  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.89971 (* 1 = 2.89971 loss)
I0818 04:46:04.437736  1670 sgd_solver.cpp:138] Iteration 69300, lr = 1e-05
I0818 04:55:22.538322  1670 solver.cpp:243] Iteration 69400, loss = 2.58604
I0818 04:55:22.539589  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.97051 (* 1 = 1.97051 loss)
I0818 04:55:22.539598  1670 sgd_solver.cpp:138] Iteration 69400, lr = 1e-05
I0818 05:04:44.374842  1670 solver.cpp:243] Iteration 69500, loss = 3.47278
I0818 05:04:44.375993  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.69566 (* 1 = 3.69566 loss)
I0818 05:04:44.376000  1670 sgd_solver.cpp:138] Iteration 69500, lr = 1e-05
I0818 05:14:02.069850  1670 solver.cpp:243] Iteration 69600, loss = 2.5722
I0818 05:14:02.071100  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.10287 (* 1 = 3.10287 loss)
I0818 05:14:02.071111  1670 sgd_solver.cpp:138] Iteration 69600, lr = 1e-05
I0818 05:23:24.430595  1670 solver.cpp:243] Iteration 69700, loss = 2.93168
I0818 05:23:24.431866  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.67863 (* 1 = 1.67863 loss)
I0818 05:23:24.431874  1670 sgd_solver.cpp:138] Iteration 69700, lr = 1e-05
I0818 05:32:42.083513  1670 solver.cpp:243] Iteration 69800, loss = 2.51078
I0818 05:32:42.083971  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.91916 (* 1 = 2.91916 loss)
I0818 05:32:42.083976  1670 sgd_solver.cpp:138] Iteration 69800, lr = 1e-05
I0818 05:42:04.828320  1670 solver.cpp:243] Iteration 69900, loss = 2.91209
I0818 05:42:04.829553  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.8486 (* 1 = 2.8486 loss)
I0818 05:42:04.829560  1670 sgd_solver.cpp:138] Iteration 69900, lr = 1e-05
I0818 05:51:16.441068  1670 solver.cpp:433] Iteration 70000, Testing net (#0)
I0818 05:51:16.441161  1670 net.cpp:693] Ignoring source layer mbox_loss
W0818 05:53:49.093606  1670 solver.cpp:524] Missing true_pos for label: 20
W0818 05:53:49.095155  1670 solver.cpp:524] Missing true_pos for label: 22
I0818 05:53:49.095163  1670 solver.cpp:546]     Test net output #0: detection_eval = 0.363753
I0818 05:53:54.100373  1670 solver.cpp:243] Iteration 70000, loss = 2.07793
I0818 05:53:54.100409  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.14597 (* 1 = 3.14597 loss)
I0818 05:53:54.100414  1670 sgd_solver.cpp:138] Iteration 70000, lr = 1e-05
I0818 06:03:17.244405  1670 solver.cpp:243] Iteration 70100, loss = 2.95882
I0818 06:03:17.245733  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.59395 (* 1 = 1.59395 loss)
I0818 06:03:17.245739  1670 sgd_solver.cpp:138] Iteration 70100, lr = 1e-05
I0818 06:12:33.544229  1670 solver.cpp:243] Iteration 70200, loss = 2.11569
I0818 06:12:33.545410  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.65917 (* 1 = 1.65917 loss)
I0818 06:12:33.545416  1670 sgd_solver.cpp:138] Iteration 70200, lr = 1e-05
I0818 06:21:56.945617  1670 solver.cpp:243] Iteration 70300, loss = 3.114
I0818 06:21:56.946985  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.27916 (* 1 = 1.27916 loss)
I0818 06:21:56.946993  1670 sgd_solver.cpp:138] Iteration 70300, lr = 1e-05
I0818 06:31:13.193675  1670 solver.cpp:243] Iteration 70400, loss = 2.58684
I0818 06:31:13.194543  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.37389 (* 1 = 1.37389 loss)
I0818 06:31:13.194550  1670 sgd_solver.cpp:138] Iteration 70400, lr = 1e-05
I0818 06:40:37.016532  1670 solver.cpp:243] Iteration 70500, loss = 3.05061
I0818 06:40:37.016611  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.62449 (* 1 = 3.62449 loss)
I0818 06:40:37.016618  1670 sgd_solver.cpp:138] Iteration 70500, lr = 1e-05
I0818 06:49:53.171332  1670 solver.cpp:243] Iteration 70600, loss = 2.57591
I0818 06:49:53.171396  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.13226 (* 1 = 2.13226 loss)
I0818 06:49:53.171403  1670 sgd_solver.cpp:138] Iteration 70600, lr = 1e-05
I0818 06:59:16.527002  1670 solver.cpp:243] Iteration 70700, loss = 2.80227
I0818 06:59:16.527994  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.920381 (* 1 = 0.920381 loss)
I0818 06:59:16.528002  1670 sgd_solver.cpp:138] Iteration 70700, lr = 1e-05
I0818 07:08:33.738536  1670 solver.cpp:243] Iteration 70800, loss = 2.39796
I0818 07:08:33.740519  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.12181 (* 1 = 1.12181 loss)
I0818 07:08:33.740540  1670 sgd_solver.cpp:138] Iteration 70800, lr = 1e-05
I0818 07:17:56.934834  1670 solver.cpp:243] Iteration 70900, loss = 2.55149
I0818 07:17:56.935513  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.95115 (* 1 = 3.95115 loss)
I0818 07:17:56.935519  1670 sgd_solver.cpp:138] Iteration 70900, lr = 1e-05
I0818 07:27:14.437599  1670 solver.cpp:243] Iteration 71000, loss = 2.03303
I0818 07:27:14.438408  1670 solver.cpp:259]     Train net output #0: mbox_loss = 12.352 (* 1 = 12.352 loss)
I0818 07:27:14.438416  1670 sgd_solver.cpp:138] Iteration 71000, lr = 1e-05
I0818 07:36:36.873373  1670 solver.cpp:243] Iteration 71100, loss = 2.96135
I0818 07:36:36.874886  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.86285 (* 1 = 1.86285 loss)
I0818 07:36:36.874894  1670 sgd_solver.cpp:138] Iteration 71100, lr = 1e-05
I0818 07:45:58.436216  1670 solver.cpp:243] Iteration 71200, loss = 4.95094
I0818 07:45:58.437089  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.13544 (* 1 = 3.13544 loss)
I0818 07:45:58.437096  1670 sgd_solver.cpp:138] Iteration 71200, lr = 1e-05
I0818 07:55:18.789855  1670 solver.cpp:243] Iteration 71300, loss = 2.94901
I0818 07:55:18.791280  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.78328 (* 1 = 3.78328 loss)
I0818 07:55:18.791288  1670 sgd_solver.cpp:138] Iteration 71300, lr = 1e-05
I0818 08:04:40.569756  1670 solver.cpp:243] Iteration 71400, loss = 3.80732
I0818 08:04:40.569833  1670 solver.cpp:259]     Train net output #0: mbox_loss = 4.15223 (* 1 = 4.15223 loss)
I0818 08:04:40.569839  1670 sgd_solver.cpp:138] Iteration 71400, lr = 1e-05
I0818 08:14:00.216400  1670 solver.cpp:243] Iteration 71500, loss = 2.89051
I0818 08:14:00.217612  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.52784 (* 1 = 2.52784 loss)
I0818 08:14:00.217618  1670 sgd_solver.cpp:138] Iteration 71500, lr = 1e-05
I0818 08:23:23.074036  1670 solver.cpp:243] Iteration 71600, loss = 3.49546
I0818 08:23:23.075335  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.85802 (* 1 = 2.85802 loss)
I0818 08:23:23.075342  1670 sgd_solver.cpp:138] Iteration 71600, lr = 1e-05
I0818 08:32:41.688578  1670 solver.cpp:243] Iteration 71700, loss = 2.64213
I0818 08:32:41.689790  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.23151 (* 1 = 3.23151 loss)
I0818 08:32:41.689795  1670 sgd_solver.cpp:138] Iteration 71700, lr = 1e-05
I0818 08:42:05.142963  1670 solver.cpp:243] Iteration 71800, loss = 3.35468
I0818 08:42:05.144361  1670 solver.cpp:259]     Train net output #0: mbox_loss = 3.44715 (* 1 = 3.44715 loss)
I0818 08:42:05.144366  1670 sgd_solver.cpp:138] Iteration 71800, lr = 1e-05
I0818 08:51:23.394865  1670 solver.cpp:243] Iteration 71900, loss = 2.60194
I0818 08:51:23.396009  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.54937 (* 1 = 2.54937 loss)
I0818 08:51:23.396031  1670 sgd_solver.cpp:138] Iteration 71900, lr = 1e-05
I0818 09:00:46.813834  1670 solver.cpp:243] Iteration 72000, loss = 2.7707
I0818 09:00:46.815129  1670 solver.cpp:259]     Train net output #0: mbox_loss = 2.24504 (* 1 = 2.24504 loss)
I0818 09:00:46.815136  1670 sgd_solver.cpp:138] Iteration 72000, lr = 1e-05
I0818 09:10:04.957353  1670 solver.cpp:243] Iteration 72100, loss = 2.21885
I0818 09:10:04.958647  1670 solver.cpp:259]     Train net output #0: mbox_loss = 1.04794 (* 1 = 1.04794 loss)
I0818 09:10:04.958652  1670 sgd_solver.cpp:138] Iteration 72100, lr = 1e-05
I0818 09:19:27.756309  1670 solver.cpp:243] Iteration 72200, loss = 3.00633
I0818 09:19:27.756386  1670 solver.cpp:259]     Train net output #0: mbox_loss = 0.806831 (* 1 = 0.806831 loss)
I0818 09:19:27.756393  1670 sgd_solver.cpp:138] Iteration 72200, lr = 1e-05

